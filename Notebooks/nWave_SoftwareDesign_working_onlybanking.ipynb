{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Design Using ML&AI nWave\n",
    "\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "To prepare your environment, you need to install some packages\n",
    "\n",
    "# 1.1 Install the necessary packages\n",
    "\n",
    "You need the latest versions of these packages:<br>\n",
    " \n",
    "\n",
    "** Pandas for dataframe.<br>\n",
    "** stop_words: **List of common stop words.<br>\n",
    "** python-boto3:** is a python client for the Boto3 API used for communicating to AWS.<br>\n",
    "** websocket-client: ** is a python client for the Websockets.<br>\n",
    "** pyorient: ** is a python client for the Orient DB.<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install NLTK: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /anaconda3/lib/python3.6/site-packages (3.3)\n",
      "Requirement not upgraded as not directly required: six in /anaconda3/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pyorient in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.5.5)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n",
    "!pip install --upgrade pyorient"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Install Boto3 client for AWS communication thorugh CLI **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /anaconda3/lib/python3.6/site-packages (1.7.11)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.11 in /Users/swaroopmishra/.local/lib/python3.6/site-packages (from boto3) (1.10.20)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.11.0,>=1.10.11->boto3) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install stop_words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in /anaconda3/lib/python3.6/site-packages (2015.2.23.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install websocket client: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: websocket-client in /anaconda3/lib/python3.6/site-packages (0.47.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from websocket-client) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install websocket-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install pyorient: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.15.20)\n",
      "Requirement already satisfied: PyYAML<=3.12,>=3.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.12)\n",
      "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.4.2)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.14)\n",
      "Requirement already satisfied: botocore==1.10.20 in /Users/swaroopmishra/.local/lib/python3.6/site-packages (from awscli) (1.10.20)\n",
      "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.3.7)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.12 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.1.13)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /anaconda3/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli) (0.4.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.20->awscli) (2.6.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.20->awscli) (0.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore==1.10.20->awscli) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pyorient in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.5.5)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install awscli\n",
    "! pip install pyorient --user\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Import packages and libraries \n",
    "\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from stop_words import get_stop_words\n",
    "import numpy\n",
    "import re\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "import websocket\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuration\n",
    "\n",
    "Add configurable items of the notebook below\n",
    "## 2.1 Add your service credentials if any required( this is where you need to add credentials of infrastructure you are using to store data etc)\n",
    "\n",
    "\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the section to provide credentials for AWS S3 account\n",
    "### While sharing the notebook remove them -- will try to make this cell hidden later\n",
    "\n",
    "## Console URL :::  https://awstestconsole-swaroop.signin.aws.amazon.com/console\n",
    "## Account Id:Â \n",
    "## Username : \n",
    "## Password : \n",
    "## Then Navigate to the S3 section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Add your service credentials for S3\n",
    "\n",
    "You must create S3 bucket service on AWS. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage authentication credentials as credentials_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'ACCESS_KEY_ID': 'AKIAJW2Q23KX7U6DQMCQ',\n",
    "    'ACCESS_SECRET_KEY': 'qqgJ9L1Y8BepDnh/v5BwIvxlUUPbWrPJ6OoDchls',\n",
    "    'BUCKET': 'banking-brd-bucket'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Classification  ( this section will be required if we use spacy for machine learning)\n",
    "\n",
    "Write the classification related utility functions in a modularalized form.\n",
    "\n",
    "## 3.1  REQUIREMENT Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentence(text):\n",
    "    \"\"\" Tag the sentence using chunking.\n",
    "    \"\"\"\n",
    "    grammar = \"\"\"\n",
    "      Action: {<VB.?><NN.?>+}\n",
    "      Action: {<VB.?><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{\n",
    "      Action: {<VB.?><CLAUSE1><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{\n",
    "      Action: {<VB.?><CLAUSE1><CLAUSE1><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{  \n",
    "      CLAUSE1: {<DT|PRP.?|IN|JJ>}\n",
    "      \n",
    "      \n",
    "      \"\"\"  \n",
    "    parsed_cp = nltk.RegexpParser(grammar,loop=2)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    return pos_cp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Augumented Classification\n",
    "\n",
    "Custom classification utlity fucntions for augumenting the results by using the Grammar rule defined in JSON file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\" Split text into sentences.\n",
    "    \"\"\"\n",
    "    sentence_delimiters = re.compile(u'[\\\\[\\\\]\\n.!?]')\n",
    "    sentences = sentence_delimiters.split(text)\n",
    "    return sentences\n",
    "\n",
    "def split_into_tokens(text):\n",
    "    \"\"\" Split text into tokens.\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "    \n",
    "def POS_tagging(text):\n",
    "    \"\"\" Generate Part of speech tagging of the text.\n",
    "    \"\"\"\n",
    "    POSofText = nltk.tag.pos_tag(text)\n",
    "    return POSofText\n",
    "\n",
    "\n",
    "def keyword_tagging(tag,tagtext,text):\n",
    "    \"\"\" Tag the text matching keywords.\n",
    "    \"\"\"\n",
    "    if (text.lower().find(tagtext.lower()) != -1):\n",
    "        return text[text.lower().find(tagtext.lower()):text.lower().find(tagtext.lower())+len(tagtext)]\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "    \n",
    "def regex_tagging(tag,regex,text):\n",
    "    \"\"\" Tag the text matching REGEX.\n",
    "    \"\"\"    \n",
    "    p = re.compile(regex, re.IGNORECASE)\n",
    "    matchtext = p.findall(text)\n",
    "    regex_list=[]    \n",
    "    if (len(matchtext)>0):\n",
    "        for regword in matchtext:\n",
    "            regex_list.append(regword)\n",
    "    return regex_list\n",
    "\n",
    "def BRD_chunk_tagging(tag,chunk,text):\n",
    "    \"\"\" Tag the text using chunking.\n",
    "    \"\"\"\n",
    "    parsed_cp = nltk.RegexpParser(chunk)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    #pos_cp = chunk_sentence(text) #*** use this for getting refined output after chinking but extra entities in output\n",
    "    chunk_list=[]\n",
    "    for root in pos_cp:\n",
    "        if isinstance(root, nltk.tree.Tree):               \n",
    "            if root.label() == tag:\n",
    "                chunk_word = ''\n",
    "                for child_root in root:\n",
    "                    chunk_word = chunk_word +' '+ child_root[0]\n",
    "                chunk_list.append(chunk_word)\n",
    "    return chunk_list\n",
    "\n",
    "def chunk_tagging(tag,chunk,text):\n",
    "    \"\"\" Tag the text using chunking.\n",
    "    \"\"\"\n",
    "    parsed_cp = nltk.RegexpParser(chunk)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    chunk_list=[]\n",
    "    for root in pos_cp:\n",
    "        if isinstance(root, nltk.tree.Tree):               \n",
    "            if root.label() == tag:\n",
    "                chunk_word = ''\n",
    "                for child_root in root:\n",
    "                    chunk_word = chunk_word +' '+ child_root[0]\n",
    "                chunk_list.append(chunk_word)\n",
    "    return chunk_list\n",
    "    \n",
    "def augument_SpResponse(responsejson,updateType,text,tag):\n",
    "    \"\"\" Update the output JSON with augumented classifications.\n",
    "    \"\"\"\n",
    "    if(updateType == 'keyword'):\n",
    "        if not any(d.get('text', None) == text for d in responsejson['Keywords']):\n",
    "            responsejson['Keywords'].append({\"User\":text})\n",
    "    else:\n",
    "        if not any(d.get('text', None) == text for d in responsejson['Entities']):\n",
    "            responsejson['Entities'].append({\"type\":tag,\"text\":text}) \n",
    "\n",
    "def classify_BRD_text(text, config):\n",
    "    \"\"\" Perform augumented classification of the text for BRD specifically for getting the output with action.\n",
    "    \"\"\"\n",
    "    \n",
    "    #will be used for storing initial value of response json, this is from nlu earlier\n",
    "    with open('output_format_BRD.json') as f:\n",
    "        responsejson = json.load(f)\n",
    "    \n",
    "    sentenceList = split_sentences(text) #\n",
    "    \n",
    "    tokens = split_into_tokens(text)\n",
    "    \n",
    "    postags = POS_tagging(tokens)\n",
    "    \n",
    "    configjson = json.loads(config)#load would take a file-like object, read the data from that object, and use that string to create an object:\n",
    "    \n",
    "    no_of_items = 0\n",
    "    \n",
    "    for stages in configjson['configuration']['classification']['stages']:\n",
    "        # print('Stage - Performing ' + stages['name']+':')\n",
    "        for steps in stages['steps']:\n",
    "            # print('    Step - ' + steps['type']+':')\n",
    "            if (steps['type'] == 'keywords'):\n",
    "                for keyword in steps['keywords']:\n",
    "                        wordtag = tokens[0]\n",
    "                augument_SpResponse(responsejson,'keyword',wordtag,keyword['tag'])\n",
    "            elif(steps['type'] == 'd_regex'):\n",
    "                for regex in steps['d_regex']:\n",
    "                    for word in sentenceList:\n",
    "                        regextags = regex_tagging(regex['tag'],regex['pattern'],word)\n",
    "                        if (len(regextags)>0):\n",
    "                            for words in regextags:\n",
    "                                #print('      '+regex['tag']+':'+words)\n",
    "                                augument_SpResponse(responsejson,'Action',words,regex['tag'])\n",
    "            elif(steps['type'] == 'chunking'):\n",
    "                for chunk in steps['chunk']:\n",
    "                    chunktags = BRD_chunk_tagging(chunk['tag'],chunk['pattern'],postags)\n",
    "                    if (len(chunktags)>0):\n",
    "                        for words in chunktags:\n",
    "                            #print('      '+chunk['tag']+':'+words)\n",
    "                            if (no_of_items <1):\n",
    "                                augument_SpResponse(responsejson,'Action',words,chunk['tag'])\n",
    "                                no_of_items = no_of_items + 1\n",
    "            else:\n",
    "                print('UNKNOWN STEP')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return responsejson\n",
    "\n",
    "\n",
    "\n",
    "def classify_text(text, config):\n",
    "    \"\"\" Perform augumented classification of the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    #will be used for storing initial value of response json, this is from nlu earlier\n",
    "    with open('sample.json') as f:\n",
    "        responsejson = json.load(f)\n",
    "    \n",
    "    sentenceList = split_sentences(text) #\n",
    "    \n",
    "    tokens = split_into_tokens(text)\n",
    "    \n",
    "    postags = POS_tagging(tokens)\n",
    "    \n",
    "    configjson = json.loads(config)#load would take a file-like object, read the data from that object, and use that string to create an object:\n",
    "    \n",
    "    for stages in configjson['configuration']['classification']['stages']:\n",
    "        # print('Stage - Performing ' + stages['name']+':')\n",
    "        for steps in stages['steps']:\n",
    "            # print('    Step - ' + steps['type']+':')\n",
    "            if (steps['type'] == 'keywords'):\n",
    "                for keyword in steps['keywords']:\n",
    "                    for word in sentenceList:\n",
    "                        wordtag = keyword_tagging(keyword['tag'],keyword['text'],word)\n",
    "                        if(wordtag != 'UNKNOWN'):\n",
    "                            #print('      '+keyword['tag']+':'+wordtag)\n",
    "                            augument_SpResponse(responsejson,'keyword',wordtag,keyword['tag'])\n",
    "            elif(steps['type'] == 'd_regex'):\n",
    "                for regex in steps['d_regex']:\n",
    "                    for word in sentenceList:\n",
    "                        regextags = regex_tagging(regex['tag'],regex['pattern'],word)\n",
    "                        if (len(regextags)>0):\n",
    "                            for words in regextags:\n",
    "                                #print('      '+regex['tag']+':'+words)\n",
    "                                augument_SpResponse(responsejson,'entities',words,regex['tag'])\n",
    "            elif(steps['type'] == 'chunking'):\n",
    "                for chunk in steps['chunk']:\n",
    "                    chunktags = chunk_tagging(chunk['tag'],chunk['pattern'],postags)\n",
    "                    if (len(chunktags)>0):\n",
    "                        for words in chunktags:\n",
    "                            #print('      '+chunk['tag']+':'+words)\n",
    "                            augument_SpResponse(responsejson,'entities',words,chunk['tag'])\n",
    "            else:\n",
    "                print('UNKNOWN STEP')\n",
    "    \n",
    "    \n",
    "    return responsejson\n",
    "\n",
    "\n",
    "def replace_unicode_strings(response):\n",
    "    \"\"\" Convert dict with unicode strings to strings.\n",
    "    \"\"\"\n",
    "    if isinstance(response, dict):\n",
    "        return {replace_unicode_strings(key): replace_unicode_strings(value) for key, value in response.iteritems()}\n",
    "    elif isinstance(response, list):\n",
    "        return [replace_unicode_strings(element) for element in response]\n",
    "    elif isinstance(response, unicode):\n",
    "        return response.encode('utf-8')\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Correlate text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = get_stop_words('english')\n",
    "# List of words to be ignored for text similarity\n",
    "stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])\n",
    "\n",
    "def compute_text_similarity(text1, text2, text1tags, text2tags):\n",
    "    \"\"\" Compute text similarity using cosine\n",
    "    \"\"\"\n",
    "    #stemming is the process for reducing inflected (or sometimes derived) words to their stem, base or root form\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    sentences_text1 = split_sentences(text1)\n",
    "    sentences_text2 = split_sentences(text2)\n",
    "    tokens_text1 = []\n",
    "    tokens_text2 = []\n",
    "    \n",
    "    for sentence in sentences_text1:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        tokens_text1.extend(tokenstemp)\n",
    "    \n",
    "    for sentence in sentences_text2:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        tokens_text2.extend(tokenstemp)\n",
    "    if (len(text1tags) > 0):  \n",
    "        tokens_text1.extend(text1tags)\n",
    "    if (len(text2tags) > 0):    \n",
    "        tokens_text2.extend(text2tags)\n",
    "    \n",
    "    tokens1Filtered = [stemmer.stem(x) for x in tokens_text1 if x not in stopWords]\n",
    "    \n",
    "    tokens2Filtered = [stemmer.stem(x) for x in tokens_text2 if x not in stopWords]\n",
    "    \n",
    "    #  remove duplicate tokens\n",
    "    tokens1Filtered = set(tokens1Filtered)\n",
    "    tokens2Filtered = set(tokens2Filtered)\n",
    "   \n",
    "    tokensList=[]\n",
    "\n",
    "    text1vector = []\n",
    "    text2vector = []\n",
    "    \n",
    "    if len(tokens1Filtered) < len(tokens2Filtered):\n",
    "        tokensList = tokens1Filtered\n",
    "    else:\n",
    "        tokensList = tokens2Filtered\n",
    "\n",
    "    for token in tokensList:\n",
    "        if token in tokens1Filtered:\n",
    "            text1vector.append(1)\n",
    "        else:\n",
    "            text1vector.append(0)\n",
    "        if token in tokens2Filtered:\n",
    "            text2vector.append(1)\n",
    "        else:\n",
    "            text2vector.append(0)  \n",
    "\n",
    "    cosine_similarity = 1-cosine_distance(text1vector,text2vector)\n",
    "    if numpy.isnan(cosine_similarity):\n",
    "        cosine_similarity = 0\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Persistence and Storage\n",
    "## 5.1 Configure Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                    aws_access_key_id=credentials_1['ACCESS_KEY_ID'],\n",
    "                    aws_secret_access_key=credentials_1['ACCESS_SECRET_KEY'],\n",
    "                    config=Config(signature_version='s3v4')\n",
    "                     )\n",
    "#Enter the path where you want to store data downlaoded from S3\n",
    "\n",
    "\n",
    "def get_file(filename,Location):\n",
    "    s3.download_file(Bucket=credentials_1['BUCKET'],Key=filename,Filename=Location)\n",
    "    #t=\"abc\"\n",
    "\n",
    "#def load_string(fileobject):\n",
    "#    '''Load the file contents into a Python string'''\n",
    "#    text = fileobject.read()\n",
    "#    return text\n",
    "\n",
    "#def load_df(fileobject,sheetname):\n",
    "#    '''Load file contents into a Pandas dataframe'''\n",
    "#    excelFile = pd.ExcelFile(fileobject)\n",
    "#    df = excelFile.parse(sheetname)\n",
    "#    return df\n",
    "\n",
    "#def put_file(filename, filecontents):\n",
    "#    '''Write file to Cloud Object Storage'''\n",
    "#    resp = s3.put_object(Bucket=credentials_1['BUCKET'], Key=filename, Body=filecontents)\n",
    "    #resp = s3.Bucket(Bucket=credentials_1['BUCKET']).put_object(Key=filename, Body=filecontents)\n",
    "#    return resp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the excel file with data in S3 Storage\n",
    "BrdFileName = \"Banking-BRD.xlsx\"\n",
    "# Choose or get as an input as to which Domain it belongs to i.e banking, healthcare etc\n",
    "Domain = \"Banking\"\n",
    "\n",
    "# Name of the config files in Object Storage. Rule_brd will be used specifically for parsing requirement document\n",
    "configFileName = \"sample_config.txt\"\n",
    "BRD_configFileName = \"Rule_BRD.txt\"\n",
    "# Config contents\n",
    "config = None;\n",
    "\n",
    "Path = \".//temp/\"\n",
    "# Output excell\n",
    "\n",
    "# Requirements dataframe\n",
    "requirements_file_name = \"Requirements.xlsx\"\n",
    "#requirements_sheet_name = \"\".join((Domain,\"-Requirements\"))\n",
    "#requirements_df = None\n",
    "\n",
    "# Domain/UseCase dataframe\n",
    "domain_file_name = \"Domain.xlsx\"\n",
    "#domain_sheet_name = \"\".join((Domain,\"-Domain\"))\n",
    "#domain_df = None\n",
    "rule_file_name = \"Rule_BRD.txt\"\n",
    "\n",
    "# DataElements dataframe\n",
    "dataelements_file_name =\"DataElements.xlsx\"\n",
    "#dataelements_sheet_name =\"\".join((Domain,\"-Dataelements\"))\n",
    "#dataelements_df = None\n",
    "\n",
    "def load_artifacts():\n",
    "    Location = \"\".join((Path,requirements_file_name))\n",
    "    get_file(requirements_file_name,Location)\n",
    "    Location = \"\".join((Path,domain_file_name))\n",
    "    get_file(domain_file_name,Location)\n",
    "    Location = \"\".join((Path,dataelements_file_name))\n",
    "    get_file(dataelements_file_name,Location)\n",
    "    Location = \"\".join((Path,rule_file_name))\n",
    "    get_file(rule_file_name,Location)\n",
    "\n",
    "load_artifacts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 OrientDB client - functions to connect, store and retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Connect to OrientDB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyorient\n",
    "client = pyorient.OrientDB(host=\"localhost\", port=2424)\n",
    "user = \"root\"\n",
    "passw = \"root\"\n",
    "session_id = client.connect(user, passw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Core functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(dbname, username, password):\n",
    "    \"\"\" Create a database\n",
    "    \"\"\"\n",
    "    client.db_create( dbname, pyorient.DB_TYPE_GRAPH, pyorient.STORAGE_TYPE_MEMORY )\n",
    "    print(dbname  + \" created and opened successfully\")\n",
    "        \n",
    "def drop_database(dbname):\n",
    "    \"\"\" Drop a database\n",
    "    \"\"\"\n",
    "    if client.db_exists( dbname, pyorient.STORAGE_TYPE_MEMORY ):\n",
    "        client.db_drop(dbname)\n",
    "    \n",
    "def create_class(classname):\n",
    "    \"\"\" Create a class\n",
    "    \"\"\"\n",
    "    command = \"create class \"+classname + \" extends V\"\n",
    "    client.command(command)\n",
    "    \n",
    "def create_record(classname, entityname, attributes):\n",
    "    \"\"\" Create a record\n",
    "    \"\"\"\n",
    "    command = \"insert into \" + classname + \" set \" \n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        attrstring = attrstring + key + \" = '\"+ attributes[key] + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    client.command(command)\n",
    "    \n",
    "def create_domain_dataelements_edge(domainid, dataelementid, attributes):\n",
    "    \"\"\" Create an edge between a domain n dataelement \n",
    "    \"\"\"\n",
    "    command = \"create edge linkeddataelements from (select from Domains where ID = \" + \"'\" + domainid + \"') to (select from DataElements where ID = \" + \"'\" + dataelementid + \"')\" \n",
    "    if len(attributes) > 0:\n",
    "        command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    print(command)\n",
    "    client.command(command)    \n",
    "    \n",
    "def create_dataelements_requirement_edge(testcaseid, reqid, attributes):\n",
    "    \"\"\" Create an edge between a testcase and a requirement\n",
    "    \"\"\"\n",
    "    command = \"create edge linkedrequirements from (select from DataElements where ID = \"+ \"'\" + testcaseid+\"') to (select from Requirements where ID = \"+\"'\"+reqid+\"')\" \n",
    "    if len(attributes) > 0:\n",
    "        command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    client.command(command)  \n",
    "\n",
    "    \n",
    "def create_requirement_domain_edge(reqid, functionalityid, attributes):\n",
    "    \"\"\" Create an edge between a requirement and a domain\n",
    "    \"\"\"\n",
    "    command = \"create edge linkeddomains from (select from Requirements where ID = \"+ \"'\" + reqid+\"') to (select from Domains where ID = \"+\"'\"+functionalityid+\"')\" \n",
    "    \n",
    "    if len(attributes) > 0:\n",
    "         command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    print(command)\n",
    "    client.command(command) \n",
    "    \n",
    "def execute_query(query):\n",
    "    \"\"\" Execute a query\n",
    "    \"\"\"\n",
    "    return client.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Insights **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_domaincases(reqid):\n",
    "    \"\"\" Get the related domaincases for a requirements\n",
    "    \"\"\"\n",
    "    domaincasesQuery = \"select * from ( select expand( out('linkeddomains')) from Requirements where ID = '\" + reqid +\"' )\"\n",
    "    domaincases = execute_query(domaincasesQuery)\n",
    "    scoresQuery = \"select expand(out_linkeddomains) from Requirements where ID = '\"+reqid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    domaincaseList =[]\n",
    "    scoresList= []\n",
    "    for domaincase in domaincases:\n",
    "        domaincaseList.append(domaincase.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(domaincaseList)\n",
    "    for i in range(0, length):\n",
    "        result[domaincaseList[i]] = scoresList[i]\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "def get_related_dataelements(domaincaseid):\n",
    "    \"\"\" Get the related requirements for a testcase\n",
    "    \"\"\"\n",
    "    dataelementsQuery = \"select * from ( select expand( out('linkeddataelements') ) from Domains where ID = '\" + domaincaseid +\"' )\"\n",
    "    dataelements = execute_query(dataelementsQuery)\n",
    "    #print(dataelements)\n",
    "    scoresQuery = \"select expand(out_linkeddataelements) from Domains where ID = '\"+domaincaseid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    dataelementsList =[]\n",
    "    scoresList= []\n",
    "    for dataelement in dataelements:\n",
    "        dataelementsList.append(dataelement.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(dataelementsList)\n",
    "    #print requirementsList, scoresList\n",
    "    for i in range(0, length):\n",
    "        result[dataelementsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_related_defects(reqid):\n",
    "    \"\"\" Get the related defects for a requirement\n",
    "    \"\"\"\n",
    "    defectsQuery = \"select * from ( select expand( out('linkeddefects')) from Requirement where ID = '\" + reqid +\"' )\"\n",
    "    defects = execute_query(defectsQuery)\n",
    "    scoresQuery = \"select expand(out_linkeddefects) from Requirement where ID = '\"+reqid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    defectsList =[]\n",
    "    scoresList= []\n",
    "    for defect in defects:\n",
    "        defectsList.append(defect.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(defectsList)\n",
    "    for i in range(0, length):\n",
    "        result[defectsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def build_format_defects_list(defectsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for defects\n",
    "    \"\"\"\n",
    "    defects = []\n",
    "    for defect in defectsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] = defect.ID\n",
    "        detail['Severity'] = defect.Severity\n",
    "        detail['Description'] = defect.Description\n",
    "        defects.append(detail)\n",
    "    return defects\n",
    "\n",
    "def build_format_testcases_list(testcasesResult):\n",
    "    \"\"\" Build and format the OrientDB query results for testcases\n",
    "    \"\"\"\n",
    "    testcases = []\n",
    "    for testcase in testcasesResult:\n",
    "        detail = {}\n",
    "        detail['ID'] = testcase.ID\n",
    "        detail['Category'] = testcase.Category\n",
    "        detail['Description'] = testcase.Description\n",
    "        testcases.append(detail)\n",
    "    return testcases  \n",
    "\n",
    "def build_format_requirements_list(requirementsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for requirements\n",
    "    \"\"\"\n",
    "    requirements = []\n",
    "    for requirement in requirementsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] =requirement.ID\n",
    "        detail['Description'] = requirement.Description\n",
    "        detail['User'] = requirement.User\n",
    "        requirements.append(detail)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements():\n",
    "    \"\"\" Get all requirements\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from Requirements\"\n",
    "    requirementsResult =  execute_query(requirementsQuery)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "\n",
    "def build_format_requirements_list(requirementsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for requirements\n",
    "    \"\"\"\n",
    "    requirements = []\n",
    "    for requirement in requirementsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] =requirement.ID\n",
    "        detail['Description'] = requirement.Description\n",
    "        detail['User'] = requirement.User\n",
    "        requirements.append(detail)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements():\n",
    "    \"\"\" Get all requirements\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from Requirements\"\n",
    "    requirementsResult =  execute_query(requirementsQuery)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements \n",
    "\n",
    "def get_related_domaincases(reqid):\n",
    "    \"\"\" Get the related domaincases for a requirements\n",
    "    \"\"\"\n",
    "    domaincasesQuery = \"select * from ( select expand( out('linkeddomains')) from Requirements where ID = '\" + reqid +\"' )\"\n",
    "    domaincases = execute_query(domaincasesQuery)\n",
    "    scoresQuery = \"select expand(out_linkeddomains) from Requirements where ID = '\"+reqid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    domaincaseList =[]\n",
    "    domaincaseAction =[]\n",
    "    scoresList= []\n",
    "    for domaincase in domaincases:\n",
    "        domaincaseList.append(domaincase.ID)\n",
    "        domaincaseAction.append(domaincase.Action)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(domaincaseList)\n",
    "    for i in range(0, length):\n",
    "        result[domaincaseList[i]] = scoresList[i]\n",
    "        #result[domaincaseList[i]] = domaincaseAction[i]\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def get_related_dataelements(domaincaseid):\n",
    "    \"\"\" Get the related requirements for a testcase\n",
    "    \"\"\"\n",
    "    dataelementsQuery = \"select * from ( select expand( out('linkeddataelements') ) from Domains where ID = '\" + domaincaseid +\"' )\"\n",
    "    dataelements = execute_query(dataelementsQuery)\n",
    "    #print(dataelements)\n",
    "    scoresQuery = \"select expand(out_linkeddataelements) from Domains where ID = '\"+domaincaseid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    dataelementsList =[]\n",
    "    scoresList= []\n",
    "    for dataelement in dataelements:\n",
    "        dataelementsList.append(dataelement.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(dataelementsList)\n",
    "    #print requirementsList, scoresList\n",
    "    for i in range(0, length):\n",
    "        result[dataelementsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def get_related_user(reqid):\n",
    "    reqQuery = \"select * from Requirements where ID = '\"+reqid+\"'\"\n",
    "    requirements = execute_query(reqQuery)\n",
    "    result = ''\n",
    "    for requirement in requirements:\n",
    "        print(requirement.User)\n",
    "        result = requirement.User\n",
    "    return result\n",
    "\n",
    "def get_related_action(key):\n",
    "    domQuery = \"select * from Domains where ID = '\"+key+\"'\"\n",
    "    domains = execute_query(domQuery)\n",
    "    result = ''\n",
    "    for domain in domains:\n",
    "        print(domain.Action)\n",
    "        result = domain.Action\n",
    "    return result\n",
    "\n",
    "def get_related_shorthand(key):\n",
    "    shortQuery = \"select * from DataElements where ID = '\"+key+\"'\"\n",
    "    shorts = execute_query(shortQuery)\n",
    "    result = ''\n",
    "    for short in shorts:\n",
    "        print(short.Short)\n",
    "        result = short.Short\n",
    "    return result\n",
    "def get_requirement_defects(numdefects):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,Priority from Requirement where out('linkeddefects').size() >= \" + str(numdefects)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    for requirement in requirements:\n",
    "        num = len(get_related_defects(requirement['ID']))\n",
    "        requirement['defectcount'] = num\n",
    "    return requirements \n",
    "def merge_apply_filters_d3_bubble(mainList, filterList):\n",
    "    \"\"\" Add a filter attribute to the list elements for processing on UI\n",
    "    \"\"\"\n",
    "    mainListChildren = mainList['children']\n",
    "    filterListChildren = filterList['children']\n",
    "    for child in mainListChildren:\n",
    "        child['filter'] = 0\n",
    "        for child1 in filterListChildren:\n",
    "            if ( child['ID'] == child1['ID']):\n",
    "                child['filter'] = 1\n",
    "    return mainList\n",
    "\n",
    "def get_requirement_defects(numdefects):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,Priority from Requirement where out('linkeddefects').size() >= \" + str(numdefects)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    for requirement in requirements:\n",
    "        num = len(get_related_defects(requirement['ID']))\n",
    "        requirement['defectcount'] = num\n",
    "    return requirements \n",
    "\n",
    "def get_requirements_banker():\n",
    "    \"\"\" Get requirements that have no defects\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirements where User = 'Banker'\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements\n",
    "def get_requirements_customer():\n",
    "    \"\"\" Get requirements that have no defects\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirements where User = 'Customer'\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements\n",
    "def get_requirement_domain(numde):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,User from Requirements where out('linkeddomains').size() <= \" + str(numde)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Global variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the excel file with data in S3 Storage\n",
    "BrdFileName = \"Banking-BRD.xlsx\"\n",
    "# Choose or get as an input as to which Domain it belongs to i.e banking, healthcare etc\n",
    "Domain = \"Banking\"\n",
    "\n",
    "# Name of the config files in Object Storage. Rule_brd will be used specifically for parsing requirement document\n",
    "configFileName = \"sample_config.txt\"\n",
    "BRD_configFileName = \"Rule_BRD.txt\"\n",
    "# Config contents\n",
    "config = None;\n",
    "\n",
    "Path = \"D:/machine learning/watson-document-co-relation-master/watson-document-co-relation-master/\"\n",
    "# Output excell\n",
    "\n",
    "# Requirements dataframe\n",
    "requirements_file_name = \"data/Requirements.xlsx\"\n",
    "requirements_sheet_name = \"\".join((Domain,\"-Requirements\"))\n",
    "requirements_df = None\n",
    "\n",
    "# Domain/UseCase dataframe\n",
    "domain_file_name = \"data/Domain.xlsx\"\n",
    "domain_sheet_name = \"\".join((Domain,\"-Domain\"))\n",
    "domain_df = None\n",
    "\n",
    "# DataElements dataframe\n",
    "dataelements_file_name =\"data/DataElements.xlsx\"\n",
    "dataelements_sheet_name =\"\".join((Domain,\"-Dataelements\"))\n",
    "dataelements_df = None\n",
    "\n",
    "def load_artifacts():\n",
    "    global requirements_df \n",
    "    global domain_df \n",
    "    global dataelements_df \n",
    "    global config\n",
    "    global BRD_config\n",
    "    global Path\n",
    "    \n",
    "    \n",
    "    Location = \"\".join((Path,requirements_file_name))\n",
    "    get_file(requirements_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    requirements_df = excel.parse(requirements_sheet_name)\n",
    "    Location = \"\".join((Path,domain_file_name))\n",
    "    get_file(domain_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    domain_df = excel.parse(domain_sheet_name)\n",
    "    Location = \"\".join((Path,dataelements_file_name))\n",
    "    get_file(dataelements_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    dataelements_df = excel.parse(dataelements_sheet_name)\n",
    "    rule_text = open(configFileName)\n",
    "    config = rule_text.read()\n",
    "    BRD_rule_text = open(BRD_configFileName)\n",
    "    BRD_config = BRD_rule_text.read()\n",
    "    \n",
    "    \n",
    "\n",
    "def prepare_artifact_dataframes():\n",
    "    \"\"\" Prepare artifact dataframes by creating necessary output columns\n",
    "    \"\"\"\n",
    "    global requirements_df \n",
    "    global domain_df \n",
    "    global dataelements_df \n",
    "    req_cols_len = len(requirements_df.columns)\n",
    "    dom_cols_len = len(domain_df.columns)\n",
    "    dat_cols_len = len(dataelements_df.columns)\n",
    "    requirements_df.insert(req_cols_len, \"ClassifiedText\",\"\")\n",
    "    requirements_df.insert(req_cols_len+1, \"Keywords\",\"\")\n",
    "    requirements_df.insert(req_cols_len+2, \"DomainMatchScore\",\"\")\n",
    "    \n",
    "    domain_df.insert(dom_cols_len, \"ClassifiedText\",\"\")\n",
    "    domain_df.insert(dom_cols_len+1, \"Keywords\",\"\")\n",
    "    domain_df.insert(dom_cols_len+2, \"DataElementsMatchScore\",\"\")\n",
    "\n",
    "    dataelements_df.insert(dat_cols_len, \"ClassifiedText\",\"\")\n",
    "    dataelements_df.insert(dat_cols_len+1, \"Keywords\",\"\")\n",
    "    dataelements_df.insert(dat_cols_len+2, \"RequirementsMatchScore\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Utility functions for Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_req_text_classifier_output(artifact_df, BRD_config, output_column_name):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact_df.iterrows():\n",
    "        summary = row[\"I want to <perform some task>\"]\n",
    "        modID = row[\"ID\"]\n",
    "        \n",
    "        print(modID)\n",
    "        modID = modID.replace(\"R\",\"UC\")\n",
    "        print(modID)\n",
    "        row[\"ID\"]= modID\n",
    "        user = row[\"As a <type of user>\"]\n",
    "        user = \"\".join((user,\" want to \"))\n",
    "        summary = \"\".join((user,summary))\n",
    "        #print(\"--------------\")\n",
    "        #print(summary)\n",
    "        classifier_journey_output = classify_BRD_text(summary, BRD_config)\n",
    "        #print(classifier_journey_output)\n",
    "        artifact_df.set_value(index, output_column_name, classifier_journey_output)\n",
    "    return artifact_df \n",
    "\n",
    "\n",
    "def add_text_classifier_output(artifact_df, config, output_column_name):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact_df.iterrows():\n",
    "        summary = row[\"Description\"]\n",
    "        #print(\"--------------\")\n",
    "        #print(summary)\n",
    "        classifier_journey_output = classify_text(summary, config)\n",
    "        #print(classifier_journey_output)\n",
    "        artifact_df.set_value(index, output_column_name, classifier_journey_output)\n",
    "    return artifact_df \n",
    "           \n",
    "def add_keywords_entities(artifact_df, classify_text_column_name, output_column_name):\n",
    "    \"\"\" Add keywords and entities to the artifact dataframe\"\"\"\n",
    "    for index, artifact in artifact_df.iterrows():\n",
    "        keywords_array = []\n",
    "        for row in artifact[classify_text_column_name]['Keywords']:\n",
    "            #print(row)\n",
    "            if not row['User'] in keywords_array:\n",
    "                keywords_array.append(row['User'])\n",
    "                \n",
    "        for entities in artifact[classify_text_column_name]['Entities']:\n",
    "            if not entities['text'] in keywords_array:\n",
    "                keywords_array.append(entities['text'])\n",
    "            if not entities['type'] in keywords_array:\n",
    "                keywords_array.append(entities['type'])\n",
    "        artifact_df.set_value(index, output_column_name, keywords_array)\n",
    "        #print(keywords_array)\n",
    "    return artifact_df \n",
    "\n",
    "#requirements_df, domain_df, keywords_column_name, output_column_name)\n",
    "\n",
    "def populate_text_similarity_score(artifact_df1, artifact_df2, keywords_column_name, output_column_name):\n",
    "    \"\"\" Populate text similarity score to the artifact dataframes\n",
    "    \"\"\"\n",
    "    heading1 = \"Description\"\n",
    "    heading2 = \"Description\"\n",
    "    \n",
    "    try:\n",
    "        artifact_df1[heading1]\n",
    "    except: \n",
    "        heading1 = \"I want to <perform some task>\"\n",
    "    \n",
    "    try:\n",
    "        artifact_df2[heading2]\n",
    "    except: \n",
    "        heading2 = \"I want to <perform some task>\"    \n",
    "    \n",
    "    \n",
    "    for index1, artifact1 in artifact_df1.iterrows():\n",
    "        matches = []\n",
    "        top_matches = []\n",
    "        for index2, artifact2 in artifact_df2.iterrows():\n",
    "            matches.append({'ID': artifact2['ID'], \n",
    "                            'cosine_score': 0, \n",
    "                            'SubjectID':artifact1['ID']})\n",
    "            cosine_score = compute_text_similarity(\n",
    "                #artifact1['Description'], \n",
    "                #artifact2['Description'], \n",
    "                artifact1[heading1],\n",
    "                artifact2[heading2],\n",
    "                artifact1['Keywords'], \n",
    "                artifact2['Keywords'])\n",
    "            matches[index2][\"cosine_score\"] = cosine_score\n",
    "       \n",
    "        sorted_obj = sorted(matches, key=lambda x : x['cosine_score'], reverse=True)\n",
    "    \n",
    "    # This is where the lower cosine value to be truncated is set and needs to be adjusted based on output\n",
    "    \n",
    "        for obj in sorted_obj:\n",
    "            if obj['cosine_score'] > 0.6:\n",
    "                top_matches.append(obj)\n",
    "               \n",
    "        artifact_df1.set_value(index1, output_column_name, top_matches)\n",
    "    return artifact_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prepare data **\n",
    "* Load artifacts from object storage and create pandas dataframes\n",
    "* Prepare the pandas dataframes. Add additional columns required for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_artifacts()\n",
    "prepare_artifact_dataframes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run Text Classification on data **\n",
    "* Add the text classification output to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R01\n",
      "UC01\n",
      "R02\n",
      "UC02\n",
      "R03\n",
      "UC03\n",
      "R04\n",
      "UC04\n",
      "R05\n",
      "UC05\n",
      "R06\n",
      "UC06\n",
      "R07\n",
      "UC07\n",
      "R08\n",
      "UC08\n",
      "R09\n",
      "UC09\n",
      "R10\n",
      "UC10\n",
      "R11\n",
      "UC11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>As a &lt;type of user&gt;</th>\n",
       "      <th>I want to &lt;perform some task&gt;</th>\n",
       "      <th>so that I can &lt;achieve some goal&gt;</th>\n",
       "      <th>ClassifiedText</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DomainMatchScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC01</td>\n",
       "      <td>Customer</td>\n",
       "      <td>deposit cheque in customer name in customer ac...</td>\n",
       "      <td>I want to increase my bank balance</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC02</td>\n",
       "      <td>Customer</td>\n",
       "      <td>withdraw cash from an ATM</td>\n",
       "      <td>I don't have to wait in line at the Bank</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC03</td>\n",
       "      <td>Customer</td>\n",
       "      <td>want to transfer money from one account to ano...</td>\n",
       "      <td>I don't need to pay the amount in person</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC04</td>\n",
       "      <td>Customer</td>\n",
       "      <td>pay my utility bills online</td>\n",
       "      <td>I don't need to write checks or use postal ser...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC05</td>\n",
       "      <td>Customer</td>\n",
       "      <td>apply for a loan</td>\n",
       "      <td>purchase a car</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID As a <type of user>  \\\n",
       "0  UC01            Customer   \n",
       "1  UC02            Customer   \n",
       "2  UC03            Customer   \n",
       "3  UC04            Customer   \n",
       "4  UC05            Customer   \n",
       "\n",
       "                       I want to <perform some task>  \\\n",
       "0  deposit cheque in customer name in customer ac...   \n",
       "1                          withdraw cash from an ATM   \n",
       "2  want to transfer money from one account to ano...   \n",
       "3                        pay my utility bills online   \n",
       "4                                   apply for a loan   \n",
       "\n",
       "                   so that I can <achieve some goal>  \\\n",
       "0                 I want to increase my bank balance   \n",
       "1           I don't have to wait in line at the Bank   \n",
       "2           I don't need to pay the amount in person   \n",
       "3  I don't need to write checks or use postal ser...   \n",
       "4                                     purchase a car   \n",
       "\n",
       "                                      ClassifiedText Keywords DomainMatchScore  \n",
       "0  {'Keywords': [{'User': ''}, {'User': 'Customer...                            \n",
       "1  {'Keywords': [{'User': ''}, {'User': 'Customer...                            \n",
       "2  {'Keywords': [{'User': ''}, {'User': 'Customer...                            \n",
       "3  {'Keywords': [{'User': ''}, {'User': 'Customer...                            \n",
       "4  {'Keywords': [{'User': ''}, {'User': 'Customer...                            "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_column_name = \"ClassifiedText\"\n",
    "requirements_df = mod_req_text_classifier_output(requirements_df, BRD_config, output_column_name)\n",
    "\n",
    "domain_df = add_text_classifier_output(domain_df,config, output_column_name)\n",
    "dataelements_df = add_text_classifier_output(dataelements_df,config, output_column_name)\n",
    "\n",
    "requirements_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Populate keywords and entities **\n",
    "* Add the keywords and entities extracted from the unstructured text to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "classify_text_column_name = \"ClassifiedText\"\n",
    "output_column_name = \"Keywords\"\n",
    "requirements_df = add_keywords_entities(requirements_df, classify_text_column_name, output_column_name)\n",
    "domain_df = add_keywords_entities(domain_df, classify_text_column_name, output_column_name)\n",
    "dataelements_df = add_keywords_entities(dataelements_df, classify_text_column_name, output_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Correlate keywords between artifacts **\n",
    "* Add the text similarity score of associated artifacts to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "keywords_column_name = \"Keywords\"\n",
    "output_column_name = \"DomainMatchScore\"\n",
    "requirements_df = populate_text_similarity_score(requirements_df, domain_df, keywords_column_name, output_column_name)\n",
    "\n",
    "output_column_name = \"DataElementsMatchScore\"\n",
    "domain_df = populate_text_similarity_score(domain_df, dataelements_df, keywords_column_name, output_column_name)\n",
    "\n",
    "output_column_name = \"RequirementsMatchScore\"\n",
    "dataelements_df = populate_text_similarity_score(dataelements_df, requirements_df, keywords_column_name, output_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section will be used to create the Output in excell format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action(summary):\n",
    "    action_string = \"\"\n",
    "    count = 1\n",
    "    for entities in summary['Entities']:\n",
    "        #print(entities['text'])\n",
    "        if not entities['text'] in action_string:\n",
    "                action_string = action_string + entities['text']\n",
    "                count = count + 1\n",
    "                if count == 2:\n",
    "                    count = 1\n",
    "                    action_string = action_string + \",\"\n",
    "    \n",
    "    #print(action_string)\n",
    "    return action_string\n",
    "\n",
    "def lookup_use_case(temp,artifact3_df,column_name):\n",
    "    #print(artifact3_df.get_value(0,'ID'))\n",
    "    val = \"\"\n",
    "    rowNum = len(artifact3_df.index)\n",
    "    #print(rowNum)\n",
    "    for j in range(0,rowNum):\n",
    "        if temp == artifact3_df.get_value(j,'ID'):\n",
    "            val = artifact3_df.get_value(j,column_name)\n",
    "            #print(val)\n",
    "    \n",
    "    return val       \n",
    "        \n",
    "    \n",
    "def extract_match(summary,no_of_matches,artifact3_df,column_name):\n",
    "    match_array_description = []\n",
    "    match_array_id = []\n",
    "    for index in range(0,no_of_matches):\n",
    "        try:\n",
    "            temp = summary[index][\"ID\"]\n",
    "            \n",
    "        except:\n",
    "              break\n",
    "    \n",
    "            \n",
    "        temp = summary[index][\"ID\"]\n",
    "        #print(temp)\n",
    "        use_case = lookup_use_case(temp,artifact3_df,column_name)\n",
    "        \n",
    "        match_array_id.append(temp)\n",
    "        #match_array_description.append(use_case + \"(\" + str(round(summary[index][\"cosine_score\"], 2)) +\")\")\n",
    "        match_array_description.append(use_case)\n",
    "        #print(use_case)\n",
    "            \n",
    "    \n",
    "    #print(\"************\")\n",
    "    #print(match_array_id)       \n",
    "    #print(\"************\")\n",
    "    return (match_array_description,match_array_id)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def extract_action_requirements_df(artifact1_df, artifact2_df):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact2_df.iterrows():\n",
    "        summary = row[\"ClassifiedText\"]\n",
    "        classifier_journey_output = extract_action(summary)\n",
    "        artifact1_df.set_value(index, 'Use Case', classifier_journey_output)\n",
    "    return artifact1_df \n",
    "\n",
    "def extract_bestmatch(artifact1_df, artifact2_df, artifact3_df, artifact4_df):\n",
    "    \"\"\" Extract best Match\n",
    "    \"\"\"\n",
    "    No_of_matches_user_function = 2\n",
    "    No_of_matches_data_elements = 8\n",
    "    best_match_output_domain_function = []\n",
    "    best_match_output_dataelement_function = []\n",
    "    \n",
    "    for index, row in artifact2_df.iterrows():\n",
    "        summary = row[\"DomainMatchScore\"]\n",
    "        #print(summary)\n",
    "        (best_match_output_domain_function,best_match_output_domain_id) = extract_match(summary, No_of_matches_user_function, artifact3_df,\"User Function\")\n",
    "        #print(best_match_output_domain_id)\n",
    "        artifact1_df.set_value(index, 'Functionality', best_match_output_domain_function)\n",
    "        print(\"************\")\n",
    "        for index2 in best_match_output_domain_id:\n",
    "            #print(index2)\n",
    "        \n",
    "            row_domain = len(artifact3_df.index)\n",
    "            for p in range(0,row_domain):\n",
    "                if index2 == artifact3_df.get_value(p,'ID'):\n",
    "                    dataelement_summary = artifact3_df.get_value(p,'DataElementsMatchScore')\n",
    "                    #print(dataelement_summary)\n",
    "                    #print(\"------\")\n",
    "                    (best_match_output_dataelement_function,best_match_output_dataelement_id) = extract_match(dataelement_summary, No_of_matches_data_elements, artifact4_df, \"Short\")\n",
    "            \n",
    "            \n",
    "            #best_match_output_dataelement_function.append(best_match_output_dataelement_function)\n",
    "            best_match_output_dataelement_function.extend(best_match_output_dataelement_function)\n",
    "            print(best_match_output_dataelement_function)\n",
    "          \n",
    "        #print(best_match_output_dataelement_function)\n",
    "        #print(\"==============\")\n",
    "        #print(index)\n",
    "        best_match_output_dataelement_function = list(set(best_match_output_dataelement_function))\n",
    "        artifact1_df.set_value(index, 'Attributes', best_match_output_dataelement_function)\n",
    "    return artifact1_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "['From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type', 'From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type']\n",
      "['Debit_pin', 'Acc_type', 'Acc_num', 'Bill_type', 'From_AcctNum', 'To_AcctNum', 'Cus_Nme', 'Amt_avail', 'Debit_pin', 'Acc_type', 'Acc_num', 'Bill_type', 'From_AcctNum', 'To_AcctNum', 'Cus_Nme', 'Amt_avail']\n",
      "************\n",
      "['From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type', 'From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type']\n",
      "['Bill_type', 'Max_limit', 'Amt_wdrl', 'Amt_deposit', 'Debit_pin', 'Amt_trnsfr', 'Acc_type', 'Bill_type', 'Max_limit', 'Amt_wdrl', 'Amt_deposit', 'Debit_pin', 'Amt_trnsfr', 'Acc_type']\n",
      "************\n",
      "['From_AcctNum', 'To_AcctNum', 'Acc_type', 'Amt_trnsfr', 'Cus_Nme', 'Bill_type', 'Acc_num', 'Amt_wdrl', 'From_AcctNum', 'To_AcctNum', 'Acc_type', 'Amt_trnsfr', 'Cus_Nme', 'Bill_type', 'Acc_num', 'Amt_wdrl']\n",
      "['From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type', 'From_AcctNum', 'To_AcctNum', 'Debit_pin', 'Cus_Nme', 'Acc_num', 'Bill_type', 'Amt_deposit', 'Acc_type']\n",
      "************\n",
      "['Acc_num', 'Amt_wdrl', 'Bill_type', 'Acc_type', 'Amt_deposit', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr', 'Acc_num', 'Amt_wdrl', 'Bill_type', 'Acc_type', 'Amt_deposit', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr']\n",
      "['Bill_type', 'Max_limit', 'Amt_deposit', 'Amt_wdrl', 'Acc_num', 'Debit_pin', 'Cust_Addr', 'Bill_type', 'Max_limit', 'Amt_deposit', 'Amt_wdrl', 'Acc_num', 'Debit_pin', 'Cust_Addr']\n",
      "************\n",
      "['Loan_Amt', 'Loan_purp', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr', 'Loan_Amt', 'Loan_purp', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr']\n",
      "['Cred_Score', 'Loan_Amt', 'Amt_avail', 'Cust_Addr', 'Cred_Score', 'Loan_Amt', 'Amt_avail', 'Cust_Addr']\n",
      "************\n",
      "['Amt_deposit', 'Amt_wdrl', 'Acc_num', 'Bill_type', 'Cust_Addr', 'Amt_deposit', 'Amt_wdrl', 'Acc_num', 'Bill_type', 'Cust_Addr']\n",
      "************\n",
      "['Bill_type', 'Debit_pin', 'Amt_deposit', 'Max_limit', 'Amt_wdrl', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr', 'Bill_type', 'Debit_pin', 'Amt_deposit', 'Max_limit', 'Amt_wdrl', 'From_AcctNum', 'To_AcctNum', 'Amt_trnsfr']\n",
      "['Amt_wdrl', 'Amt_deposit', 'Max_limit', 'Amt_trnsfr', 'Bill_type', 'Loan_Amt', 'Debit_pin', 'Cus_Nme', 'Amt_wdrl', 'Amt_deposit', 'Max_limit', 'Amt_trnsfr', 'Bill_type', 'Loan_Amt', 'Debit_pin', 'Cus_Nme']\n",
      "************\n",
      "['Amt_wdrl', 'Amt_deposit', 'Max_limit', 'Amt_trnsfr', 'Bill_type', 'Loan_Amt', 'Debit_pin', 'Cus_Nme', 'Amt_wdrl', 'Amt_deposit', 'Max_limit', 'Amt_trnsfr', 'Bill_type', 'Loan_Amt', 'Debit_pin', 'Cus_Nme']\n",
      "['Bill_type', 'Max_limit', 'Amt_wdrl', 'Amt_deposit', 'Debit_pin', 'Amt_trnsfr', 'Acc_type', 'Bill_type', 'Max_limit', 'Amt_wdrl', 'Amt_deposit', 'Debit_pin', 'Amt_trnsfr', 'Acc_type']\n",
      "************\n",
      "['Bill_type', 'Bill_type']\n",
      "['From_AcctNum', 'To_AcctNum', 'Acc_num', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'Acc_type', 'Amt_avail', 'From_AcctNum', 'To_AcctNum', 'Acc_num', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'Acc_type', 'Amt_avail']\n",
      "************\n",
      "['From_AcctNum', 'To_AcctNum', 'Acc_num', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'Acc_type', 'Amt_avail', 'From_AcctNum', 'To_AcctNum', 'Acc_num', 'Amt_wdrl', 'Debit_pin', 'Amt_deposit', 'Acc_type', 'Amt_avail']\n",
      "['Cred_Score', 'Loan_Amt', 'Amt_avail', 'Cust_Addr', 'Cred_Score', 'Loan_Amt', 'Amt_avail', 'Cust_Addr']\n",
      "************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:87: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:102: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Acc_num',\n",
       " 'Debit_pin',\n",
       " 'Amt_avail',\n",
       " 'From_AcctNum',\n",
       " 'Acc_type',\n",
       " 'Bill_type',\n",
       " 'To_AcctNum',\n",
       " 'Cus_Nme']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "no_of_rows_brd = len(requirements_df.index)\n",
    "\n",
    "index = range(0,no_of_rows_brd)\n",
    "columns = ['User','Use Case', 'Functionality', 'Attributes']\n",
    "\n",
    "\n",
    "SimMean = pd.DataFrame(index=index, columns=columns)\n",
    "SimMean.loc[0:no_of_rows_brd,'User'] = requirements_df.loc[0:no_of_rows_brd,'As a <type of user>'].values\n",
    "SimMean = extract_action_requirements_df(SimMean,requirements_df)\n",
    "SimMean = extract_bestmatch(SimMean,requirements_df,domain_df,dataelements_df)\n",
    "#SimMean = extract_bestmatch_domaintodataelem(SimMean,domain_df)\n",
    "SimMean.get_value(0,\"Attributes\")\n",
    "#print(SimMean)\n",
    "\n",
    "#writer = pd.ExcelWriter('final_output_banking.xlsx', engine='xlsxwriter')\n",
    "#SimMean.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"*\"**********************************************************\"\n",
    "# Next steps :\n",
    "\n",
    "* Populate the correct wording in 3 sheets to provide more accurate and insightful data\n",
    "* Use OrientdB to graph the result of cosine\n",
    "* Use Node Red to start a UI dashboard\n",
    "* Optmize code to reduce memory usage\n",
    "* Move the components like Notebook,OrientDB etc to EC2 AWS ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utility functions to store entities and relations in Orient DB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_requirements(requirements_df):\n",
    "    \"\"\" Store requirements into the database\n",
    "    \"\"\"\n",
    "    for index, row in requirements_df.iterrows():\n",
    "        attrs = {}\n",
    "        reqid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"I want to <perform some task>\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = reqid\n",
    "        attrs[\"User\"]= str(row[\"As a <type of user>\"])\n",
    "        create_record(requirement_classname, reqid, attrs)    \n",
    "        \n",
    "def store_domain(domain_df):  \n",
    "    \"\"\" Store domain which has user functions into the database\n",
    "    \"\"\"\n",
    "    for index, row in domain_df.iterrows():\n",
    "        attrs = {}\n",
    "        tcaseid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"Description\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = tcaseid\n",
    "        attrs[\"Action\"] = str(row[\"User Function\"])\n",
    "        create_record(domain_classname, tcaseid, attrs)\n",
    "        \n",
    "def store_dataelements(dataelements_df):\n",
    "    \"\"\" Store data elements or attributes into the database\n",
    "    \"\"\"\n",
    "    for index, row in dataelements_df.iterrows():\n",
    "        attrs = {}\n",
    "        defid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"Description\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = defid\n",
    "        attrs[\"Short\"] = str(row[\"Short\"])\n",
    "        create_record(dataelement_classname, defid, attrs)\n",
    "        \n",
    "def store_dataelements_requirement_mapping(dataelements_df):\n",
    "    \"\"\" Store the related requirements for testcases into the database\n",
    "    \"\"\"\n",
    "    for index, row in dataelements_df.iterrows():\n",
    "        tcaseid = row[\"ID\"]\n",
    "        requirements = row[\"RequirementsMatchScore\"]\n",
    "        for requirement in requirements:\n",
    "            reqid = requirement[\"ID\"]\n",
    "            attributes = {}\n",
    "            attributes['score'] = requirement['cosine_score']\n",
    "            create_dataelements_requirement_edge(tcaseid,reqid, attributes)\n",
    "            \n",
    "def store_domain_dataelement_mapping(domain_df):\n",
    "    \"\"\" Store the related dataelement for the domain into the database\n",
    "    \"\"\"\n",
    "    for index, row in domain_df.iterrows():\n",
    "        domainid = row[\"ID\"]\n",
    "        dataelements = row[\"DataElementsMatchScore\"]\n",
    "        count = 0\n",
    "        #print(\"---------\")\n",
    "        for dataelement in dataelements:\n",
    "            \n",
    "            if count < 4:\n",
    "                dataelementid = dataelement[\"ID\"]\n",
    "                attributes = {}\n",
    "                attributes['score'] = dataelement[\"cosine_score\"]\n",
    "                create_domain_dataelements_edge(domainid,dataelementid, attributes)\n",
    "                count = count + 1\n",
    "            \n",
    "def store_requirement_domain_mapping(requirements_df):\n",
    "    \"\"\" Store the related domains for the requirements in the database\n",
    "    \"\"\"\n",
    "    for index, row in requirements_df.iterrows():\n",
    "        count = 0\n",
    "        reqid = row[\"ID\"]\n",
    "        functionalities = row[\"DomainMatchScore\"]\n",
    "        #print(\"----------\") \n",
    "        for functionality in functionalities:\n",
    "            \n",
    "            if count < 2:  \n",
    "                functionalityID = functionality[\"ID\"]\n",
    "                cosine_score =  functionality[\"cosine_score\"]\n",
    "                attributes = {}\n",
    "                attributes['score'] = cosine_score\n",
    "                create_requirement_domain_edge(reqid, functionalityID, attributes)\n",
    "                count = count + 1\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Store artifacts data and relations into OrientDB **\n",
    "* Drop and create a database\n",
    "* Create classes for each category of artifact\n",
    "* Store artifact data\n",
    "* Store artifact relations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftwareDesignAI created and opened successfully\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC01') to (select from Domains where ID = 'Fn1') set score = '0.8819171036881969'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC01') to (select from Domains where ID = 'Fn25') set score = '0.8819171036881969'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC02') to (select from Domains where ID = 'Fn1') set score = '0.7559289460184544'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC02') to (select from Domains where ID = 'Fn4') set score = '0.7559289460184544'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC03') to (select from Domains where ID = 'Fn3') set score = '0.7745966692414834'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC03') to (select from Domains where ID = 'Fn1') set score = '0.6324555320336759'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC04') to (select from Domains where ID = 'Fn14') set score = '0.8660254037844387'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC04') to (select from Domains where ID = 'Fn16') set score = '0.7071067811865475'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC05') to (select from Domains where ID = 'Fn5') set score = '0.8164965809277261'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC05') to (select from Domains where ID = 'Fn7') set score = '0.8164965809277261'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC06') to (select from Domains where ID = 'Fn15') set score = '0.6546536707079772'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC07') to (select from Domains where ID = 'Fn6') set score = '0.6666666666666666'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC07') to (select from Domains where ID = 'Fn10') set score = '0.6666666666666666'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC08') to (select from Domains where ID = 'Fn10') set score = '0.7453559924999299'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC08') to (select from Domains where ID = 'Fn4') set score = '0.6666666666666666'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC09') to (select from Domains where ID = 'Fn9') set score = '0.7071067811865475'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC09') to (select from Domains where ID = 'Fn2') set score = '0.6123724356957945'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC10') to (select from Domains where ID = 'Fn2') set score = '0.7071067811865476'\n",
      "create edge linkeddomains from (select from Requirements where ID = 'UC10') to (select from Domains where ID = 'Fn7') set score = '0.7071067811865476'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn1') to (select from DataElements where ID = 'DE5') set score = '0.8660254037844387'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn1') to (select from DataElements where ID = 'DE6') set score = '0.8660254037844387'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn1') to (select from DataElements where ID = 'DE4') set score = '0.8498365855987976'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn1') to (select from DataElements where ID = 'DE1') set score = '0.8451542547285166'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn2') to (select from DataElements where ID = 'DE5') set score = '0.7905694150420948'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn2') to (select from DataElements where ID = 'DE6') set score = '0.7905694150420948'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn2') to (select from DataElements where ID = 'DE2') set score = '0.780189497605494'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn2') to (select from DataElements where ID = 'DE12') set score = '0.7745966692414834'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn3') to (select from DataElements where ID = 'DE5') set score = '0.9682458365518541'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn3') to (select from DataElements where ID = 'DE6') set score = '0.9013878188659974'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn3') to (select from DataElements where ID = 'DE8') set score = '0.7745966692414834'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn3') to (select from DataElements where ID = 'DE11') set score = '0.7637626158259734'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn4') to (select from DataElements where ID = 'DE9') set score = '0.8770580193070293'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn4') to (select from DataElements where ID = 'DE10') set score = '0.8744746321952063'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn4') to (select from DataElements where ID = 'DE12') set score = '0.7745966692414834'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn4') to (select from DataElements where ID = 'DE7') set score = '0.7453559924999299'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn5') to (select from DataElements where ID = 'DE14') set score = '0.7745966692414833'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn5') to (select from DataElements where ID = 'DE15') set score = '0.7302967433402213'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn5') to (select from DataElements where ID = 'DE12') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn5') to (select from DataElements where ID = 'DE4') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn6') to (select from DataElements where ID = 'DE9') set score = '0.8770580193070293'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn6') to (select from DataElements where ID = 'DE4') set score = '0.74535599249993'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn6') to (select from DataElements where ID = 'DE7') set score = '0.7453559924999299'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn6') to (select from DataElements where ID = 'DE10') set score = '0.727606875108999'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn7') to (select from DataElements where ID = 'DE16') set score = '0.7817359599705717'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn7') to (select from DataElements where ID = 'DE14') set score = '0.6831300510639732'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn7') to (select from DataElements where ID = 'DE3') set score = '0.6030226891555273'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn7') to (select from DataElements where ID = 'DE13') set score = '0.6030226891555273'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn8') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn8') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn8') to (select from DataElements where ID = 'DE14') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn8') to (select from DataElements where ID = 'DE2') set score = '0.6255432421712244'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn9') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn10') to (select from DataElements where ID = 'DE12') set score = '0.7745966692414834'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn10') to (select from DataElements where ID = 'DE7') set score = '0.7453559924999299'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn10') to (select from DataElements where ID = 'DE10') set score = '0.727606875108999'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn10') to (select from DataElements where ID = 'DE11') set score = '0.7071067811865476'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn11') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create edge linkeddataelements from (select from Domains where ID = 'Fn11') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn11') to (select from DataElements where ID = 'DE9') set score = '0.6201736729460423'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn12') to (select from DataElements where ID = 'DE2') set score = '0.7518094115561125'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn12') to (select from DataElements where ID = 'DE7') set score = '0.7453559924999299'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn12') to (select from DataElements where ID = 'DE8') set score = '0.7416198487095663'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn12') to (select from DataElements where ID = 'DE12') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn13') to (select from DataElements where ID = 'DE12') set score = '0.7745966692414834'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn13') to (select from DataElements where ID = 'DE7') set score = '0.7453559924999299'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn13') to (select from DataElements where ID = 'DE11') set score = '0.7071067811865476'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn13') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn14') to (select from DataElements where ID = 'DE2') set score = '0.7223151185146154'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn14') to (select from DataElements where ID = 'DE12') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn14') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn14') to (select from DataElements where ID = 'DE8') set score = '0.6708203932499369'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn15') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn15') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn15') to (select from DataElements where ID = 'DE2') set score = '0.6255432421712244'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn15') to (select from DataElements where ID = 'DE9') set score = '0.6201736729460423'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn16') to (select from DataElements where ID = 'DE9') set score = '0.7337993857053429'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn16') to (select from DataElements where ID = 'DE10') set score = '0.6859943405700353'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn16') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn16') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn17') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn17') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn17') to (select from DataElements where ID = 'DE2') set score = '0.6255432421712244'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn17') to (select from DataElements where ID = 'DE9') set score = '0.6201736729460423'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn18') to (select from DataElements where ID = 'DE7') set score = '0.6666666666666666'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn18') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn18') to (select from DataElements where ID = 'DE14') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn20') to (select from DataElements where ID = 'DE13') set score = '0.6030226891555273'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn21') to (select from DataElements where ID = 'DE5') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn21') to (select from DataElements where ID = 'DE6') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn21') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn21') to (select from DataElements where ID = 'DE12') set score = '0.6324555320336759'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn22') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn25') to (select from DataElements where ID = 'DE4') set score = '0.7071067811865476'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn25') to (select from DataElements where ID = 'DE8') set score = '0.7071067811865475'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn25') to (select from DataElements where ID = 'DE2') set score = '0.6915640748081248'\n",
      "create edge linkeddataelements from (select from Domains where ID = 'Fn25') to (select from DataElements where ID = 'DE9') set score = '0.6793662204867575'\n"
     ]
    }
   ],
   "source": [
    "drop_database(\"SoftwareDesignAI\")\n",
    "create_database(\"SoftwareDesignAI\", \"admin\", \"admin\")\n",
    "\n",
    "requirement_classname = \"Requirements\"\n",
    "domain_classname = \"Domains\"\n",
    "dataelement_classname = \"DataElements\"\n",
    "\n",
    "create_class(requirement_classname)\n",
    "create_class(domain_classname)\n",
    "create_class(dataelement_classname)\n",
    "\n",
    "\n",
    "\n",
    "store_requirements(requirements_df)\n",
    "store_dataelements(dataelements_df)\n",
    "store_domain(domain_df)\n",
    "\n",
    "\n",
    "store_requirement_domain_mapping(requirements_df)\n",
    "store_domain_dataelement_mapping(domain_df)\n",
    "store_dataelements_requirement_mapping(dataelements_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform results for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artifacts_mapping_d3_tree(defectId):\n",
    "    \"\"\" Create an artifacts mapping json for display by d3js tree widget\n",
    "    \"\"\"\n",
    "    depTree = {}\n",
    "    depTree['ID'] = defectId\n",
    "    testcases = get_related_testcases(defectId)\n",
    "    \n",
    "    depTree['children'] = []\n",
    "    i=1\n",
    "    for key in testcases:\n",
    "        #print key,testcases[key]\n",
    "        testcaseChildren = {}\n",
    "        testcaseChildren['ID'] = key\n",
    "        testcaseChildren['Score'] = testcases[key]\n",
    "        testcaseChildren['children'] = []\n",
    "        depTree['children'].append(testcaseChildren)\n",
    "        requirements = get_related_requirements(key)\n",
    "        \n",
    "        for key in requirements:\n",
    "            requirementChildren = {}\n",
    "            requirementChildren['ID']=key\n",
    "            requirementChildren['Score']=requirements[key]\n",
    "            testcaseChildren['children'].append(requirementChildren)\n",
    "    return depTree \n",
    "\n",
    "def get_artifacts_mapping_d3_network(reqid):\n",
    "    \"\"\" Create an artifacts mapping json for display by d3js network widget\n",
    "    \"\"\"\n",
    "    nodes =[]\n",
    "    links =[] \n",
    "    req = {}\n",
    "    req['id'] = reqid\n",
    "    req['group'] = 1\n",
    "    nodes.append(req)\n",
    "    \n",
    "    domaincases = get_related_domaincases(reqid)\n",
    "    \n",
    "    for key in domaincases:\n",
    "        domaincase ={}\n",
    "        domaincaseid = key\n",
    "        domaincase['id'] = domaincaseid\n",
    "        domaincase['group'] = 2\n",
    "        if domaincase not in nodes:\n",
    "            nodes.append(domaincase)\n",
    "        link = {}\n",
    "        link['source'] = reqid\n",
    "        link['target']=domaincaseid\n",
    "        link['value']=domaincases[domaincaseid]\n",
    "        links.append(link)\n",
    "        dataelements = get_related_dataelements(key)\n",
    "        for key in dataelements:\n",
    "            dataelement ={}\n",
    "            dataelement['id'] = key\n",
    "            dataelement['group'] = 3\n",
    "            if dataelement not in nodes:\n",
    "                nodes.append(dataelement)\n",
    "            link = {}\n",
    "            link['source'] = domaincaseid\n",
    "            link['target'] = key\n",
    "            link['value'] = dataelements[key]\n",
    "            links.append(link)\n",
    "            \n",
    "    result ={}\n",
    "    result[\"nodes\"] = nodes\n",
    "    result[\"links\"] = links\n",
    "    return result\n",
    "\n",
    "def get_tc_req_mapping_d3_network(testcaseid):\n",
    "    \"\"\" Create a testcases to requirement mapping json for display by d3js network widget\n",
    "    \"\"\"\n",
    "    nodes =[]\n",
    "    links =[] \n",
    "    testcase = {}\n",
    "    testcase['id'] = testcaseid\n",
    "    testcase['group'] = 2\n",
    "    nodes.append(testcase)\n",
    "    requirements = get_related_requirements(testcaseid)\n",
    "    for key in requirements:            \n",
    "        requirement ={}\n",
    "        requirement['id'] = key\n",
    "        requirement['group'] = 3\n",
    "        nodes.append(requirement)\n",
    "            \n",
    "        link = {}\n",
    "        link['source'] = testcaseid\n",
    "        link['target'] = key\n",
    "        link['value'] = requirements[key]\n",
    "        links.append(link)\n",
    "    result ={}\n",
    "    result[\"nodes\"] = nodes\n",
    "    result[\"links\"] = links\n",
    "    return result\n",
    "\n",
    "def transform_defects_d3_bubble(defects):\n",
    "    \"\"\" Transform the defects list output to a json for display by d3js bubble chart\"\"\"\n",
    "    defectsList = {}\n",
    "    defectsList['name'] = \"defect\"\n",
    "    children = []\n",
    "    for defect in defects:\n",
    "        detail = {}\n",
    "        sizeList = [400,230,130]\n",
    "        detail[\"ID\"] = defect['ID']\n",
    "        severity = int(defect['Severity'])\n",
    "        detail[\"group\"] = str(severity)\n",
    "        detail[\"size\"] = sizeList[severity-1]\n",
    "        children.append(detail)\n",
    "    defectsList['children'] = children \n",
    "    return defectsList\n",
    "\n",
    "def transform_testcases_d3_bubble(testcases):\n",
    "    \"\"\" Transform the testcases list output to a json for display by d3js bubble chart\"\"\"\n",
    "    testcasesList = {}\n",
    "    testcasesList['name'] = \"test\"\n",
    "    sizeList = {}\n",
    "    sizeList[\"FVT\"]=200\n",
    "    sizeList[\"TVT\"]=110\n",
    "    sizeList[\"SVT\"]=400\n",
    "    children = []\n",
    "    for testcase in testcases:\n",
    "        detail = {}\n",
    "        detail[\"ID\"] = testcase['ID']\n",
    "        detail[\"group\"] = testcase['Category']\n",
    "        detail[\"size\"]= sizeList[testcase['Category']]\n",
    "        children.append(detail)\n",
    "    testcasesList['children'] = children \n",
    "    return testcasesList\n",
    "\n",
    "def transform_requirements_d3_bubble(requirements):\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"requirement\"\n",
    "    sizeList = {}\n",
    "    sizeList[1]=300\n",
    "    sizeList[2]=100\n",
    "    sizeList[3]=75\n",
    "    children = []\n",
    "    for requirement in requirements:\n",
    "        detail = {}\n",
    "        size = 0\n",
    "        detail[\"ID\"] = requirement['ID']\n",
    "        detail[\"group\"] = requirement['User']\n",
    "        if requirement['User'] == 'Customer':\n",
    "            size = 2\n",
    "        elif requirement['User'] == 'Banker':\n",
    "            size = 3\n",
    "        else:\n",
    "            size = 1\n",
    "        detail[\"size\"]= sizeList[size]\n",
    "        if 'defectcount' in requirement:\n",
    "            detail['defectcount'] = requirement['defectcount']\n",
    "        children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "def merge_apply_filters_d3_bubble(mainList, filterList):\n",
    "    \"\"\" Add a filter attribute to the list elements for processing on UI\n",
    "    \"\"\"\n",
    "    mainListChildren = mainList['children']\n",
    "    filterListChildren = filterList['children']\n",
    "    for child in mainListChildren:\n",
    "        child['filter'] = 0\n",
    "        for child1 in filterListChildren:\n",
    "            if ( child['ID'] == child1['ID']):\n",
    "                child['filter'] = 1\n",
    "    return mainList  \n",
    "\n",
    "def setup_download_excel():\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    \n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"download\"\n",
    "    children = []\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"final_output.xlsx\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"excel_download.jpg\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following snippet is for temporary purpose and will be used to check server side programing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"forCmd\": \"GetExcel\",\n",
      "  \"response\": {\n",
      "    \"name\": \"download\",\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"filename\": \"final_output.xlsx\",\n",
      "        \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
      "      },\n",
      "      {\n",
      "        \"filename\": \"excel_download.jpg\",\n",
      "        \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def build_format_requirements_list(requirementsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for requirements\n",
    "    \"\"\"\n",
    "    requirements = []\n",
    "    for requirement in requirementsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] =requirement.ID\n",
    "        detail['Description'] = requirement.Description\n",
    "        detail['User'] = requirement.User\n",
    "        requirements.append(detail)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements():\n",
    "    \"\"\" Get all requirements\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from Requirements\"\n",
    "    requirementsResult =  execute_query(requirementsQuery)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "def transform_requirements_d3_bubble(requirements):\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"requirement\"\n",
    "    sizeList = {}\n",
    "    sizeList[1]=300\n",
    "    sizeList[2]=100\n",
    "    sizeList[3]=75\n",
    "    children = []\n",
    "    for requirement in requirements:\n",
    "        detail = {}\n",
    "        size = 0\n",
    "        detail[\"ID\"] = requirement['ID']\n",
    "        detail[\"group\"] = requirement['User']\n",
    "        if requirement['User'] == 'Customer':\n",
    "            size = 2\n",
    "        elif requirement['User'] == 'Banker':\n",
    "            size = 3\n",
    "        else:\n",
    "            size = 1\n",
    "        detail[\"size\"]= sizeList[size]\n",
    "        if 'defectcount' in requirement:\n",
    "            detail['defectcount'] = requirement['defectcount']\n",
    "        children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "\n",
    "#wsresponse = {}\n",
    "#wsresponse[\"forCmd\"] = \"ReqsList\"\n",
    "#requirements = get_requirements()\n",
    "#wsresponse[\"response\"] = transform_requirements_d3_bubble(requirements)\n",
    "#print(json.dumps(wsresponse, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "def setup_download_excel():\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    \n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"download\"\n",
    "    children = []\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"final_output.xlsx\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"excel_download.jpg\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "wsresponse = {}\n",
    "wsresponse[\"forCmd\"] = \"GetExcel\"\n",
    "wsresponse[\"response\"] = setup_download_excel()\n",
    "\n",
    "print(json.dumps(wsresponse, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Expose integration point with a websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "1 - nodes\n",
      "[{'id': 'R01', 'group': 1, 'desc': ''}]\n",
      "2 - domaincases\n",
      "{}\n",
      "***** final response ******\n",
      "{\"forCmd\": \"AllRelation\", \"response\": {\"nodes\": [{\"id\": \"R01\", \"group\": 1, \"desc\": \"\"}], \"links\": []}}\n"
     ]
    }
   ],
   "source": [
    "def get_related_domaincases(reqid):\n",
    "    \"\"\" Get the related domaincases for a requirements\n",
    "    \"\"\"\n",
    "    domaincasesQuery = \"select * from ( select expand( out('linkeddomains')) from Requirements where ID = '\" + reqid +\"' )\"\n",
    "    domaincases = execute_query(domaincasesQuery)\n",
    "    scoresQuery = \"select expand(out_linkeddomains) from Requirements where ID = '\"+reqid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    domaincaseList =[]\n",
    "    domaincaseAction =[]\n",
    "    scoresList= []\n",
    "    for domaincase in domaincases:\n",
    "        domaincaseList.append(domaincase.ID)\n",
    "        domaincaseAction.append(domaincase.Action)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(domaincaseList)\n",
    "    for i in range(0, length):\n",
    "        result[domaincaseList[i]] = scoresList[i]\n",
    "        #result[domaincaseList[i]] = domaincaseAction[i]\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def get_related_dataelements(domaincaseid):\n",
    "    \"\"\" Get the related requirements for a testcase\n",
    "    \"\"\"\n",
    "    dataelementsQuery = \"select * from ( select expand( out('linkeddataelements') ) from Domains where ID = '\" + domaincaseid +\"' )\"\n",
    "    dataelements = execute_query(dataelementsQuery)\n",
    "    #print(dataelements)\n",
    "    scoresQuery = \"select expand(out_linkeddataelements) from Domains where ID = '\"+domaincaseid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    dataelementsList =[]\n",
    "    scoresList= []\n",
    "    for dataelement in dataelements:\n",
    "        dataelementsList.append(dataelement.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(dataelementsList)\n",
    "    #print requirementsList, scoresList\n",
    "    for i in range(0, length):\n",
    "        result[dataelementsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def get_related_user(reqid):\n",
    "    reqQuery = \"select * from Requirements where ID = '\"+reqid+\"'\"\n",
    "    requirements = execute_query(reqQuery)\n",
    "    result = ''\n",
    "    for requirement in requirements:\n",
    "        print(requirement.User)\n",
    "        result = requirement.User\n",
    "    return result\n",
    "\n",
    "def get_related_action(key):\n",
    "    domQuery = \"select * from Domains where ID = '\"+key+\"'\"\n",
    "    domains = execute_query(domQuery)\n",
    "    result = ''\n",
    "    for domain in domains:\n",
    "        print(domain.Action)\n",
    "        result = domain.Action\n",
    "    return result\n",
    "\n",
    "def get_related_shorthand(key):\n",
    "    shortQuery = \"select * from DataElements where ID = '\"+key+\"'\"\n",
    "    shorts = execute_query(shortQuery)\n",
    "    result = ''\n",
    "    for short in shorts:\n",
    "        print(short.Short)\n",
    "        result = short.Short\n",
    "    return result\n",
    "\n",
    "def get_artifacts_mapping_d3_network(reqid):\n",
    "    \"\"\" Create an artifacts mapping json for display by d3js network widget\n",
    "    \"\"\"\n",
    "    nodes =[]\n",
    "    links =[] \n",
    "    req = {}\n",
    "    req['id'] = reqid\n",
    "    req['group'] = 1\n",
    "    req['desc'] = get_related_user(reqid)\n",
    "    nodes.append(req)\n",
    "    \n",
    "    domaincases = get_related_domaincases(reqid)\n",
    "    print(\"1 - nodes\")\n",
    "    print(nodes)\n",
    "    print(\"2 - domaincases\")\n",
    "    print(domaincases)\n",
    "    for key in domaincases:\n",
    "        print(\"3  - For each domaincases\")\n",
    "        print(key)\n",
    "        domaincase ={}\n",
    "        domaincaseid = key\n",
    "        domaincase['id'] = domaincaseid\n",
    "        domaincase['group'] = 2\n",
    "        domaincase['desc'] = get_related_action(key)\n",
    "        if domaincase not in nodes:\n",
    "            nodes.append(domaincase)\n",
    "        print(\"4 - appended node\")\n",
    "        print(nodes)\n",
    "        link = {}\n",
    "        link['source'] = reqid\n",
    "        link['target']=domaincaseid\n",
    "        link['value']=domaincases[domaincaseid]\n",
    "        links.append(link)\n",
    "        print(\"5 - create links for individual domaincase\")\n",
    "        print(links)\n",
    "        dataelements = get_related_dataelements(key)\n",
    "        print(\"6 - for the domain case find dataelements\")\n",
    "        print(dataelements)\n",
    "        for key in dataelements:\n",
    "            print(\"7- individual dataelements\")\n",
    "            print(key)\n",
    "            dataelement ={}\n",
    "            dataelement['id'] = key\n",
    "            dataelement['group'] = 3\n",
    "            dataelement['desc'] = get_related_shorthand(key)\n",
    "            if dataelement not in nodes:\n",
    "                nodes.append(dataelement)\n",
    "            print(\"8 - appended node with dataelement\")\n",
    "            print(nodes)\n",
    "            link = {}\n",
    "            link['source'] = domaincaseid\n",
    "            link['target'] = key\n",
    "            link['value'] = dataelements[key]\n",
    "            links.append(link)\n",
    "            print(\"9- create links for dataelements\")\n",
    "            print(links)\n",
    "    result ={}\n",
    "    result[\"nodes\"] = nodes\n",
    "    result[\"links\"] = links\n",
    "    return result\n",
    "\n",
    "\n",
    "req_id = \"R01\"\n",
    "wsresponse = {}\n",
    "wsresponse[\"forCmd\"] = \"AllRelation\" \n",
    "wsresponse[\"response\"] = get_artifacts_mapping_d3_network(req_id)\n",
    "print(\"***** final response ******\")\n",
    "print(json.dumps(wsresponse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'requirement', 'children': [{'ID': 'UC01', 'group': 'Customer', 'size': 100}, {'ID': 'UC05', 'group': 'Customer', 'size': 100}, {'ID': 'UC09', 'group': 'Banker', 'size': 75}, {'ID': 'UC02', 'group': 'Customer', 'size': 100}, {'ID': 'UC06', 'group': 'Banker', 'size': 75}, {'ID': 'UC10', 'group': 'Banker', 'size': 75}, {'ID': 'UC03', 'group': 'Customer', 'size': 100}, {'ID': 'UC07', 'group': 'Banker', 'size': 75}, {'ID': 'UC11', 'group': 'Banker', 'size': 75}, {'ID': 'UC04', 'group': 'Customer', 'size': 100}, {'ID': 'UC08', 'group': 'Banker', 'size': 75}]}\n",
      "Insight1\n",
      "******only banker********\n",
      "{'name': 'requirement', 'children': [{'ID': 'UC09', 'group': 'Banker', 'size': 75}, {'ID': 'UC06', 'group': 'Banker', 'size': 75}, {'ID': 'UC10', 'group': 'Banker', 'size': 75}, {'ID': 'UC07', 'group': 'Banker', 'size': 75}, {'ID': 'UC11', 'group': 'Banker', 'size': 75}, {'ID': 'UC08', 'group': 'Banker', 'size': 75}]}\n",
      "******* Applying filter *****\n",
      "{'name': 'requirement', 'children': [{'ID': 'UC01', 'group': 'Customer', 'size': 100, 'filter': 0}, {'ID': 'UC05', 'group': 'Customer', 'size': 100, 'filter': 0}, {'ID': 'UC09', 'group': 'Banker', 'size': 75, 'filter': 1}, {'ID': 'UC02', 'group': 'Customer', 'size': 100, 'filter': 0}, {'ID': 'UC06', 'group': 'Banker', 'size': 75, 'filter': 1}, {'ID': 'UC10', 'group': 'Banker', 'size': 75, 'filter': 1}, {'ID': 'UC03', 'group': 'Customer', 'size': 100, 'filter': 0}, {'ID': 'UC07', 'group': 'Banker', 'size': 75, 'filter': 1}, {'ID': 'UC11', 'group': 'Banker', 'size': 75, 'filter': 1}, {'ID': 'UC04', 'group': 'Customer', 'size': 100, 'filter': 0}, {'ID': 'UC08', 'group': 'Banker', 'size': 75, 'filter': 1}]}\n",
      "********\n",
      "{\"forCmd\": \"Insight\", \"response\": {\"name\": \"requirement\", \"children\": [{\"ID\": \"UC01\", \"group\": \"Customer\", \"size\": 100, \"filter\": 0}, {\"ID\": \"UC05\", \"group\": \"Customer\", \"size\": 100, \"filter\": 0}, {\"ID\": \"UC09\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}, {\"ID\": \"UC02\", \"group\": \"Customer\", \"size\": 100, \"filter\": 0}, {\"ID\": \"UC06\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}, {\"ID\": \"UC10\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}, {\"ID\": \"UC03\", \"group\": \"Customer\", \"size\": 100, \"filter\": 0}, {\"ID\": \"UC07\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}, {\"ID\": \"UC11\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}, {\"ID\": \"UC04\", \"group\": \"Customer\", \"size\": 100, \"filter\": 0}, {\"ID\": \"UC08\", \"group\": \"Banker\", \"size\": 75, \"filter\": 1}]}}\n"
     ]
    }
   ],
   "source": [
    "def get_requirement_defects(numdefects):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,Priority from Requirement where out('linkeddefects').size() >= \" + str(numdefects)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    for requirement in requirements:\n",
    "        num = len(get_related_defects(requirement['ID']))\n",
    "        requirement['defectcount'] = num\n",
    "    return requirements \n",
    "def merge_apply_filters_d3_bubble(mainList, filterList):\n",
    "    \"\"\" Add a filter attribute to the list elements for processing on UI\n",
    "    \"\"\"\n",
    "    mainListChildren = mainList['children']\n",
    "    filterListChildren = filterList['children']\n",
    "    for child in mainListChildren:\n",
    "        child['filter'] = 0\n",
    "        for child1 in filterListChildren:\n",
    "            if ( child['ID'] == child1['ID']):\n",
    "                child['filter'] = 1\n",
    "    return mainList\n",
    "\n",
    "def get_requirement_defects(numdefects):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,Priority from Requirement where out('linkeddefects').size() >= \" + str(numdefects)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    for requirement in requirements:\n",
    "        num = len(get_related_defects(requirement['ID']))\n",
    "        requirement['defectcount'] = num\n",
    "    return requirements \n",
    "\n",
    "def get_requirements_banker():\n",
    "    \"\"\" Get requirements that have no defects\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirements where User = 'Banker'\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements\n",
    "def get_requirements_customer():\n",
    "    \"\"\" Get requirements that have no defects\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirements where User = 'Customer'\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements\n",
    "def get_requirement_domain(numde):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,User from Requirements where out('linkeddomains').size() <= \" + str(numde)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements \n",
    "\n",
    "insight_id = 'Insight1 Get requirements for Banker'\n",
    "requirements = get_requirements()\n",
    "requirements = transform_requirements_d3_bubble(requirements)\n",
    "print(requirements)\n",
    "if (insight_id.find('Insight1') != -1):\n",
    "    print('Insight1')\n",
    "    #req = get_requirements_zero_defect()\n",
    "    req = get_requirements_banker()\n",
    "    req = transform_requirements_d3_bubble(req)\n",
    "    print('******only banker********')\n",
    "    print(req)\n",
    "    response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "    print('******* Applying filter *****')\n",
    "    print(response)\n",
    "    print('********')\n",
    "if (insight_id.find('Insight2') != -1):\n",
    "    req = get_requirements_customer()\n",
    "    req = transform_requirements_d3_bubble(req)\n",
    "    response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "if (insight_id.find('Insight3') != -1):\n",
    "    #req = get_requirement_defects(5)\n",
    "    req = get_requirement_dataelements(5)\n",
    "    req = transform_requirements_d3_bubble(req)\n",
    "    response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "wsresponse = {}\n",
    "wsresponse[\"forCmd\"] = \"Insight\" \n",
    "wsresponse[\"response\"] = response\n",
    "print(json.dumps(wsresponse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message(ws, message):\n",
    "    print(message)\n",
    "    msg = json.loads(message)\n",
    "    print(\"message\",msg)\n",
    "    cmd = msg['cmd']\n",
    "    \n",
    "    print(\"Command :\", cmd)\n",
    "\n",
    "    if cmd == 'getExcel':\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"GetExcel\"\n",
    "        wsresponse[\"response\"] = setup_download_excel()\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "    \n",
    "    if cmd == 'ReqsList':\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"ReqsList\"\n",
    "        requirements = get_requirements()\n",
    "        wsresponse[\"response\"] = transform_requirements_d3_bubble(requirements)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'AllRelation':\n",
    "        req_id = msg['ID']\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"AllRelation\" \n",
    "        wsresponse[\"response\"] = get_artifacts_mapping_d3_network(req_id)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'DataElementRelation':\n",
    "        testcase_id = msg['ID']\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"TestcaseRelation\" \n",
    "        wsresponse[\"response\"] = get_tc_req_mapping_d3_network(testcase_id)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    #  the below protion is for getting insight into download section, this has not yet been done and will be done later if required\n",
    "    \n",
    "    if cmd == 'DownloadInsight':\n",
    "        insight_id = msg['ID']\n",
    "        testcases = get_testcases()\n",
    "        testcases = transform_testcases_d3_bubble(testcases)\n",
    "        if (insight_id.find('Insight1') != -1):\n",
    "            fvtTests = get_testcases_category('FVT')\n",
    "            fvtTests = transform_testcases_d3_bubble(fvtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, fvtTests)\n",
    "        if (insight_id.find('Insight2') != -1):\n",
    "            svtTests = get_testcases_category('SVT')\n",
    "            svtTests = transform_testcases_d3_bubble(svtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, svtTests)\n",
    "        if (insight_id.find('Insight3') != -1):\n",
    "            tvtTests = get_testcases_category('TVT')\n",
    "            tvtTests = transform_testcases_d3_bubble(tvtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, tvtTests)\n",
    "        if (insight_id.find('Insight4') != -1):\n",
    "            testcase_zero_defect = get_testcases_zero_defects()\n",
    "            testcase_zero_defect = transform_testcases_d3_bubble(testcase_zero_defect)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, testcase_zero_defect)\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"Insight\" \n",
    "        wsresponse[\"response\"] = response\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'ReqInsight':\n",
    "        insight_id = msg['ID']\n",
    "        requirements = get_requirements()\n",
    "        requirements = transform_requirements_d3_bubble(requirements)\n",
    "    #print(requirements)\n",
    "        if (insight_id.find('Insight1') != -1):\n",
    "            print('Insight1')\n",
    "            req = get_requirements_banker()\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "        #print('******only banker********')\n",
    "        #print(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "        #print('******* Applying filter *****')\n",
    "            #print(response)\n",
    "            #print('********')\n",
    "        if (insight_id.find('Insight2') != -1):\n",
    "            req = get_requirements_customer()\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "        if (insight_id.find('Insight3') != -1):\n",
    "            req = get_requirement_domain(1)\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "\n",
    "    wsresponse = {}\n",
    "    wsresponse[\"forCmd\"] = \"Insight\" \n",
    "    wsresponse[\"response\"] = response\n",
    "    ws.send(json.dumps(wsresponse)) \n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(error)\n",
    "\n",
    "def on_close(ws):\n",
    "    print (\"DSX Listen End\")\n",
    "    ws.send(\"DSX Listen End\")\n",
    "\n",
    "def on_open(ws):\n",
    "    def run(*args):\n",
    "        for i in range(10000):\n",
    "            hbeat = '{\"cmd\":\"AI nWave HeartBeat\"}'\n",
    "            ws.send(hbeat)\n",
    "            time.sleep(100)\n",
    "            \n",
    "    _thread.start_new_thread(run, ())\n",
    "\n",
    "\n",
    "def start_websocket_listener():\n",
    "    websocket.enableTrace(True)\n",
    "    ws = websocket.WebSocketApp(\"ws://localhost:1880/ws/software\",\n",
    "                              on_message = on_message,\n",
    "                              on_error = on_error,\n",
    "                              on_close = on_close)\n",
    "    ws.on_open = on_open\n",
    "    ws.run_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Start websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#start_websocket_listener()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

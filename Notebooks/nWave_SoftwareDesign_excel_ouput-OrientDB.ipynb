{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Design Using ML&AI nWave\n",
    "\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "To prepare your environment, you need to install some packages\n",
    "\n",
    "# 1.1 Install the necessary packages\n",
    "\n",
    "You need the latest versions of these packages:<br>\n",
    " \n",
    "** Spacy** a client library for NLP.<br>\n",
    "** Pandas for dataframe.<br>\n",
    "** stop_words: **List of common stop words.<br>\n",
    "** python-boto3:** is a python client for the Boto3 API used for communicating to AWS.<br>\n",
    "** websocket-client: ** is a python client for the Websockets.<br>\n",
    "** pyorient: ** is a python client for the Orient DB.<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install NLTK: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mRetrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x11205b080>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/nltk/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x11205be10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/nltk/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x11205b160>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/nltk/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x11205bfd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/nltk/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x1120674e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/nltk/\u001b[0m\n",
      "Requirement already up-to-date: nltk in /anaconda3/lib/python3.6/site-packages (3.3)\n",
      "Requirement not upgraded as not directly required: six in /anaconda3/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "\u001b[33mRetrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x111ead8d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/pyorient/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x111ead208>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/pyorient/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x111ead550>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/pyorient/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x111ead470>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/pyorient/\u001b[0m\n",
      "\u001b[33mRetrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x111eadd68>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',)': /simple/pyorient/\u001b[0m\n",
      "Requirement already up-to-date: pyorient in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.5.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n",
    "!pip install --upgrade pyorient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Boto3 client for AWS communication thorugh CLI **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /anaconda3/lib/python3.6/site-packages (1.7.11)\r\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.11 in /Users/swaroopmishra/.local/lib/python3.6/site-packages (from boto3) (1.10.20)\r\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.1.13)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.9.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (2.6.1)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (0.14)\r\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.11.0,>=1.10.11->boto3) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install stop_words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in /anaconda3/lib/python3.6/site-packages (2015.2.23.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install websocket client: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: websocket-client in /anaconda3/lib/python3.6/site-packages (0.47.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from websocket-client) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install websocket-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install pyorient: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.15.20)\n",
      "Requirement already satisfied: botocore==1.10.20 in /Users/swaroopmishra/.local/lib/python3.6/site-packages (from awscli) (1.10.20)\n",
      "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.4.2)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.12 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.14)\n",
      "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.3.7)\n",
      "Requirement already satisfied: PyYAML<=3.12,>=3.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.20->awscli) (2.6.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.20->awscli) (0.9.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /anaconda3/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore==1.10.20->awscli) (1.11.0)\n",
      "Requirement already satisfied: pyorient in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.5.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install awscli\n",
    "! pip install pyorient --user\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Import packages and libraries \n",
    "\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from stop_words import get_stop_words\n",
    "import numpy\n",
    "\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "import websocket\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuration\n",
    "\n",
    "Add configurable items of the notebook below\n",
    "## 2.1 Add your service credentials if any required( this is where you need to add credentials of infrastructure you are using to store data etc)\n",
    "\n",
    "\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the section to provide credentials for AWS S3 account\n",
    "### While sharing the notebook remove them -- will try to make this cell hidden later\n",
    "\n",
    "## Console URL :::  https://awstestconsole-swaroop.signin.aws.amazon.com/console\n",
    "## Account Id: \n",
    "## Username : \n",
    "## Password : \n",
    "## Then Navigate to the S3 section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Add your service credentials for S3\n",
    "\n",
    "You must create S3 bucket service on AWS. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage authentication credentials as credentials_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'ACCESS_KEY_ID': '',\n",
    "    'ACCESS_SECRET_KEY': '',\n",
    "    'BUCKET': 'software-testing-pyscript'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Spacy Text Classification  ( this section will be required if we use spacy for machine learning)\n",
    "\n",
    "Write the classification related utility functions in a modularalized form.\n",
    "\n",
    "## 3.1  REQUIREMENT Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentence(text):\n",
    "    \"\"\" Tag the sentence using chunking.\n",
    "    \"\"\"\n",
    "    grammar = \"\"\"\n",
    "      Action: {<VB.?><NN.?>+}\n",
    "      Action: {<VB.?><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{\n",
    "      Action: {<VB.?><CLAUSE1><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{\n",
    "      Action: {<VB.?><CLAUSE1><CLAUSE1><CLAUSE1><NN.?>+}\n",
    "               }<CLAUSE1>{  \n",
    "      CLAUSE1: {<DT|PRP.?|IN|JJ>}\n",
    "      \n",
    "      \n",
    "      \"\"\"  \n",
    "    parsed_cp = nltk.RegexpParser(grammar,loop=2)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    return pos_cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Augumented Classification\n",
    "\n",
    "Custom classification utlity fucntions for augumenting the results of Spacy API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\" Split text into sentences.\n",
    "    \"\"\"\n",
    "    sentence_delimiters = re.compile(u'[\\\\[\\\\]\\n.!?]')\n",
    "    sentences = sentence_delimiters.split(text)\n",
    "    return sentences\n",
    "\n",
    "def split_into_tokens(text):\n",
    "    \"\"\" Split text into tokens.\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "    \n",
    "def POS_tagging(text):\n",
    "    \"\"\" Generate Part of speech tagging of the text.\n",
    "    \"\"\"\n",
    "    POSofText = nltk.tag.pos_tag(text)\n",
    "    return POSofText\n",
    "\n",
    "\n",
    "def keyword_tagging(tag,tagtext,text):\n",
    "    \"\"\" Tag the text matching keywords.\n",
    "    \"\"\"\n",
    "    if (text.lower().find(tagtext.lower()) != -1):\n",
    "        return text[text.lower().find(tagtext.lower()):text.lower().find(tagtext.lower())+len(tagtext)]\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "    \n",
    "def regex_tagging(tag,regex,text):\n",
    "    \"\"\" Tag the text matching REGEX.\n",
    "    \"\"\"    \n",
    "    p = re.compile(regex, re.IGNORECASE)\n",
    "    matchtext = p.findall(text)\n",
    "    regex_list=[]    \n",
    "    if (len(matchtext)>0):\n",
    "        for regword in matchtext:\n",
    "            regex_list.append(regword)\n",
    "    return regex_list\n",
    "\n",
    "def BRD_chunk_tagging(tag,chunk,text):\n",
    "    \"\"\" Tag the text using chunking.\n",
    "    \"\"\"\n",
    "    parsed_cp = nltk.RegexpParser(chunk)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    #pos_cp = chunk_sentence(text) #*** use this for getting refined output after chinking but extra entities in output\n",
    "    chunk_list=[]\n",
    "    for root in pos_cp:\n",
    "        if isinstance(root, nltk.tree.Tree):               \n",
    "            if root.label() == tag:\n",
    "                chunk_word = ''\n",
    "                for child_root in root:\n",
    "                    chunk_word = chunk_word +' '+ child_root[0]\n",
    "                chunk_list.append(chunk_word)\n",
    "    return chunk_list\n",
    "\n",
    "def chunk_tagging(tag,chunk,text):\n",
    "    \"\"\" Tag the text using chunking.\n",
    "    \"\"\"\n",
    "    parsed_cp = nltk.RegexpParser(chunk)\n",
    "    pos_cp = parsed_cp.parse(text)\n",
    "    chunk_list=[]\n",
    "    for root in pos_cp:\n",
    "        if isinstance(root, nltk.tree.Tree):               \n",
    "            if root.label() == tag:\n",
    "                chunk_word = ''\n",
    "                for child_root in root:\n",
    "                    chunk_word = chunk_word +' '+ child_root[0]\n",
    "                chunk_list.append(chunk_word)\n",
    "    return chunk_list\n",
    "    \n",
    "def augument_SpResponse(responsejson,updateType,text,tag):\n",
    "    \"\"\" Update the output JSON with augumented classifications.\n",
    "    \"\"\"\n",
    "    if(updateType == 'keyword'):\n",
    "        if not any(d.get('text', None) == text for d in responsejson['Keywords']):\n",
    "            responsejson['Keywords'].append({\"User\":text})\n",
    "    else:\n",
    "        if not any(d.get('text', None) == text for d in responsejson['Entities']):\n",
    "            responsejson['Entities'].append({\"type\":tag,\"text\":text}) \n",
    "\n",
    "def classify_BRD_text(text, config):\n",
    "    \"\"\" Perform augumented classification of the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    #will be used for storing initial value of response json, this is from nlu earlier\n",
    "    with open('output_format_BRD.json') as f:\n",
    "        responsejson = json.load(f)\n",
    "    \n",
    "    sentenceList = split_sentences(text) #\n",
    "    \n",
    "    tokens = split_into_tokens(text)\n",
    "    \n",
    "    postags = POS_tagging(tokens)\n",
    "    \n",
    "    configjson = json.loads(config)#load would take a file-like object, read the data from that object, and use that string to create an object:\n",
    "    \n",
    "    no_of_items = 0\n",
    "    \n",
    "    for stages in configjson['configuration']['classification']['stages']:\n",
    "        # print('Stage - Performing ' + stages['name']+':')\n",
    "        for steps in stages['steps']:\n",
    "            # print('    Step - ' + steps['type']+':')\n",
    "            if (steps['type'] == 'keywords'):\n",
    "                for keyword in steps['keywords']:\n",
    "                        wordtag = tokens[0]\n",
    "                augument_SpResponse(responsejson,'keyword',wordtag,keyword['tag'])\n",
    "            elif(steps['type'] == 'd_regex'):\n",
    "                for regex in steps['d_regex']:\n",
    "                    for word in sentenceList:\n",
    "                        regextags = regex_tagging(regex['tag'],regex['pattern'],word)\n",
    "                        if (len(regextags)>0):\n",
    "                            for words in regextags:\n",
    "                                #print('      '+regex['tag']+':'+words)\n",
    "                                augument_SpResponse(responsejson,'Action',words,regex['tag'])\n",
    "            elif(steps['type'] == 'chunking'):\n",
    "                for chunk in steps['chunk']:\n",
    "                    chunktags = BRD_chunk_tagging(chunk['tag'],chunk['pattern'],postags)\n",
    "                    if (len(chunktags)>0):\n",
    "                        for words in chunktags:\n",
    "                            #print('      '+chunk['tag']+':'+words)\n",
    "                            if (no_of_items <1):\n",
    "                                augument_SpResponse(responsejson,'Action',words,chunk['tag'])\n",
    "                                no_of_items = no_of_items + 1\n",
    "            else:\n",
    "                print('UNKNOWN STEP')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return responsejson\n",
    "\n",
    "\n",
    "\n",
    "def classify_text(text, config):\n",
    "    \"\"\" Perform augumented classification of the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    #will be used for storing initial value of response json, this is from nlu earlier\n",
    "    with open('sample.json') as f:\n",
    "        responsejson = json.load(f)\n",
    "    \n",
    "    sentenceList = split_sentences(text) #\n",
    "    \n",
    "    tokens = split_into_tokens(text)\n",
    "    \n",
    "    postags = POS_tagging(tokens)\n",
    "    \n",
    "    configjson = json.loads(config)#load would take a file-like object, read the data from that object, and use that string to create an object:\n",
    "    \n",
    "    for stages in configjson['configuration']['classification']['stages']:\n",
    "        # print('Stage - Performing ' + stages['name']+':')\n",
    "        for steps in stages['steps']:\n",
    "            # print('    Step - ' + steps['type']+':')\n",
    "            if (steps['type'] == 'keywords'):\n",
    "                for keyword in steps['keywords']:\n",
    "                    for word in sentenceList:\n",
    "                        wordtag = keyword_tagging(keyword['tag'],keyword['text'],word)\n",
    "                        if(wordtag != 'UNKNOWN'):\n",
    "                            #print('      '+keyword['tag']+':'+wordtag)\n",
    "                            augument_SpResponse(responsejson,'keyword',wordtag,keyword['tag'])\n",
    "            elif(steps['type'] == 'd_regex'):\n",
    "                for regex in steps['d_regex']:\n",
    "                    for word in sentenceList:\n",
    "                        regextags = regex_tagging(regex['tag'],regex['pattern'],word)\n",
    "                        if (len(regextags)>0):\n",
    "                            for words in regextags:\n",
    "                                #print('      '+regex['tag']+':'+words)\n",
    "                                augument_SpResponse(responsejson,'entities',words,regex['tag'])\n",
    "            elif(steps['type'] == 'chunking'):\n",
    "                for chunk in steps['chunk']:\n",
    "                    chunktags = chunk_tagging(chunk['tag'],chunk['pattern'],postags)\n",
    "                    if (len(chunktags)>0):\n",
    "                        for words in chunktags:\n",
    "                            #print('      '+chunk['tag']+':'+words)\n",
    "                            augument_SpResponse(responsejson,'entities',words,chunk['tag'])\n",
    "            else:\n",
    "                print('UNKNOWN STEP')\n",
    "    \n",
    "    \n",
    "    return responsejson\n",
    "\n",
    "\n",
    "def replace_unicode_strings(response):\n",
    "    \"\"\" Convert dict with unicode strings to strings.\n",
    "    \"\"\"\n",
    "    if isinstance(response, dict):\n",
    "        return {replace_unicode_strings(key): replace_unicode_strings(value) for key, value in response.iteritems()}\n",
    "    elif isinstance(response, list):\n",
    "        return [replace_unicode_strings(element) for element in response]\n",
    "    elif isinstance(response, unicode):\n",
    "        return response.encode('utf-8')\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Correlate text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = get_stop_words('english')\n",
    "# List of words to be ignored for text similarity\n",
    "stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])\n",
    "\n",
    "def compute_text_similarity(text1, text2, text1tags, text2tags):\n",
    "    \"\"\" Compute text similarity using cosine\n",
    "    \"\"\"\n",
    "    #stemming is the process for reducing inflected (or sometimes derived) words to their stem, base or root form\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    sentences_text1 = split_sentences(text1)\n",
    "    sentences_text2 = split_sentences(text2)\n",
    "    tokens_text1 = []\n",
    "    tokens_text2 = []\n",
    "    \n",
    "    for sentence in sentences_text1:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        tokens_text1.extend(tokenstemp)\n",
    "    \n",
    "    for sentence in sentences_text2:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        tokens_text2.extend(tokenstemp)\n",
    "    if (len(text1tags) > 0):  \n",
    "        tokens_text1.extend(text1tags)\n",
    "    if (len(text2tags) > 0):    \n",
    "        tokens_text2.extend(text2tags)\n",
    "    \n",
    "    tokens1Filtered = [stemmer.stem(x) for x in tokens_text1 if x not in stopWords]\n",
    "    \n",
    "    tokens2Filtered = [stemmer.stem(x) for x in tokens_text2 if x not in stopWords]\n",
    "    \n",
    "    #  remove duplicate tokens\n",
    "    tokens1Filtered = set(tokens1Filtered)\n",
    "    tokens2Filtered = set(tokens2Filtered)\n",
    "   \n",
    "    tokensList=[]\n",
    "\n",
    "    text1vector = []\n",
    "    text2vector = []\n",
    "    \n",
    "    if len(tokens1Filtered) < len(tokens2Filtered):\n",
    "        tokensList = tokens1Filtered\n",
    "    else:\n",
    "        tokensList = tokens2Filtered\n",
    "\n",
    "    for token in tokensList:\n",
    "        if token in tokens1Filtered:\n",
    "            text1vector.append(1)\n",
    "        else:\n",
    "            text1vector.append(0)\n",
    "        if token in tokens2Filtered:\n",
    "            text2vector.append(1)\n",
    "        else:\n",
    "            text2vector.append(0)  \n",
    "\n",
    "    cosine_similarity = 1-cosine_distance(text1vector,text2vector)\n",
    "    if numpy.isnan(cosine_similarity):\n",
    "        cosine_similarity = 0\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Persistence and Storage\n",
    "## 5.1 Configure Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3',\n",
    "                    aws_access_key_id=credentials_1['ACCESS_KEY_ID'],\n",
    "                    aws_secret_access_key=credentials_1['ACCESS_SECRET_KEY'],\n",
    "                    config=Config(signature_version='s3v4')\n",
    "                     )\n",
    "#Enter the path where you want to store data downlaoded from S3\n",
    "\n",
    "\n",
    "def get_file(filename,Location):\n",
    "    #s3.download_file(Bucket=credentials_1['BUCKET'],Key=filename,Filename=Location)\n",
    "    t=\"abc\"\n",
    "\n",
    "#def load_string(fileobject):\n",
    "#    '''Load the file contents into a Python string'''\n",
    "#    text = fileobject.read()\n",
    "#    return text\n",
    "\n",
    "#def load_df(fileobject,sheetname):\n",
    "#    '''Load file contents into a Pandas dataframe'''\n",
    "#    excelFile = pd.ExcelFile(fileobject)\n",
    "#    df = excelFile.parse(sheetname)\n",
    "#    return df\n",
    "\n",
    "#def put_file(filename, filecontents):\n",
    "#    '''Write file to Cloud Object Storage'''\n",
    "#    resp = s3.put_object(Bucket=credentials_1['BUCKET'], Key=filename, Body=filecontents)\n",
    "    #resp = s3.Bucket(Bucket=credentials_1['BUCKET']).put_object(Key=filename, Body=filecontents)\n",
    "#    return resp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 OrientDB client - functions to connect, store and retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Connect to OrientDB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyorient\n",
    "client = pyorient.OrientDB(host=\"localhost\", port=2424)\n",
    "user = \"root\"\n",
    "passw = \"root\"\n",
    "session_id = client.connect(user, passw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Core functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(dbname, username, password):\n",
    "    \"\"\" Create a database\n",
    "    \"\"\"\n",
    "    client.db_create( dbname, pyorient.DB_TYPE_GRAPH, pyorient.STORAGE_TYPE_MEMORY )\n",
    "    print(dbname  + \" created and opened successfully\")\n",
    "        \n",
    "def drop_database(dbname):\n",
    "    \"\"\" Drop a database\n",
    "    \"\"\"\n",
    "    if client.db_exists( dbname, pyorient.STORAGE_TYPE_MEMORY ):\n",
    "        client.db_drop(dbname)\n",
    "    \n",
    "def create_class(classname):\n",
    "    \"\"\" Create a class\n",
    "    \"\"\"\n",
    "    command = \"create class \"+classname + \" extends V\"\n",
    "    client.command(command)\n",
    "    \n",
    "def create_record(classname, entityname, attributes):\n",
    "    \"\"\" Create a record\n",
    "    \"\"\"\n",
    "    command = \"insert into \" + classname + \" set \" \n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        attrstring = attrstring + key + \" = '\"+ attributes[key] + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    client.command(command)\n",
    "    \n",
    "def create_domain_dataelements_edge(domainid, dataelementid, attributes):\n",
    "    \"\"\" Create an edge between a domain n dataelement \n",
    "    \"\"\"\n",
    "    command = \"create edge linkeddataelements from (select from Domains where ID = \" + \"'\" + domainid + \"') to (select from DataElements where ID = \" + \"'\" + dataelementid + \"')\" \n",
    "    if len(attributes) > 0:\n",
    "        command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    print(command)\n",
    "    client.command(command)    \n",
    "    \n",
    "def create_dataelements_requirement_edge(testcaseid, reqid, attributes):\n",
    "    \"\"\" Create an edge between a testcase and a requirement\n",
    "    \"\"\"\n",
    "    command = \"create edge linkedrequirements from (select from DataElements where ID = \"+ \"'\" + testcaseid+\"') to (select from Requirements where ID = \"+\"'\"+reqid+\"')\" \n",
    "    if len(attributes) > 0:\n",
    "        command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    client.command(command)  \n",
    "\n",
    "    \n",
    "def create_requirement_domain_edge(reqid, functionalityid, attributes):\n",
    "    \"\"\" Create an edge between a requirement and a domain\n",
    "    \"\"\"\n",
    "    command = \"create edge linkeddomains from (select from Requirements where ID = \"+ \"'\" + reqid+\"') to (select from Domains where ID = \"+\"'\"+functionalityid+\"')\" \n",
    "    \n",
    "    if len(attributes) > 0:\n",
    "         command = command + \" set \"\n",
    "    attrstring = \"\"\n",
    "    for index,key in enumerate(attributes):\n",
    "        val = attributes[key]\n",
    "        if not isinstance(val, str):\n",
    "            val = str(val)\n",
    "        attrstring = attrstring + key + \" = '\"+ val + \"'\"\n",
    "        if index != len(attributes) -1:\n",
    "            attrstring = attrstring +\",\"\n",
    "    command = command + attrstring\n",
    "    print(command)\n",
    "    client.command(command) \n",
    "    \n",
    "def execute_query(query):\n",
    "    \"\"\" Execute a query\n",
    "    \"\"\"\n",
    "    return client.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Insights **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(int testcases)? (<ipython-input-85-f8375e1c579b>, line 126)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-f8375e1c579b>\"\u001b[0;36m, line \u001b[0;32m126\u001b[0m\n\u001b[0;31m    print testcases\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(int testcases)?\n"
     ]
    }
   ],
   "source": [
    "def get_related_testcases(defectid):\n",
    "    \"\"\" Get the related testcases for a defect\n",
    "    \"\"\"\n",
    "    testcasesQuery = \"select * from ( select expand( out('linkedtestcases')) from Defect where ID = '\" + defectid +\"' )\"\n",
    "    testcases = execute_query(testcasesQuery)\n",
    "    scoresQuery = \"select expand(out_linkedtestcases) from Defect where ID = '\"+defectid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    testcaseList =[]\n",
    "    scoresList= []\n",
    "    for testcase in testcases:\n",
    "        testcaseList.append(testcase.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(testcaseList)\n",
    "    for i in range(0, length):\n",
    "        result[testcaseList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def get_related_requirements(testcaseid):\n",
    "    \"\"\" Get the related requirements for a testcase\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from ( select expand( out('linkedrequirements') ) from Testcase where ID = '\" + testcaseid +\"' )\"\n",
    "    requirements = execute_query(requirementsQuery)\n",
    "    print(requirements)\n",
    "    scoresQuery = \"select expand(out_linkedrequirements) from Testcase where ID = '\"+testcaseid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    requirementsList =[]\n",
    "    scoresList= []\n",
    "    for requirement in requirements:\n",
    "        requirementsList.append(requirement.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(requirementsList)\n",
    "    #print requirementsList, scoresList\n",
    "    for i in range(0, length):\n",
    "        result[requirementsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def get_related_defects(reqid):\n",
    "    \"\"\" Get the related defects for a requirement\n",
    "    \"\"\"\n",
    "    defectsQuery = \"select * from ( select expand( out('linkeddefects')) from Requirement where ID = '\" + reqid +\"' )\"\n",
    "    defects = execute_query(defectsQuery)\n",
    "    scoresQuery = \"select expand(out_linkeddefects) from Requirement where ID = '\"+reqid+\"'\"\n",
    "    scores = execute_query(scoresQuery)\n",
    "    defectsList =[]\n",
    "    scoresList= []\n",
    "    for defect in defects:\n",
    "        defectsList.append(defect.ID)\n",
    "    for score in scores:\n",
    "        scoresList.append(score.score)\n",
    "    result = {}\n",
    "    length = len(defectsList)\n",
    "    for i in range(0, length):\n",
    "        result[defectsList[i]] = scoresList[i]\n",
    "    return result\n",
    "\n",
    "def build_format_defects_list(defectsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for defects\n",
    "    \"\"\"\n",
    "    defects = []\n",
    "    for defect in defectsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] = defect.ID\n",
    "        detail['Severity'] = defect.Severity\n",
    "        detail['Description'] = defect.Description\n",
    "        defects.append(detail)\n",
    "    return defects\n",
    "\n",
    "def build_format_testcases_list(testcasesResult):\n",
    "    \"\"\" Build and format the OrientDB query results for testcases\n",
    "    \"\"\"\n",
    "    testcases = []\n",
    "    for testcase in testcasesResult:\n",
    "        detail = {}\n",
    "        detail['ID'] = testcase.ID\n",
    "        detail['Category'] = testcase.Category\n",
    "        detail['Description'] = testcase.Description\n",
    "        testcases.append(detail)\n",
    "    return testcases  \n",
    "\n",
    "def build_format_requirements_list(requirementsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for requirements\n",
    "    \"\"\"\n",
    "    requirements = []\n",
    "    for requirement in requirementsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] =requirement.ID\n",
    "        detail['Description'] = requirement.Description\n",
    "        detail['User'] = requirement.User\n",
    "        requirements.append(detail)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements():\n",
    "    \"\"\" Get all requirements\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from Requirements\"\n",
    "    requirementsResult =  execute_query(requirementsQuery)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "\n",
    "def get_defects_severity(severity):\n",
    "    \"\"\" Get defects of a given severity\n",
    "    \"\"\"\n",
    "    query = \"select * from Defect where Severity = \" + str(severity)\n",
    "    queryResult =  execute_query(query)\n",
    "    defects = build_format_defects_list(queryResult)    \n",
    "    return defects\n",
    "\n",
    "def get_testcases_category(category):\n",
    "    \"\"\" Get testcases of a given category\n",
    "    \"\"\"\n",
    "    testcasesQuery = \"select * from Testcase where Category = '\"+str(category)+\"'\"\n",
    "    testcasesResult = execute_query(testcasesQuery)\n",
    "    testcases = build_format_testcases_list(testcasesResult)\n",
    "    return testcases\n",
    "\n",
    "def get_testcases_zero_defects():\n",
    "    \"\"\" Get testcases that did not generate any defects\n",
    "    \"\"\"\n",
    "    testcasesQuery = \"Select * from Testcase where in('linkedtestcases').size() = 0\"\n",
    "    testcasesResult = execute_query(testcasesQuery)\n",
    "    testcases = build_format_testcases_list(testcasesResult)\n",
    "    print testcases\n",
    "    return testcases\n",
    "\n",
    "def get_defects_zero_testcases():\n",
    "    \"\"\" Get defects that have no associated testcases\n",
    "    \"\"\"\n",
    "    query = \"Select * from Defect where out('linkedtestcases').size() = 0\"\n",
    "    queryResult =  execute_query(query)\n",
    "    defects = build_format_defects_list(queryResult)   \n",
    "    print defects\n",
    "    return defects\n",
    "\n",
    "def get_requirements_zero_defect():\n",
    "    \"\"\" Get requirements that have no defects\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirement where out('linkeddefects').size() = 0\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements_zero_testcases():\n",
    "    \"\"\" Get requirements that have no associated testcases\n",
    "    \"\"\"\n",
    "    query = \"Select * from Requirement where in('linkedrequirements').size() = 0\"\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirement_defects(numdefects):\n",
    "    \"\"\" Get requirements that have more than a given number of defects\n",
    "    \"\"\"\n",
    "    query = \"select ID,Description,Priority from Requirement where out('linkeddefects').size() >= \" + str(numdefects)\n",
    "    requirementsResult =  execute_query(query)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    for requirement in requirements:\n",
    "        num = len(get_related_defects(requirement['ID']))\n",
    "        requirement['defectcount'] = num\n",
    "    return requirements  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Global variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the excel file with data in S3 Storage\n",
    "BrdFileName = \"Banking-BRD.xlsx\"\n",
    "# Choose or get as an input as to which Domain it belongs to i.e banking, healthcare etc\n",
    "Domain = \"Banking\"\n",
    "\n",
    "# Name of the config files in Object Storage. Rule_brd will be used specifically for parsing requirement document\n",
    "configFileName = \"sample_config.txt\"\n",
    "BRD_configFileName = \"Rule_BRD.txt\"\n",
    "# Config contents\n",
    "config = None;\n",
    "\n",
    "Path = \".//final/\"\n",
    "# Output excell\n",
    "\n",
    "# Requirements dataframe\n",
    "requirements_file_name = \"Requirements.xlsx\"\n",
    "requirements_sheet_name = \"\".join((Domain,\"-Requirements\"))\n",
    "requirements_df = None\n",
    "\n",
    "# Domain/UseCase dataframe\n",
    "domain_file_name = \"Domain.xlsx\"\n",
    "domain_sheet_name = \"\".join((Domain,\"-Domain\"))\n",
    "domain_df = None\n",
    "\n",
    "# DataElements dataframe\n",
    "dataelements_file_name =\"DataElements.xlsx\"\n",
    "dataelements_sheet_name =\"\".join((Domain,\"-Dataelements\"))\n",
    "dataelements_df = None\n",
    "\n",
    "def load_artifacts():\n",
    "    global requirements_df \n",
    "    global domain_df \n",
    "    global dataelements_df \n",
    "    global config\n",
    "    global BRD_config\n",
    "    global Path\n",
    "    Location = \"\".join((Path,requirements_file_name))\n",
    "    get_file(requirements_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    requirements_df = excel.parse(requirements_sheet_name)\n",
    "    Location = \"\".join((Path,domain_file_name))\n",
    "    get_file(domain_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    domain_df = excel.parse(domain_sheet_name)\n",
    "    Location = \"\".join((Path,dataelements_file_name))\n",
    "    get_file(dataelements_file_name,Location)\n",
    "    excel = pd.ExcelFile(Location)\n",
    "    dataelements_df = excel.parse(dataelements_sheet_name)\n",
    "    rule_text = open(configFileName)\n",
    "    config = rule_text.read()\n",
    "    BRD_rule_text = open(BRD_configFileName)\n",
    "    BRD_config = BRD_rule_text.read()\n",
    "    \n",
    "    \n",
    "\n",
    "def prepare_artifact_dataframes():\n",
    "    \"\"\" Prepare artifact dataframes by creating necessary output columns\n",
    "    \"\"\"\n",
    "    global requirements_df \n",
    "    global domain_df \n",
    "    global dataelements_df \n",
    "    req_cols_len = len(requirements_df.columns)\n",
    "    dom_cols_len = len(domain_df.columns)\n",
    "    dat_cols_len = len(dataelements_df.columns)\n",
    "    requirements_df.insert(req_cols_len, \"ClassifiedText\",\"\")\n",
    "    requirements_df.insert(req_cols_len+1, \"Keywords\",\"\")\n",
    "    requirements_df.insert(req_cols_len+2, \"DomainMatchScore\",\"\")\n",
    "    \n",
    "    domain_df.insert(dom_cols_len, \"ClassifiedText\",\"\")\n",
    "    domain_df.insert(dom_cols_len+1, \"Keywords\",\"\")\n",
    "    domain_df.insert(dom_cols_len+2, \"DataElementsMatchScore\",\"\")\n",
    "\n",
    "    dataelements_df.insert(dat_cols_len, \"ClassifiedText\",\"\")\n",
    "    dataelements_df.insert(dat_cols_len+1, \"Keywords\",\"\")\n",
    "    dataelements_df.insert(dat_cols_len+2, \"RequirementsMatchScore\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Utility functions for Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_req_text_classifier_output(artifact_df, BRD_config, output_column_name):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact_df.iterrows():\n",
    "        summary = row[\"I want to <perform some task>\"]\n",
    "        user = row[\"As a <type of user>\"]\n",
    "        user = \"\".join((user,\" want to \"))\n",
    "        summary = \"\".join((user,summary))\n",
    "        print(\"--------------\")\n",
    "        print(summary)\n",
    "        classifier_journey_output = classify_BRD_text(summary, BRD_config)\n",
    "        print(classifier_journey_output)\n",
    "        artifact_df.set_value(index, output_column_name, classifier_journey_output)\n",
    "    return artifact_df \n",
    "\n",
    "\n",
    "def add_text_classifier_output(artifact_df, config, output_column_name):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact_df.iterrows():\n",
    "        summary = row[\"Description\"]\n",
    "        print(\"--------------\")\n",
    "        print(summary)\n",
    "        classifier_journey_output = classify_text(summary, config)\n",
    "        #print(classifier_journey_output)\n",
    "        artifact_df.set_value(index, output_column_name, classifier_journey_output)\n",
    "    return artifact_df \n",
    "           \n",
    "def add_keywords_entities(artifact_df, classify_text_column_name, output_column_name):\n",
    "    \"\"\" Add keywords and entities to the artifact dataframe\"\"\"\n",
    "    for index, artifact in artifact_df.iterrows():\n",
    "        keywords_array = []\n",
    "        for row in artifact[classify_text_column_name]['Keywords']:\n",
    "            #print(row)\n",
    "            if not row['User'] in keywords_array:\n",
    "                keywords_array.append(row['User'])\n",
    "                \n",
    "        for entities in artifact[classify_text_column_name]['Entities']:\n",
    "            if not entities['text'] in keywords_array:\n",
    "                keywords_array.append(entities['text'])\n",
    "            if not entities['type'] in keywords_array:\n",
    "                keywords_array.append(entities['type'])\n",
    "        artifact_df.set_value(index, output_column_name, keywords_array)\n",
    "        print(keywords_array)\n",
    "    return artifact_df \n",
    "\n",
    "#requirements_df, domain_df, keywords_column_name, output_column_name)\n",
    "\n",
    "def populate_text_similarity_score(artifact_df1, artifact_df2, keywords_column_name, output_column_name):\n",
    "    \"\"\" Populate text similarity score to the artifact dataframes\n",
    "    \"\"\"\n",
    "    heading1 = \"Description\"\n",
    "    heading2 = \"Description\"\n",
    "    \n",
    "    try:\n",
    "        artifact_df1[heading1]\n",
    "    except: \n",
    "        heading1 = \"I want to <perform some task>\"\n",
    "    \n",
    "    try:\n",
    "        artifact_df2[heading2]\n",
    "    except: \n",
    "        heading2 = \"I want to <perform some task>\"    \n",
    "    \n",
    "    \n",
    "    for index1, artifact1 in artifact_df1.iterrows():\n",
    "        matches = []\n",
    "        top_matches = []\n",
    "        for index2, artifact2 in artifact_df2.iterrows():\n",
    "            matches.append({'ID': artifact2['ID'], \n",
    "                            'cosine_score': 0, \n",
    "                            'SubjectID':artifact1['ID']})\n",
    "            cosine_score = compute_text_similarity(\n",
    "                #artifact1['Description'], \n",
    "                #artifact2['Description'], \n",
    "                artifact1[heading1],\n",
    "                artifact2[heading2],\n",
    "                artifact1['Keywords'], \n",
    "                artifact2['Keywords'])\n",
    "            matches[index2][\"cosine_score\"] = cosine_score\n",
    "       \n",
    "        sorted_obj = sorted(matches, key=lambda x : x['cosine_score'], reverse=True)\n",
    "    \n",
    "    # This is where the lower cosine value to be truncated is set and needs to be adjusted based on output\n",
    "    \n",
    "        for obj in sorted_obj:\n",
    "            if obj['cosine_score'] > 0.6:\n",
    "                top_matches.append(obj)\n",
    "               \n",
    "        artifact_df1.set_value(index1, output_column_name, top_matches)\n",
    "    return artifact_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prepare data **\n",
    "* Load artifacts from object storage and create pandas dataframes\n",
    "* Prepare the pandas dataframes. Add additional columns required for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_artifacts()\n",
    "prepare_artifact_dataframes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run Text Classification on data **\n",
    "* Add the text classification output to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Customer want to deposit cheque in customer name in customer account number\n",
      "{'Keywords': [{'User': ''}, {'User': 'Customer'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' deposit cheque'}]}\n",
      "--------------\n",
      "Customer want to withdraw cash from an ATM\n",
      "{'Keywords': [{'User': ''}, {'User': 'Customer'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' withdraw cash'}]}\n",
      "--------------\n",
      "Customer want to want to transfer money from one account to another\n",
      "{'Keywords': [{'User': ''}, {'User': 'Customer'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' transfer money'}]}\n",
      "--------------\n",
      "Customer want to pay my utility bills online\n",
      "{'Keywords': [{'User': ''}, {'User': 'Customer'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' pay my utility bills'}]}\n",
      "--------------\n",
      "Customer want to apply for a loan\n",
      "{'Keywords': [{'User': ''}, {'User': 'Customer'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' apply for a loan'}]}\n",
      "--------------\n",
      "Banker want to request for check books\n",
      "{'Keywords': [{'User': ''}, {'User': 'Banker'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' request for check books'}]}\n",
      "--------------\n",
      "Banker want to restock sufficient cash in ATM machines\n",
      "{'Keywords': [{'User': ''}, {'User': 'Banker'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' restock sufficient cash'}]}\n",
      "--------------\n",
      "Banker want to limit the cash withdrawl from ATM machines\n",
      "{'Keywords': [{'User': ''}, {'User': 'Banker'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' limit the cash withdrawl'}]}\n",
      "--------------\n",
      "Banker want to I want to review all transactions of the day\n",
      "{'Keywords': [{'User': ''}, {'User': 'Banker'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' review all transactions'}]}\n",
      "--------------\n",
      "Banker want to review the credit history and the bank balance of customers that apply for loans\n",
      "{'Keywords': [{'User': ''}, {'User': 'Banker'}], 'Entities': [{'type': '', 'text': ''}, {'type': 'Action', 'text': ' review the credit history'}]}\n",
      "--------------\n",
      "Function deals with Verification of PIN entered by Customer at ATM. It will be used for withdrawing money, checking balance  or depositing cheque. Input required for this are Account number, Name of customer \n",
      "--------------\n",
      "View Account allows a customer to view the account balance information on deposit (saving/current), credit card, etc. The customer can also view transaction history with retention period up to a maximum of 90 days. Within this feature, the customer can request for account such as “view online, by e-mail or by post option. But the customer most be logged in the internet bank. Input required for function is account number and account name\n",
      "--------------\n",
      "This use case is intended for transfering money from one account to another. This will require source account number, target account number, IFSC code, transfer date which will say when to transfer, and which account type to be used\n",
      "--------------\n",
      "This function manages actual process of withdrawing cash, based on bill type and maximum amount limit that can be withdrawn from the ATM.\n",
      "--------------\n",
      "This function is required if a customer is willing to apply for loan. This requires type of loan like car loan, house loan. Also account number is required along with loan amount requested. \n",
      "--------------\n",
      "Function will be used by banker to fill the cash at ATM with required  bill types and necessary amount of cash. \n",
      "--------------\n",
      "Function deals with checking credit history of customer with account number and applying for loan.  The data is collected from external credit rating agency and  credit score of customer account.\n",
      "--------------\n",
      "Cheque service is the functionality by which the customer may enquiries cheque status, whether it is paid, unpaid, stopped or returned. It also allows customer to stop cheque payment and to order cheque bookto be delivered at home .The customer must be logged into Banking System.\n",
      "--------------\n",
      "If the customer wants to display his/her payment histor, review old transactions  just he/she has to click on Bill Payment History, the system will display the transaction he/she done.\n",
      "--------------\n",
      "Limit cash withdrawl function is used by banker to limit the amount of cash that can be dispensed at any given time to one customer. It will also need to invoke restock cash \n",
      "--------------\n",
      "A customer to be able into the system, he/she has to enter username and password which he/she has created before.  This function might be for a customer or an Admin also. \n",
      "--------------\n",
      "View Account allows a customer to view the minute balance information on deposit (saving/current), credit card, etc. The customer can also view transaction history with retention period up to a maximum of 90 days. Within this feature, the customer can request for account such as “view online, by e-mail or by post option. But the customer most be logged in the internet banking.\n",
      "--------------\n",
      "The customer must be logged into Banking System to be able to make his/her transaction for transfer funds. Transfer Funds allows customer to transfer funds between authorized accounts – own personal accounts. Requested transfer take place immediately or at a selected future date specified by customer. The customer can save up to a maximum of 10 accounts and update or delete the account details. All the outstanding future transfers are recorded in a table. The customer can enquire whether there is any funds transfer pending.\n",
      "--------------\n",
      "The customer most be logged into Banking System. Customers can make payments to corporations that include utilities, assessments, Insurance, telecommunications, and other services. The customers can use Online Pay Bill service to pay bills by debiting their account. This payment made to payee corporations that the customer has registered with internet banking by using the Registered Bill. But with new payee corporations that the customer has not registered, this payment can be made immediately or at a later date.  There are Enquiry Future Payment Status, this function lets customer enquires whether if has scheduled any future payments or not. And Cancel Future Payment lets customer cancels his/her scheduled future payments if he/she changes his/her mind. \n",
      "--------------\n",
      "The customer most be logged into Banking System.The customer may enquiries cheque status, whether it is paid, unpaid, stopped or returned. It also allows customer to stop cheque payment and to request for a cheque book online. \n",
      "--------------\n",
      "The customer most be logged into Banking System. Utility allows customer to change password and the secure delivery contact information. Within this feature, the customer can also change the online profile personal information that is retained by the internet banking system only. And the customer can cancel the ATM facilities. \n",
      "--------------\n",
      "The customer must be logged into Banking System. This function is used when a logged in user finishes his/her job and wants to be logged out so that no one can abuse his username.\n",
      "--------------\n",
      "An administrator is that person who makes some editing for the internet banking system like add/cancel customer, check the transactions etc. but this administrator must be valid user. Therefore the administrator must have ausername and password.\n",
      "--------------\n",
      "This function allows a customer to pay Immediate and future payment to corporations, those customers have registered the corportations.\n",
      "--------------\n",
      "This function allows a customer to pay Immediate and  future Payment to corporations that customer has not registered.\n",
      "--------------\n",
      "Select Corporation Name from the list provided Enter the  Bill Account Number, Bill Account Holder Name. And key information required, and then click’ Register. The system will appear the confirm message to confirm the transaction.\n",
      "--------------\n",
      "When the customer selects and clicks on Deregistration  Bill. The screen will display all the registered bills. Tick the box of payee(s) the customer intends to delete from the list and click cancel. Then the system will appear message confirmation to confirm the transaction. \n",
      "--------------\n",
      "Bank A creates an investigation case when the customer of bank A states that the fund transferred to Bank B has not been credited\n",
      "--------------\n",
      "Bank B obtains transaction details of the payment\n",
      "--------------\n",
      "function dealswith deposit cheque at ATM or branch office. Input required for this are Account number, account type and Customer Name\n",
      "--------------\n",
      "Customer Name  and will be used for verification, deposit , withdrawal, transfer of money and for all activities \n",
      "--------------\n",
      "Account number of the customer will be used to deposit,withdrawal, verififcation, and other banking activities\n",
      "--------------\n",
      "This number signifies how much money is available in the account\n",
      "--------------\n",
      "Debit Card Number will be required as input for withdrawing amount from ATM\n",
      "--------------\n",
      "From Account Number will be required for transfering money from source account\n",
      "--------------\n",
      "To Account Number will be required for transfering money to destination account\n",
      "--------------\n",
      "this specifies how much amount is to be deposited\n",
      "--------------\n",
      "Account Type will specify which type of account it is and will be used for deposit,  withddrawl, etc\n",
      "--------------\n",
      "This specifies the type of bills that will be withdrawn from ATM\n",
      "--------------\n",
      "This element provides the maximum limit of cash that can be withdrawn from ATM\n",
      "--------------\n",
      "This amount denotes the amount to be transferred to another account\n",
      "--------------\n",
      "This  denotes the amount to be withdrawn from the account\n",
      "--------------\n",
      "This provides the addresss for any mail communication with customer\n",
      "--------------\n",
      "How much loan amount customer is asking. For applying loan this is must have\n",
      "--------------\n",
      "This signifies the purpose of taking loan like cbuying new car or house\n",
      "--------------\n",
      "For approving loan one has to perform credit check score which is obtained from external agencies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  del sys.path[0]\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "output_column_name = \"ClassifiedText\"\n",
    "requirements_df = mod_req_text_classifier_output(requirements_df, BRD_config, output_column_name)\n",
    "\n",
    "domain_df = add_text_classifier_output(domain_df,config, output_column_name)\n",
    "dataelements_df = add_text_classifier_output(dataelements_df,config, output_column_name)\n",
    "\n",
    "#requirements_df.head()\n",
    "#domain_df.head()\n",
    "#dataelements_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Populate keywords and entities **\n",
    "* Add the keywords and entities extracted from the unstructured text to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Customer', ' deposit cheque', 'Action']\n",
      "['', 'Customer', ' withdraw cash', 'Action']\n",
      "['', 'Customer', ' transfer money', 'Action']\n",
      "['', 'Customer', ' pay my utility bills', 'Action']\n",
      "['', 'Customer', ' apply for a loan', 'Action']\n",
      "['', 'Banker', ' request for check books', 'Action']\n",
      "['', 'Banker', ' restock sufficient cash', 'Action']\n",
      "['', 'Banker', ' limit the cash withdrawl', 'Action']\n",
      "['', 'Banker', ' review all transactions', 'Action']\n",
      "['', 'Banker', ' review the credit history', 'Action']\n",
      "['', 'Customer', 'customer', ' Function', 'NP', ' money', ' balance', ' cheque', ' number', ' customer', ' Verification', 'NAME', ' PIN', ' Customer', ' ATM', ' Input', ' Account', ' Name', ' be', 'VERB']\n",
      "['', 'customer', ' a customer', 'NP', ' the account', ' balance', ' information', ' deposit', ' saving/current', ' credit', ' card', ' The customer', ' transaction', ' history', ' retention', ' period', ' a maximum', ' this feature', ' the customer', ' account', ' “ view', ' online', ' e-mail', ' post', ' option', ' the internet', ' bank', ' function', ' account number', ' name', ' View Account', 'NAME', ' Input', ' view', 'VERB', ' request', ' be']\n",
      "['', ' This use', 'NP', ' case', ' money', ' account', ' source', ' number', ' target', ' code', ' transfer', ' date', ' type', ' IFSC', 'NAME', ' require', 'VERB', ' say', ' be']\n",
      "['', ' This function', 'NP', ' actual process', ' cash', ' bill', ' type', ' maximum amount', ' limit', ' ATM', 'NAME', ' be', 'VERB']\n",
      "['', 'customer', ' This function', 'NP', ' a customer', ' loan', ' type', ' car', ' house', ' number', ' amount', ' apply', 'VERB']\n",
      "['', 'banker', ' Function', 'NP', ' banker', ' the cash', ' required bill', ' necessary amount', ' cash', ' ATM', 'NAME', ' be', 'VERB', ' fill']\n",
      "['', 'customer', ' Function', 'NP', ' credit', ' history', ' customer', ' account', ' number', ' loan', ' The data', ' external credit', ' rating', ' agency', ' score']\n",
      "['', 'customer', ' service', 'NP', ' the functionality', ' the customer', ' cheque', ' status', ' customer', ' payment', ' order', ' bookto', ' home', ' Cheque', 'NAME', ' .The', ' Banking System', ' enquiries', 'VERB', ' stop', ' be']\n",
      "['', 'customer', ' the customer', 'NP', ' payment', ' histor', ' he/she', ' the system', ' the transaction', ' Bill Payment History', 'NAME', ' display', 'VERB', ' click']\n",
      "['', 'banker', 'customer', ' cash', 'NP', ' withdrawl', ' function', ' banker', ' the amount', ' time', ' customer', ' restock', ' Limit', 'NAME', ' limit', 'VERB', ' be', ' need', ' invoke']\n",
      "['', 'customer', ' A customer', 'NP', ' the system', ' he/she', ' password', ' This function', ' a customer', ' Admin', 'NAME', ' be', 'VERB', ' enter']\n",
      "['', 'customer', ' a customer', 'NP', ' the minute', ' balance', ' information', ' deposit', ' saving/current', ' credit', ' card', ' The customer', ' transaction', ' history', ' retention', ' period', ' a maximum', ' this feature', ' the customer', ' account', ' “ view', ' online', ' e-mail', ' post', ' option', ' the internet', ' banking', ' View Account', 'NAME', ' view', 'VERB', ' request', ' be']\n",
      "['', 'customer', ' The customer', 'NP', ' transaction', ' transfer', ' customer', ' place', ' a selected future', ' date', ' a maximum', ' update', ' the account', ' the outstanding future', ' a table', ' Banking System', 'NAME', ' be', 'VERB', ' make', ' Transfer', ' take', ' save', ' delete', ' enquire']\n",
      "['', 'customer', 'Customer', ' The customer', 'NP', ' service', ' account', ' This payment', ' the customer', ' internet', ' banking', ' new payee', ' this payment', ' a later date', ' this function', ' customer', ' mind', ' Banking System', 'NAME', ' Insurance', ' Online Pay Bill', ' Registered Bill', ' Enquiry Future Payment Status', ' Cancel Future Payment', ' be', 'VERB', ' make', ' use', ' pay', ' payee']\n",
      "['', 'customer', ' The customer', 'NP', ' customer', ' cheque', ' status', ' payment', ' a cheque', ' book', ' online', ' Banking System.The', 'NAME', ' be', 'VERB', ' enquiries', ' stop', ' request']\n",
      "['', 'customer', ' The customer', 'NP', ' customer', ' password', ' the secure', ' delivery', ' contact', ' information', ' this feature', ' the customer', ' the online', ' personal information', ' the internet', ' banking', ' system', ' Banking System', 'NAME', ' Utility', ' ATM', ' be', 'VERB', ' change', ' cancel']\n",
      "['', 'customer', ' The customer', 'NP', ' This function', ' job', ' no one', ' username', ' Banking System', 'NAME', ' be', 'VERB', ' abuse']\n",
      "['', 'customer', ' An administrator', 'NP', ' person', ' the internet', ' banking', ' system', ' add/cancel customer', ' this administrator', ' valid user', ' the administrator', ' ausername', ' password', ' check', 'VERB', ' be', ' have']\n",
      "['', 'customer', ' This function', 'NP', ' a customer', ' future payment', ' Immediate', 'NAME', ' pay', 'VERB']\n",
      "['', 'customer', ' This function', 'NP', ' a customer', ' customer', ' Immediate', 'NAME', ' Payment', ' pay', 'VERB']\n",
      "['', ' Name', 'NP', ' the list', ' key information', ' The system', ' the confirm message', ' the transaction', ' Corporation', 'NAME', ' Enter', ' Bill Account Number', ' Bill Account Holder Name', ' ’ Register', ' click', 'VERB', ' appear', ' confirm']\n",
      "['', 'customer', ' the customer', 'NP', ' The screen', ' the box', ' payee', ' the list', ' click cancel', ' the system', ' message', ' confirmation', ' the transaction', ' Deregistration Bill', 'NAME', ' display', 'VERB', ' Tick', ' delete', ' appear', ' confirm']\n",
      "['', 'customer', ' an investigation', 'NP', ' case', ' the customer', ' bank', ' the fund', ' Bank A', 'NAME', ' A', ' Bank B']\n",
      "['', ' transaction', 'NP', ' the payment', ' Bank B', 'NAME']\n",
      "['', 'Customer', ' function', 'NP', ' deposit', ' cheque', ' branch', ' office', ' Input', ' number', ' type', ' ATM', 'NAME', ' Account', ' Customer Name']\n",
      "['', 'Customer', ' verification', 'NP', ' deposit', ' withdrawal', ' transfer', ' money', ' Customer Name', 'NAME', ' be', 'VERB']\n",
      "['', 'customer', ' number', 'NP', ' the customer', ' withdrawal', ' verififcation', ' other banking', ' Account', 'NAME', ' be', 'VERB', ' deposit']\n",
      "['', ' This number', 'NP', ' much money', ' the account']\n",
      "['', ' input', 'NP', ' amount', ' Debit Card Number', 'NAME', ' ATM', ' be', 'VERB']\n",
      "['', ' money', 'NP', ' source', ' account', ' Account Number', 'NAME', ' be', 'VERB']\n",
      "['', ' money', 'NP', ' destination', ' account', ' Account Number', 'NAME', ' be', 'VERB']\n",
      "['', ' much amount', 'NP', ' be', 'VERB']\n",
      "['', ' type', 'NP', ' account', ' deposit', ' withddrawl', ' Account Type', 'NAME', ' specify', 'VERB', ' be']\n",
      "['', ' the type', 'NP', ' ATM', 'NAME', ' be', 'VERB']\n",
      "['', ' This element', 'NP', ' the maximum limit', ' cash', ' ATM', 'NAME', ' be', 'VERB']\n",
      "['', ' This amount', 'NP', ' the amount', ' another account', ' be', 'VERB']\n",
      "['', ' the amount', 'NP', ' the account', ' be', 'VERB']\n",
      "['', 'customer', ' the addresss', 'NP', ' any mail', ' communication', ' customer']\n",
      "['', 'customer', ' much loan', 'NP', ' amount', ' customer', ' loan', ' have', 'VERB']\n",
      "['', ' the purpose', 'NP', ' loan', ' new car', ' house']\n",
      "['', ' loan', 'NP', ' credit', ' check', ' score', ' perform', 'VERB']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "classify_text_column_name = \"ClassifiedText\"\n",
    "output_column_name = \"Keywords\"\n",
    "requirements_df = add_keywords_entities(requirements_df, classify_text_column_name, output_column_name)\n",
    "domain_df = add_keywords_entities(domain_df, classify_text_column_name, output_column_name)\n",
    "dataelements_df = add_keywords_entities(dataelements_df, classify_text_column_name, output_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Correlate keywords between artifacts **\n",
    "* Add the text similarity score of associated artifacts to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Short</th>\n",
       "      <th>Description</th>\n",
       "      <th>ClassifiedText</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>RequirementsMatchScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE1</td>\n",
       "      <td>Cus_Nme</td>\n",
       "      <td>Customer Name  and will be used for verificati...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  verification, NP,  deposit,  wit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE2</td>\n",
       "      <td>Acc_num</td>\n",
       "      <td>Account number of the customer will be used to...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'customer...</td>\n",
       "      <td>[, customer,  number, NP,  the customer,  with...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE3</td>\n",
       "      <td>Amt_avail</td>\n",
       "      <td>This number signifies how much money is availa...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  This number, NP,  much money,  the account]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE4</td>\n",
       "      <td>Debit_pin</td>\n",
       "      <td>Debit Card Number will be required as input fo...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  input, NP,  amount,  Debit Card Number, NA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE5</td>\n",
       "      <td>From_AcctNum</td>\n",
       "      <td>From Account Number will be required for trans...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  money, NP,  source,  account,  Account Num...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID         Short                                        Description  \\\n",
       "0  DE1       Cus_Nme  Customer Name  and will be used for verificati...   \n",
       "1  DE2       Acc_num  Account number of the customer will be used to...   \n",
       "2  DE3     Amt_avail  This number signifies how much money is availa...   \n",
       "3  DE4     Debit_pin  Debit Card Number will be required as input fo...   \n",
       "4  DE5  From_AcctNum  From Account Number will be required for trans...   \n",
       "\n",
       "                                      ClassifiedText  \\\n",
       "0  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "1  {'Keywords': [{'User': ''}, {'User': 'customer...   \n",
       "2  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "3  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "4  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "\n",
       "                                            Keywords RequirementsMatchScore  \n",
       "0  [, Customer,  verification, NP,  deposit,  wit...                         \n",
       "1  [, customer,  number, NP,  the customer,  with...                         \n",
       "2    [,  This number, NP,  much money,  the account]                         \n",
       "3  [,  input, NP,  amount,  Debit Card Number, NA...                         \n",
       "4  [,  money, NP,  source,  account,  Account Num...                         "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#requirements_df.get_value(0,'ClassifiedText')\n",
    "#domain_df.head()\n",
    "dataelements_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:90: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "keywords_column_name = \"Keywords\"\n",
    "output_column_name = \"DomainMatchScore\"\n",
    "requirements_df = populate_text_similarity_score(requirements_df, domain_df, keywords_column_name, output_column_name)\n",
    "\n",
    "output_column_name = \"DataElementsMatchScore\"\n",
    "domain_df = populate_text_similarity_score(domain_df, dataelements_df, keywords_column_name, output_column_name)\n",
    "\n",
    "output_column_name = \"RequirementsMatchScore\"\n",
    "dataelements_df = populate_text_similarity_score(dataelements_df, requirements_df, keywords_column_name, output_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section will be used to create the Output in excell format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action(summary):\n",
    "    action_string = \"\"\n",
    "    count = 1\n",
    "    for entities in summary['Entities']:\n",
    "        #print(entities['text'])\n",
    "        if not entities['text'] in action_string:\n",
    "                action_string = action_string + entities['text']\n",
    "                count = count + 1\n",
    "                if count == 2:\n",
    "                    count = 1\n",
    "                    action_string = action_string + \",\"\n",
    "    \n",
    "    #print(action_string)\n",
    "    return action_string\n",
    "\n",
    "def lookup_use_case(temp,artifact3_df,column_name):\n",
    "    #print(artifact3_df.get_value(0,'ID'))\n",
    "    val = \"\"\n",
    "    rowNum = len(artifact3_df.index)\n",
    "    #print(rowNum)\n",
    "    for j in range(0,rowNum):\n",
    "        if temp == artifact3_df.get_value(j,'ID'):\n",
    "            val = artifact3_df.get_value(j,column_name)\n",
    "            #print(val)\n",
    "    \n",
    "    return val       \n",
    "        \n",
    "    \n",
    "def extract_match(summary,no_of_matches,artifact3_df,column_name):\n",
    "    match_array_description = []\n",
    "    match_array_id = []\n",
    "    for index in range(0,no_of_matches):\n",
    "        try:\n",
    "            temp = summary[index][\"ID\"]\n",
    "            \n",
    "        except:\n",
    "              break\n",
    "    \n",
    "            \n",
    "        temp = summary[index][\"ID\"]\n",
    "        #print(temp)\n",
    "        use_case = lookup_use_case(temp,artifact3_df,column_name)\n",
    "        \n",
    "        match_array_id.append(temp)\n",
    "        match_array_description.append(use_case + \"(\" + str(round(summary[index][\"cosine_score\"], 2)) +\")\")\n",
    "        #print(use_case)\n",
    "            \n",
    "    \n",
    "    #print(\"************\")\n",
    "    #print(match_array_id)       \n",
    "    #print(\"************\")\n",
    "    return (match_array_description,match_array_id)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def extract_action_requirements_df(artifact1_df, artifact2_df):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    for index, row in artifact2_df.iterrows():\n",
    "        summary = row[\"ClassifiedText\"]\n",
    "        classifier_journey_output = extract_action(summary)\n",
    "        artifact1_df.set_value(index, 'Action', classifier_journey_output)\n",
    "    return artifact1_df \n",
    "\n",
    "def extract_bestmatch(artifact1_df, artifact2_df, artifact3_df, artifact4_df):\n",
    "    \"\"\" Add text classifier output to the artifact dataframe based on rule defined in config\n",
    "    \"\"\"\n",
    "    No_of_matches_user_function = 2\n",
    "    No_of_matches_data_elements = 8\n",
    "    best_match_output_domain_function = []\n",
    "    best_match_output_dataelement_function = []\n",
    "    \n",
    "    for index, row in artifact2_df.iterrows():\n",
    "        summary = row[\"DomainMatchScore\"]\n",
    "        #print(summary)\n",
    "        (best_match_output_domain_function,best_match_output_domain_id) = extract_match(summary, No_of_matches_user_function, artifact3_df,\"User Function\")\n",
    "        #print(best_match_output_domain_id)\n",
    "        artifact1_df.set_value(index, 'Functionality Match', best_match_output_domain_function)\n",
    "        \n",
    "        for index2 in best_match_output_domain_id:\n",
    "            #print(index2)\n",
    "            row_domain = len(artifact3_df.index)\n",
    "            for p in range(0,row_domain):\n",
    "                if index2 == artifact3_df.get_value(p,'ID'):\n",
    "                    dataelement_summary = artifact3_df.get_value(p,'DataElementsMatchScore')\n",
    "                    #print(dataelement_summary)\n",
    "                    #print(\"------\")\n",
    "                    (best_match_output_dataelement_function,best_match_output_dataelement_id) = extract_match(dataelement_summary, No_of_matches_data_elements, artifact4_df, \"Short\")\n",
    "            best_match_output_dataelement_function.extend(best_match_output_dataelement_function)\n",
    "          \n",
    "        #print(best_match_output_dataelement_function)\n",
    "        #print(\"==============\")\n",
    "        #print(index)\n",
    "        best_match_output_dataelement_function = list(set(best_match_output_dataelement_function))\n",
    "        artifact1_df.set_value(index, 'Attributes Match', best_match_output_dataelement_function)\n",
    "    return artifact1_df \n",
    "\n",
    "\n",
    "#if not any(d.get('text', None) == text for d in responsejson['Keywords']):\n",
    "#            responsejson['Keywords'].append({\"User\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       User                       Action  \\\n",
      "0  Customer              deposit cheque,   \n",
      "1  Customer               withdraw cash,   \n",
      "2  Customer              transfer money,   \n",
      "3  Customer        pay my utility bills,   \n",
      "4  Customer            apply for a loan,   \n",
      "5    Banker     request for check books,   \n",
      "6    Banker     restock sufficient cash,   \n",
      "7    Banker    limit the cash withdrawl,   \n",
      "8    Banker     review all transactions,   \n",
      "9    Banker   review the credit history,   \n",
      "\n",
      "                                Functionality Match  \\\n",
      "0          [Verify PIN(0.88), Deposit Cheque(0.88)]   \n",
      "1           [Verify PIN(0.76), Withdraw cash(0.76)]   \n",
      "2          [Transfer Money(0.77), Verify PIN(0.63)]   \n",
      "3                 [Pay Bills (0.87), Utility(0.71)]   \n",
      "4            [Apply loan(0.82), Credit_check(0.82)]   \n",
      "5                           [Cheque Services(0.65)]   \n",
      "6            [Restock cash(0.67), Limit Cash(0.67)]   \n",
      "7           [Limit Cash(0.75), Withdraw cash(0.67)]   \n",
      "8  [Review transactions(0.71), View Account (0.61)]   \n",
      "9         [View Account (0.71), Credit_check(0.71)]   \n",
      "\n",
      "                                    Attributes Match  \n",
      "0  [Acc_type(0.71), To_AcctNum(0.66), Cus_Nme(0.6...  \n",
      "1  [Amt_wdrl(0.77), Acc_type(0.63), Amt_trnsfr(0....  \n",
      "2  [Bill_type(0.78), From_AcctNum(0.87), Amt_depo...  \n",
      "3  [Max_limit(0.69), Amt_wdrl(0.63), Debit_pin(0....  \n",
      "4  [Amt_avail(0.6), Cred_Score(0.78), Cust_Addr(0...  \n",
      "5  [Amt_wdrl(0.63), Bill_type(0.62), Acc_num(0.63...  \n",
      "6  [Amt_wdrl(0.77), Cus_Nme(0.62), Max_limit(0.73...  \n",
      "7  [Amt_wdrl(0.77), Acc_type(0.63), Amt_trnsfr(0....  \n",
      "8  [Amt_wdrl(0.77), Acc_num(0.78), To_AcctNum(0.7...  \n",
      "9  [Amt_avail(0.6), Cred_Score(0.78), Cust_Addr(0...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "no_of_rows_brd = len(requirements_df.index)\n",
    "\n",
    "index = range(0,no_of_rows_brd)\n",
    "columns = ['User','Action', 'Functionality Match', 'Attributes Match']\n",
    "\n",
    "\n",
    "SimMean = pd.DataFrame(index=index, columns=columns)\n",
    "#print(requirements_df)\n",
    "SimMean.loc[0:no_of_rows_brd,'User'] = requirements_df.loc[0:no_of_rows_brd,'As a <type of user>'].values\n",
    "SimMean = extract_action_requirements_df(SimMean,requirements_df)\n",
    "SimMean = extract_bestmatch(SimMean,requirements_df,domain_df,dataelements_df)\n",
    "#SimMean = extract_bestmatch_domaintodataelem(SimMean,domain_df)\n",
    "SimMean.get_value(1,\"Attributes Match\")\n",
    "print(SimMean)\n",
    "\n",
    "writer = pd.ExcelWriter('final_output.xlsx', engine='xlsxwriter')\n",
    "SimMean.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"*\"**********************************************************\"\n",
    "# Next steps :\n",
    "\n",
    "* Populate the correct wording in 3 sheets to provide more accurate and insightful data\n",
    "* Use OrientdB to graph the result of cosine\n",
    "* Use Node Red to start a UI dashboard\n",
    "* Optmize code to reduce memory usage\n",
    "* Move the components like Notebook,OrientDB etc to EC2 AWS ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utility functions to store entities and relations in Orient DB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_requirements(requirements_df):\n",
    "    \"\"\" Store requirements into the database\n",
    "    \"\"\"\n",
    "    for index, row in requirements_df.iterrows():\n",
    "        attrs = {}\n",
    "        reqid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"I want to <perform some task>\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = reqid\n",
    "        attrs[\"User\"]= str(row[\"As a <type of user>\"])\n",
    "        create_record(requirement_classname, reqid, attrs)    \n",
    "        \n",
    "def store_domain(domain_df):  \n",
    "    \"\"\" Store domain which has user functions into the database\n",
    "    \"\"\"\n",
    "    for index, row in domain_df.iterrows():\n",
    "        attrs = {}\n",
    "        tcaseid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"Description\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = tcaseid\n",
    "        attrs[\"Action\"] = str(row[\"User Function\"])\n",
    "        create_record(domain_classname, tcaseid, attrs)\n",
    "        \n",
    "def store_dataelements(dataelements_df):\n",
    "    \"\"\" Store data elements or attributes into the database\n",
    "    \"\"\"\n",
    "    for index, row in dataelements_df.iterrows():\n",
    "        attrs = {}\n",
    "        defid = row[\"ID\"]\n",
    "        attrs[\"Description\"] = row[\"Description\"].replace('\\n', ' ').replace('\\r', '')\n",
    "        attrs[\"ID\"] = defid\n",
    "        attrs[\"Short\"] = str(row[\"Short\"])\n",
    "        create_record(dataelement_classname, defid, attrs)\n",
    "        \n",
    "def store_dataelements_requirement_mapping(dataelements_df):\n",
    "    \"\"\" Store the related requirements for testcases into the database\n",
    "    \"\"\"\n",
    "    for index, row in dataelements_df.iterrows():\n",
    "        tcaseid = row[\"ID\"]\n",
    "        requirements = row[\"RequirementsMatchScore\"]\n",
    "        for requirement in requirements:\n",
    "            reqid = requirement[\"ID\"]\n",
    "            attributes = {}\n",
    "            attributes['score'] = requirement['cosine_score']\n",
    "            create_dataelements_requirement_edge(tcaseid,reqid, attributes)\n",
    "            \n",
    "def store_domain_dataelement_mapping(domain_df):\n",
    "    \"\"\" Store the related dataelement for the domain into the database\n",
    "    \"\"\"\n",
    "    for index, row in domain_df.iterrows():\n",
    "        domainid = row[\"ID\"]\n",
    "        dataelements = row[\"DataElementsMatchScore\"]\n",
    "        count = 0\n",
    "        print(\"---------\")\n",
    "        for dataelement in dataelements:\n",
    "            \n",
    "            if count < 4:\n",
    "                dataelementid = dataelement[\"ID\"]\n",
    "                attributes = {}\n",
    "                attributes['score'] = dataelement[\"cosine_score\"]\n",
    "                create_domain_dataelements_edge(domainid,dataelementid, attributes)\n",
    "                count = count + 1\n",
    "            \n",
    "def store_requirement_domain_mapping(requirements_df):\n",
    "    \"\"\" Store the related domains for the requirements in the database\n",
    "    \"\"\"\n",
    "    for index, row in requirements_df.iterrows():\n",
    "        count = 0\n",
    "        reqid = row[\"ID\"]\n",
    "        functionalities = row[\"DomainMatchScore\"]\n",
    "        print(\"----------\") \n",
    "        for functionality in functionalities:\n",
    "            \n",
    "            if count < 2:  \n",
    "                functionalityID = functionality[\"ID\"]\n",
    "                cosine_score =  functionality[\"cosine_score\"]\n",
    "                attributes = {}\n",
    "                attributes['score'] = cosine_score\n",
    "                create_requirement_domain_edge(reqid, functionalityID, attributes)\n",
    "                count = count + 1\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Store artifacts data and relations into OrientDB **\n",
    "* Drop and create a database\n",
    "* Create classes for each category of artifact\n",
    "* Store artifact data\n",
    "* Store artifact relations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ID': 'U1', 'SubjectID': 'R01', 'cosine_score': 0.8819171036881969},\n",
       " {'ID': 'U4', 'SubjectID': 'R01', 'cosine_score': 0.8164965809277261},\n",
       " {'ID': 'U11', 'SubjectID': 'R01', 'cosine_score': 0.7453559924999299},\n",
       " {'ID': 'U14', 'SubjectID': 'R01', 'cosine_score': 0.7453559924999299},\n",
       " {'ID': 'U2', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U3', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U6', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U8', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U15', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U16', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U17', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666},\n",
       " {'ID': 'U23', 'SubjectID': 'R01', 'cosine_score': 0.6666666666666666}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements_df.get_value(0,'DomainMatchScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>ClassifiedText</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DataElementsMatchScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1</td>\n",
       "      <td>Verify PIN</td>\n",
       "      <td>Function deals with Verification of PIN entere...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer, customer,  Function, NP,  money, ...</td>\n",
       "      <td>[{'ID': 'DE5', 'cosine_score': 0.8660254037844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2</td>\n",
       "      <td>Check Account Balance</td>\n",
       "      <td>This use case deals with checking the current ...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  This use, NP,  case,  the current account,...</td>\n",
       "      <td>[{'ID': 'DE4', 'cosine_score': 0.7071067811865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U3</td>\n",
       "      <td>Transfer Money</td>\n",
       "      <td>This use case is intended for transfering mone...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  This use, NP,  case,  money,  account,  so...</td>\n",
       "      <td>[{'ID': 'DE5', 'cosine_score': 0.9682458365518...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U4</td>\n",
       "      <td>Deposit Cheque</td>\n",
       "      <td>function dealswith deposit cheque at ATM or br...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  function, NP,  deposit,  cheque,...</td>\n",
       "      <td>[{'ID': 'DE8', 'cosine_score': 0.7071067811865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U5</td>\n",
       "      <td>Withdraw cash</td>\n",
       "      <td>This function manages actual process of withdr...</td>\n",
       "      <td>{'Keywords': [{'User': ''}], 'Entities': [{'ty...</td>\n",
       "      <td>[,  This function, NP,  actual process,  cash,...</td>\n",
       "      <td>[{'ID': 'DE9', 'cosine_score': 0.8770580193070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          User Function  \\\n",
       "0  U1             Verify PIN   \n",
       "1  U2  Check Account Balance   \n",
       "2  U3         Transfer Money   \n",
       "3  U4         Deposit Cheque   \n",
       "4  U5          Withdraw cash   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Function deals with Verification of PIN entere...   \n",
       "1  This use case deals with checking the current ...   \n",
       "2  This use case is intended for transfering mone...   \n",
       "3  function dealswith deposit cheque at ATM or br...   \n",
       "4  This function manages actual process of withdr...   \n",
       "\n",
       "                                      ClassifiedText  \\\n",
       "0  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "1  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "2  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "3  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "4  {'Keywords': [{'User': ''}], 'Entities': [{'ty...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [, Customer, customer,  Function, NP,  money, ...   \n",
       "1  [,  This use, NP,  case,  the current account,...   \n",
       "2  [,  This use, NP,  case,  money,  account,  so...   \n",
       "3  [, Customer,  function, NP,  deposit,  cheque,...   \n",
       "4  [,  This function, NP,  actual process,  cash,...   \n",
       "\n",
       "                              DataElementsMatchScore  \n",
       "0  [{'ID': 'DE5', 'cosine_score': 0.8660254037844...  \n",
       "1  [{'ID': 'DE4', 'cosine_score': 0.7071067811865...  \n",
       "2  [{'ID': 'DE5', 'cosine_score': 0.9682458365518...  \n",
       "3  [{'ID': 'DE8', 'cosine_score': 0.7071067811865...  \n",
       "4  [{'ID': 'DE9', 'cosine_score': 0.8770580193070...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "PyOrientSchemaException",
     "evalue": "com.orientechnologies.orient.core.exception.OSchemaException - Class 'Requirements' already exists in current database\r\n\tDB name=\"SoftwareDesignAI\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mPyOrientSchemaException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-3ba641a34578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataelement_classname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DataElements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcreate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement_classname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#create_class(domain_classname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#create_class(dataelement_classname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-e036c7adb7d1>\u001b[0m in \u001b[0;36mcreate_class\u001b[0;34m(classname)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m     16\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"create class \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclassname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" extends V\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentityname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyorient/orient.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CommandMessage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mQUERY_CMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyorient/messages/commands.py\u001b[0m in \u001b[0;36mfetch_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# decode header only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mCommandMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQUERY_ASYNC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyorient/messages/base.py\u001b[0m in \u001b[0;36mfetch_response\u001b[0;34m(self, *_continue)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# already fetched, get last results as cache info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyorient/messages/base.py\u001b[0m in \u001b[0;36m_decode_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decode_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyorient/messages/base.py\u001b[0m in \u001b[0;36m_decode_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m             raise PyOrientCommandException(\n\u001b[1;32m    181\u001b[0m                 \u001b[0mexception_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'utf8'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;34m[\u001b[0m \u001b[0mexception_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'utf8'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPyOrientSchemaException\u001b[0m: com.orientechnologies.orient.core.exception.OSchemaException - Class 'Requirements' already exists in current database\r\n\tDB name=\"SoftwareDesignAI\""
     ]
    }
   ],
   "source": [
    "#drop_database(\"SoftwareDesignAI\")\n",
    "#create_database(\"SoftwareDesignAI\", \"admin\", \"admin\")\n",
    "\n",
    "requirement_classname = \"Requirements\"\n",
    "domain_classname = \"Domains\"\n",
    "dataelement_classname = \"DataElements\"\n",
    "\n",
    "#create_class(requirement_classname)\n",
    "#create_class(domain_classname)\n",
    "#create_class(dataelement_classname)\n",
    "\n",
    "\n",
    "\n",
    "#store_requirements(requirements_df)\n",
    "#store_dataelements(dataelements_df)\n",
    "#store_domain(domain_df)\n",
    "\n",
    "\n",
    "#store_requirement_domain_mapping(requirements_df)\n",
    "#store_domain_dataelement_mapping(domain_df)\n",
    "#store_dataelements_requirement_mapping(dataelements_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform results for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(print key,testcases[key])? (<ipython-input-202-2b2c360acac3>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-202-2b2c360acac3>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print key,testcases[key]\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(print key,testcases[key])?\n"
     ]
    }
   ],
   "source": [
    "def get_artifacts_mapping_d3_tree(defectId):\n",
    "    \"\"\" Create an artifacts mapping json for display by d3js tree widget\n",
    "    \"\"\"\n",
    "    depTree = {}\n",
    "    depTree['ID'] = defectId\n",
    "    testcases = get_related_testcases(defectId)\n",
    "    \n",
    "    depTree['children'] = []\n",
    "    i=1\n",
    "    for key in testcases:\n",
    "        print key,testcases[key]\n",
    "        testcaseChildren = {}\n",
    "        testcaseChildren['ID'] = key\n",
    "        testcaseChildren['Score'] = testcases[key]\n",
    "        testcaseChildren['children'] = []\n",
    "        depTree['children'].append(testcaseChildren)\n",
    "        requirements = get_related_requirements(key)\n",
    "        \n",
    "        for key in requirements:\n",
    "            requirementChildren = {}\n",
    "            requirementChildren['ID']=key\n",
    "            requirementChildren['Score']=requirements[key]\n",
    "            testcaseChildren['children'].append(requirementChildren)\n",
    "    return depTree \n",
    "\n",
    "def get_artifacts_mapping_d3_network(defectid):\n",
    "    \"\"\" Create an artifacts mapping json for display by d3js network widget\n",
    "    \"\"\"\n",
    "    nodes =[]\n",
    "    links =[] \n",
    "    defect = {}\n",
    "    defect['id'] = defectid\n",
    "    defect['group'] = 1\n",
    "    nodes.append(defect)\n",
    "    \n",
    "    testcases = get_related_testcases(defectid)\n",
    "    \n",
    "    for key in testcases:\n",
    "        testcase ={}\n",
    "        testcaseid = key\n",
    "        testcase['id'] = testcaseid\n",
    "        testcase['group'] = 2\n",
    "        if testcase not in nodes:\n",
    "            nodes.append(testcase)\n",
    "        \n",
    "        link = {}\n",
    "        link['source'] = defectid\n",
    "        link['target']=testcaseid\n",
    "        link['value']=testcases[testcaseid]\n",
    "        links.append(link)\n",
    "        \n",
    "        requirements = get_related_requirements(key)\n",
    "        for key in requirements:\n",
    "            requirement ={}\n",
    "            requirement['id'] = key\n",
    "            requirement['group'] = 3\n",
    "            if requirement not in nodes:\n",
    "                nodes.append(requirement)\n",
    "            \n",
    "            link = {}\n",
    "            link['source'] = testcaseid\n",
    "            link['target'] = key\n",
    "            link['value'] = requirements[key]\n",
    "            links.append(link)\n",
    "    result ={}\n",
    "    result[\"nodes\"] = nodes\n",
    "    result[\"links\"] = links\n",
    "    return result\n",
    "\n",
    "def get_tc_req_mapping_d3_network(testcaseid):\n",
    "    \"\"\" Create a testcases to requirement mapping json for display by d3js network widget\n",
    "    \"\"\"\n",
    "    nodes =[]\n",
    "    links =[] \n",
    "    testcase = {}\n",
    "    testcase['id'] = testcaseid\n",
    "    testcase['group'] = 2\n",
    "    nodes.append(testcase)\n",
    "    requirements = get_related_requirements(testcaseid)\n",
    "    for key in requirements:            \n",
    "        requirement ={}\n",
    "        requirement['id'] = key\n",
    "        requirement['group'] = 3\n",
    "        nodes.append(requirement)\n",
    "            \n",
    "        link = {}\n",
    "        link['source'] = testcaseid\n",
    "        link['target'] = key\n",
    "        link['value'] = requirements[key]\n",
    "        links.append(link)\n",
    "    result ={}\n",
    "    result[\"nodes\"] = nodes\n",
    "    result[\"links\"] = links\n",
    "    return result\n",
    "\n",
    "def transform_defects_d3_bubble(defects):\n",
    "    \"\"\" Transform the defects list output to a json for display by d3js bubble chart\"\"\"\n",
    "    defectsList = {}\n",
    "    defectsList['name'] = \"defect\"\n",
    "    children = []\n",
    "    for defect in defects:\n",
    "        detail = {}\n",
    "        sizeList = [400,230,130]\n",
    "        detail[\"ID\"] = defect['ID']\n",
    "        severity = int(defect['Severity'])\n",
    "        detail[\"group\"] = str(severity)\n",
    "        detail[\"size\"] = sizeList[severity-1]\n",
    "        children.append(detail)\n",
    "    defectsList['children'] = children \n",
    "    return defectsList\n",
    "\n",
    "def transform_testcases_d3_bubble(testcases):\n",
    "    \"\"\" Transform the testcases list output to a json for display by d3js bubble chart\"\"\"\n",
    "    testcasesList = {}\n",
    "    testcasesList['name'] = \"test\"\n",
    "    sizeList = {}\n",
    "    sizeList[\"FVT\"]=200\n",
    "    sizeList[\"TVT\"]=110\n",
    "    sizeList[\"SVT\"]=400\n",
    "    children = []\n",
    "    for testcase in testcases:\n",
    "        detail = {}\n",
    "        detail[\"ID\"] = testcase['ID']\n",
    "        detail[\"group\"] = testcase['Category']\n",
    "        detail[\"size\"]= sizeList[testcase['Category']]\n",
    "        children.append(detail)\n",
    "    testcasesList['children'] = children \n",
    "    return testcasesList\n",
    "\n",
    "def transform_requirements_d3_bubble(requirements):\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"requirement\"\n",
    "    sizeList = {}\n",
    "    sizeList[1]=300\n",
    "    sizeList[2]=100\n",
    "    sizeList[3]=75\n",
    "    children = []\n",
    "    for requirement in requirements:\n",
    "        detail = {}\n",
    "        size = 0\n",
    "        detail[\"ID\"] = requirement['ID']\n",
    "        detail[\"group\"] = requirement['User']\n",
    "        if requirement['User'] == 'Customer':\n",
    "            size = 2\n",
    "        elif requirement['User'] == 'Banker':\n",
    "            size = 3\n",
    "        else:\n",
    "            size = 1\n",
    "        detail[\"size\"]= sizeList[size]\n",
    "        if 'defectcount' in requirement:\n",
    "            detail['defectcount'] = requirement['defectcount']\n",
    "        children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "def merge_apply_filters_d3_bubble(mainList, filterList):\n",
    "    \"\"\" Add a filter attribute to the list elements for processing on UI\n",
    "    \"\"\"\n",
    "    mainListChildren = mainList['children']\n",
    "    filterListChildren = filterList['children']\n",
    "    for child in mainListChildren:\n",
    "        child['filter'] = 0\n",
    "        for child1 in filterListChildren:\n",
    "            if ( child['ID'] == child1['ID']):\n",
    "                child['filter'] = 1\n",
    "    return mainList  \n",
    "\n",
    "def setup_download_excel():\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    \n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"download\"\n",
    "    children = []\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"final_output.xlsx\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"excel_download.jpg\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following snippet is for temporary purpose and will be used to check server side programing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"forCmd\": \"GetExcel\",\n",
      "  \"response\": {\n",
      "    \"name\": \"download\",\n",
      "    \"children\": [\n",
      "      {\n",
      "        \"filename\": \"final_output.xlsx\",\n",
      "        \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
      "      },\n",
      "      {\n",
      "        \"filename\": \"excel_download.jpg\",\n",
      "        \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def build_format_requirements_list(requirementsResult):\n",
    "    \"\"\" Build and format the OrientDB query results for requirements\n",
    "    \"\"\"\n",
    "    requirements = []\n",
    "    for requirement in requirementsResult:\n",
    "        detail = {}\n",
    "        detail['ID'] =requirement.ID\n",
    "        detail['Description'] = requirement.Description\n",
    "        detail['User'] = requirement.User\n",
    "        requirements.append(detail)\n",
    "    return requirements  \n",
    "\n",
    "def get_requirements():\n",
    "    \"\"\" Get all requirements\n",
    "    \"\"\"\n",
    "    requirementsQuery = \"select * from Requirements\"\n",
    "    requirementsResult =  execute_query(requirementsQuery)\n",
    "    requirements = build_format_requirements_list(requirementsResult)\n",
    "    return requirements  \n",
    "def transform_requirements_d3_bubble(requirements):\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"requirement\"\n",
    "    sizeList = {}\n",
    "    sizeList[1]=300\n",
    "    sizeList[2]=100\n",
    "    sizeList[3]=75\n",
    "    children = []\n",
    "    for requirement in requirements:\n",
    "        detail = {}\n",
    "        size = 0\n",
    "        detail[\"ID\"] = requirement['ID']\n",
    "        detail[\"group\"] = requirement['User']\n",
    "        if requirement['User'] == 'Customer':\n",
    "            size = 2\n",
    "        elif requirement['User'] == 'Banker':\n",
    "            size = 3\n",
    "        else:\n",
    "            size = 1\n",
    "        detail[\"size\"]= sizeList[size]\n",
    "        if 'defectcount' in requirement:\n",
    "            detail['defectcount'] = requirement['defectcount']\n",
    "        children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "\n",
    "#wsresponse = {}\n",
    "#wsresponse[\"forCmd\"] = \"ReqsList\"\n",
    "#requirements = get_requirements()\n",
    "#wsresponse[\"response\"] = transform_requirements_d3_bubble(requirements)\n",
    "#print(json.dumps(wsresponse, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "def setup_download_excel():\n",
    "    \"\"\" Transform the requirements list output to a json for display by d3js bubble chart\"\"\"\n",
    "    \n",
    "    requirementsList = {}\n",
    "    requirementsList['name'] = \"download\"\n",
    "    children = []\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"final_output.xlsx\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    detail = {}\n",
    "    detail[\"filename\"] = \"excel_download.jpg\"\n",
    "    detail[\"path\"] = \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"\n",
    "    children.append(detail)\n",
    "    requirementsList['children'] = children \n",
    "    return requirementsList\n",
    "\n",
    "wsresponse = {}\n",
    "wsresponse[\"forCmd\"] = \"GetExcel\"\n",
    "wsresponse[\"response\"] = setup_download_excel()\n",
    "\n",
    "print(json.dumps(wsresponse, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Expose integration point with a websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message(ws, message):\n",
    "    print(message)\n",
    "    msg = json.loads(message)\n",
    "    print(\"message\",msg)\n",
    "    cmd = msg['cmd']\n",
    "    \n",
    "    print(\"Command :\", cmd)\n",
    "\n",
    "    if cmd == 'getExcel':\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"GetExcel\"\n",
    "        wsresponse[\"response\"] = setup_download_excel()\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "    \n",
    "    if cmd == 'ReqsList':\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"ReqsList\"\n",
    "        requirements = get_requirements()\n",
    "        wsresponse[\"response\"] = transform_requirements_d3_bubble(requirements)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'DefectRelation':\n",
    "        defect_id = msg['ID']\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"DefectRelation\" \n",
    "        wsresponse[\"response\"] = get_artifacts_mapping_d3_network(defect_id)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'TestcaseRelation':\n",
    "        testcase_id = msg['ID']\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"TestcaseRelation\" \n",
    "        wsresponse[\"response\"] = get_tc_req_mapping_d3_network(testcase_id)\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'DefectInsight':\n",
    "        insight_id = msg['ID']\n",
    "        defects = get_defects()\n",
    "        defects = transform_defects_d3_bubble(defects)\n",
    "        if (insight_id.find('Insight1') != -1):\n",
    "            defectsSev1 = get_defects_severity(1)\n",
    "            defectsSev1 = transform_defects_d3_bubble(defectsSev1)\n",
    "            response = merge_apply_filters_d3_bubble(defects, defectsSev1)\n",
    "        if (insight_id.find('Insight2') != -1):\n",
    "            defectsSev2 = get_defects_severity(2)\n",
    "            defectsSev2 = transform_defects_d3_bubble(defectsSev2)\n",
    "            response = merge_apply_filters_d3_bubble(defects, defectsSev2)\n",
    "        if (insight_id.find('Insight3') != -1):\n",
    "            defectsSev3 = get_defects_severity(3)\n",
    "            defectsSev3 = transform_defects_d3_bubble(defectsSev3)\n",
    "            response = merge_apply_filters_d3_bubble(defects, defectsSev3)\n",
    "        if (insight_id.find('Insight4') != -1):\n",
    "            defects_zero_tc = get_defects_zero_testcases()\n",
    "            defects_zero_tc = transform_defects_d3_bubble(defects_zero_tc)\n",
    "            response = merge_apply_filters_d3_bubble(defects, defects_zero_tc)\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"Insight\" \n",
    "        wsresponse[\"response\"] = response\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'TestInsight':\n",
    "        insight_id = msg['ID']\n",
    "        testcases = get_testcases()\n",
    "        testcases = transform_testcases_d3_bubble(testcases)\n",
    "        if (insight_id.find('Insight1') != -1):\n",
    "            fvtTests = get_testcases_category('FVT')\n",
    "            fvtTests = transform_testcases_d3_bubble(fvtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, fvtTests)\n",
    "        if (insight_id.find('Insight2') != -1):\n",
    "            svtTests = get_testcases_category('SVT')\n",
    "            svtTests = transform_testcases_d3_bubble(svtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, svtTests)\n",
    "        if (insight_id.find('Insight3') != -1):\n",
    "            tvtTests = get_testcases_category('TVT')\n",
    "            tvtTests = transform_testcases_d3_bubble(tvtTests)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, tvtTests)\n",
    "        if (insight_id.find('Insight4') != -1):\n",
    "            testcase_zero_defect = get_testcases_zero_defects()\n",
    "            testcase_zero_defect = transform_testcases_d3_bubble(testcase_zero_defect)\n",
    "            response = merge_apply_filters_d3_bubble(testcases, testcase_zero_defect)\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"Insight\" \n",
    "        wsresponse[\"response\"] = response\n",
    "        ws.send(json.dumps(wsresponse))\n",
    "\n",
    "    if cmd == 'ReqInsight':\n",
    "        insight_id = msg['ID']\n",
    "        requirements = get_requirements()\n",
    "        requirements = transform_requirements_d3_bubble(requirements)\n",
    "        if (insight_id.find('Insight1') != -1):\n",
    "            req = get_requirements_zero_defect()\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "        if (insight_id.find('Insight2') != -1):\n",
    "            req = get_requirements_zero_testcases()\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "        if (insight_id.find('Insight3') != -1):\n",
    "            req = get_requirement_defects(5)\n",
    "            req = transform_requirements_d3_bubble(req)\n",
    "            response = merge_apply_filters_d3_bubble(requirements, req)\n",
    "        wsresponse = {}\n",
    "        wsresponse[\"forCmd\"] = \"Insight\" \n",
    "        wsresponse[\"response\"] = response\n",
    "        ws.send(json.dumps(wsresponse)) \n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(error)\n",
    "\n",
    "def on_close(ws):\n",
    "    print (\"DSX Listen End\")\n",
    "    ws.send(\"DSX Listen End\")\n",
    "\n",
    "def on_open(ws):\n",
    "    def run(*args):\n",
    "        for i in range(10000):\n",
    "            hbeat = '{\"cmd\":\"AI nWave HeartBeat\"}'\n",
    "            ws.send(hbeat)\n",
    "            time.sleep(100)\n",
    "            \n",
    "    _thread.start_new_thread(run, ())\n",
    "\n",
    "\n",
    "def start_websocket_listener():\n",
    "    websocket.enableTrace(True)\n",
    "    ws = websocket.WebSocketApp(\"ws://localhost:1880/ws/software\",\n",
    "                              on_message = on_message,\n",
    "                              on_error = on_error,\n",
    "                              on_close = on_close)\n",
    "    ws.on_open = on_open\n",
    "    ws.run_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Start websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- request header ---\n",
      "GET /ws/software HTTP/1.1\n",
      "Upgrade: websocket\n",
      "Connection: Upgrade\n",
      "Host: localhost:1880\n",
      "Origin: http://localhost:1880\n",
      "Sec-WebSocket-Key: kz6900geRY+PmXJ1GKAw1g==\n",
      "Sec-WebSocket-Version: 13\n",
      "\n",
      "\n",
      "-----------------------\n",
      "--- response header ---\n",
      "HTTP/1.1 101 Switching Protocols\n",
      "Upgrade: websocket\n",
      "Connection: Upgrade\n",
      "Sec-WebSocket-Accept: S9pQSlKVUSkrp6b4tzJvHds99LE=\n",
      "-----------------------\n",
      "send: b'\\x81\\x9c\\x80Q\\x00\\xe3\\xfbsc\\x8e\\xe4s:\\xc1\\xc1\\x18 \\x8d\\xd70v\\x86\\xa0\\x19e\\x82\\xf2%B\\x86\\xe1%\"\\x9e'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n",
      "{\"cmd\":\"Client connected\"}\n",
      "message {'cmd': 'Client connected'}\n",
      "Command : Client connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\xfe\\x01M\\xf0\\x06\\xb4\\x16\\x8b$\\xd2y\\x82E\\xd9r\\xd2<\\x944\\xb7c\\xc0S\\x88e\\xd1z\\xd2*\\x944\\x82c\\xc7f\\x9fh\\xc7s\\xd2<\\x94m\\xd2h\\xd5{\\x95$\\x8e6\\xd2b\\xdba\\x9ej\\xdbw\\x94$\\x986\\xd2e\\xdc\\x7f\\x9cb\\xc6s\\x9e$\\x8e6\\xab}\\x96p\\x99j\\xd1x\\x91k\\xd14\\xca&\\x96p\\x99h\\xd5z\\xafi\\xc1b\\x80s\\xc08\\x88j\\xc7n\\xd2*\\x944\\x80g\\xc0~\\xd2<\\x944\\xdfS\\xc7s\\x82u\\x9be\\x87g\\xc6y\\x9fv\\xd9\\x7f\\x83n\\xc6w\\xdfB\\xd1e\\x9br\\xdbf\\xdfv\\xcdb\\x98i\\xdae\\x93t\\xddf\\x84)\\xfaZ\\xa0Y\\xe4d\\x9fl\\xd1u\\x84)\\xdaA\\x91p\\xd1I\\x83i\\xd2b\\x87g\\xc6s\\xb4c\\xc7\\x7f\\x97h\\x9bx\\x9fr\\xd1t\\x9fi\\xdf9\\xd2{\\x986\\x8b$\\xd2\\x7f\\x9cc\\xdaw\\x9dc\\x96,\\xd0$\\xd1n\\x93c\\xd8I\\x94i\\xc3x\\x9ci\\xd5r\\xdel\\xc4q\\xd2*\\x944\\x80g\\xc0~\\xd2<\\x944\\xdfS\\xc7s\\x82u\\x9be\\x87g\\xc6y\\x9fv\\xd9\\x7f\\x83n\\xc6w\\xdfB\\xd1e\\x9br\\xdbf\\xdfv\\xcdb\\x98i\\xdae\\x93t\\xddf\\x84)\\xfaZ\\xa0Y\\xe4d\\x9fl\\xd1u\\x84)\\xdaA\\x91p\\xd1I\\x83i\\xd2b\\x87g\\xc6s\\xb4c\\xc7\\x7f\\x97h\\x9bx\\x9fr\\xd1t\\x9fi\\xdf9\\xd2{\\xe9k\\x8d'\n",
      "error from callback <function on_message at 0x1a10228c80>: 'cmd'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"getExcel\"}\n",
      "message {'cmd': 'getExcel'}\n",
      "Command : getExcel\n",
      "{\"forCmd\": \"GetExcel\", \"response\": {\"name\": \"download\", \"children\": [{\"filename\": \"final_output.xlsx\", \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"}, {\"filename\": \"excel_download.jpg\", \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"}]}}\n",
      "message {'forCmd': 'GetExcel', 'response': {'name': 'download', 'children': [{'filename': 'final_output.xlsx', 'path': '/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/'}, {'filename': 'excel_download.jpg', 'path': '/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_app.py\", line 315, in _callback\n",
      "    callback(self, *args)\n",
      "  File \"<ipython-input-206-ac8e05174f95>\", line 5, in on_message\n",
      "    cmd = msg['cmd']\n",
      "send: b'\\x81\\xfe\\x01M\\x82\\xce\\x97\"\\xf9\\xec\\xf1M\\xf0\\x8d\\xfaF\\xa0\\xf4\\xb7\\x00\\xc5\\xab\\xe3g\\xfa\\xad\\xf2N\\xa0\\xe2\\xb7\\x00\\xf0\\xab\\xe4R\\xed\\xa0\\xe4G\\xa0\\xf4\\xb7Y\\xa0\\xa0\\xf6O\\xe7\\xec\\xad\\x02\\xa0\\xaa\\xf8U\\xec\\xa2\\xf8C\\xe6\\xec\\xbb\\x02\\xa0\\xad\\xffK\\xee\\xaa\\xe5G\\xec\\xec\\xad\\x02\\xd9\\xb5\\xb5D\\xeb\\xa2\\xf2L\\xe3\\xa3\\xf2\\x00\\xb8\\xee\\xb5D\\xeb\\xa0\\xf6N\\xdd\\xa1\\xe2V\\xf2\\xbb\\xe3\\x0c\\xfa\\xa2\\xe4Z\\xa0\\xe2\\xb7\\x00\\xf2\\xaf\\xe3J\\xa0\\xf4\\xb7\\x00\\xad\\x9b\\xe4G\\xf0\\xbd\\xb8Q\\xf5\\xaf\\xe5M\\xed\\xbe\\xfaK\\xf1\\xa6\\xe5C\\xad\\x8a\\xf2Q\\xe9\\xba\\xf8R\\xad\\xbe\\xeeV\\xea\\xa1\\xf9Q\\xe1\\xbc\\xfeR\\xf6\\xe1\\xd9n\\xd2\\x91\\xc7P\\xed\\xa4\\xf2A\\xf6\\xe1\\xf9u\\xe3\\xb8\\xf2}\\xf1\\xa1\\xf1V\\xf5\\xaf\\xe5G\\xc6\\xab\\xe4K\\xe5\\xa0\\xb8L\\xed\\xba\\xf2@\\xed\\xa1\\xfc\\r\\xa0\\xb3\\xbb\\x02\\xf9\\xec\\xf1K\\xee\\xab\\xf9C\\xef\\xab\\xb5\\x18\\xa2\\xec\\xf2Z\\xe1\\xab\\xfb}\\xe6\\xa1\\xe0L\\xee\\xa1\\xf6F\\xac\\xa4\\xe7E\\xa0\\xe2\\xb7\\x00\\xf2\\xaf\\xe3J\\xa0\\xf4\\xb7\\x00\\xad\\x9b\\xe4G\\xf0\\xbd\\xb8Q\\xf5\\xaf\\xe5M\\xed\\xbe\\xfaK\\xf1\\xa6\\xe5C\\xad\\x8a\\xf2Q\\xe9\\xba\\xf8R\\xad\\xbe\\xeeV\\xea\\xa1\\xf9Q\\xe1\\xbc\\xfeR\\xf6\\xe1\\xd9n\\xd2\\x91\\xc7P\\xed\\xa4\\xf2A\\xf6\\xe1\\xf9u\\xe3\\xb8\\xf2}\\xf1\\xa1\\xf1V\\xf5\\xaf\\xe5G\\xc6\\xab\\xe4K\\xe5\\xa0\\xb8L\\xed\\xba\\xf2@\\xed\\xa1\\xfc\\r\\xa0\\xb3\\xca_\\xff'\n",
      "error from callback <function on_message at 0x1a10228c80>: 'cmd'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"getExcel\"}\n",
      "message {'cmd': 'getExcel'}\n",
      "Command : getExcel\n",
      "{\"forCmd\": \"GetExcel\", \"response\": {\"name\": \"download\", \"children\": [{\"filename\": \"final_output.xlsx\", \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"}, {\"filename\": \"excel_download.jpg\", \"path\": \"/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/\"}]}}\n",
      "message {'forCmd': 'GetExcel', 'response': {'name': 'download', 'children': [{'filename': 'final_output.xlsx', 'path': '/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/'}, {'filename': 'excel_download.jpg', 'path': '/Users/swaroopmishra/Desktop/pythonscript/NLP_Project/nWave_softwareDesign/notebook/'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_app.py\", line 315, in _callback\n",
      "    callback(self, *args)\n",
      "  File \"<ipython-input-206-ac8e05174f95>\", line 5, in on_message\n",
      "    cmd = msg['cmd']\n",
      "Unhandled exception in thread started by <function on_open.<locals>.run at 0x1a10234c80>\n"
     ]
    },
    {
     "ename": "WebSocketConnectionClosedException",
     "evalue": "Connection is already closed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-ac8e05174f95>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mhbeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{\"cmd\":\"AI nWave HeartBeat\"}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhbeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/websocket/_app.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, opcode)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             raise WebSocketConnectionClosedException(\n\u001b[0;32m--> 149\u001b[0;31m                 \"Connection is already closed.\")\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0m: Connection is already closed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9cu\\x08\\xdfJ\\x0e*\\xbc\\'\\x11*\\xe5h4A\\xff$\"i\\xa9/U@\\xba+\\x07|\\x9d/\\x14|\\xfd7'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xd5N\\x19\\x9c\\xaelz\\xf1\\xb1l#\\xbe\\x94\\x079\\xf2\\x82/o\\xf9\\xf5\\x06|\\xfd\\xa7:[\\xf9\\xb4:;\\xe1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b\"\\x81\\x9cp\\xf1e\\xab\\x0b\\xd3\\x06\\xc6\\x14\\xd3_\\x891\\xb8E\\xc5'\\x90\\x13\\xceP\\xb9\\x00\\xca\\x02\\x85'\\xce\\x11\\x85G\\xd6\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xe9v#]\\x92T@0\\x8dT\\x19\\x7f\\xa8?\\x033\\xbe\\x17U8\\xc9>F<\\x9b\\x02a8\\x88\\x02\\x01 '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9cZ\\x00\\xf5f!\"\\x96\\x0b>\"\\xcfD\\x1bI\\xd5\\x08\\ra\\x83\\x03zH\\x90\\x07(t\\xb7\\x03;t\\xd7\\x1b'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b\"\\x81\\x9c\\x7f,\\x8bF\\x04\\x0e\\xe8+\\x1b\\x0e\\xb1d>e\\xab((M\\xfd#_d\\xee'\\rX\\xc9#\\x1eX\\xa9;\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\x88{\\x0e\\x89\\xf3Ym\\xe4\\xecY4\\xab\\xc92.\\xe7\\xdf\\x1ax\\xec\\xa83k\\xe8\\xfa\\x0fL\\xec\\xe9\\x0f,\\xf4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xf8\\x9d\\x19v\\x83\\xbfz\\x1b\\x9c\\xbf#T\\xb9\\xd49\\x18\\xaf\\xfco\\x13\\xd8\\xd5|\\x17\\x8a\\xe9[\\x13\\x99\\xe9;\\x0b'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xe8\\xe3\\xbeD\\x93\\xc1\\xdd)\\x8c\\xc1\\x84f\\xa9\\xaa\\x9e*\\xbf\\x82\\xc8!\\xc8\\xab\\xdb%\\x9a\\x97\\xfc!\\x89\\x97\\x9c9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9cK\\\\#70~@Z/~\\x19\\x15\\n\\x15\\x03Y\\x1c=URk\\x14FV9(aR*(\\x01J'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9clb!b\\x17@B\\x0f\\x08@\\x1b@-+\\x01\\x0c;\\x03W\\x07L*D\\x03\\x1e\\x16c\\x07\\r\\x16\\x03\\x1f'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\x85j\\xeb\\xe9\\xfeH\\x88\\x84\\xe1H\\xd1\\xcb\\xc4#\\xcb\\x87\\xd2\\x0b\\x9d\\x8c\\xa5\"\\x8e\\x88\\xf7\\x1e\\xa9\\x8c\\xe4\\x1e\\xc9\\x94'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9cgE;\\xd3\\x1cgX\\xbe\\x03g\\x01\\xf1&\\x0c\\x1b\\xbd0$M\\xb6G\\r^\\xb2\\x151y\\xb6\\x061\\x19\\xae'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xf8\\x03[8\\x83!8U\\x9c!a\\x1a\\xb9J{V\\xafb-]\\xd8K>Y\\x8aw\\x19]\\x99wyE'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xea\\rkh\\x91/\\x08\\x05\\x8e/QJ\\xabDK\\x06\\xbdl\\x1d\\r\\xcaE\\x0e\\t\\x98y)\\r\\x8byI\\x15'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\xf5\\xa7\\x11\\xce\\x8e\\x85r\\xa3\\x91\\x85+\\xec\\xb4\\xee1\\xa0\\xa2\\xc6g\\xab\\xd5\\xeft\\xaf\\x87\\xd3S\\xab\\x94\\xd33\\xb3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c<\\x02\\xd10G \\xb2]X \\xeb\\x12}K\\xf1^kc\\xa7U\\x1cJ\\xb4QNv\\x93U]v\\xf3M'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9cw\\xb8X\\xdb\\x0c\\x9a;\\xb6\\x13\\x9ab\\xf96\\xf1x\\xb5 \\xd9.\\xbeW\\xf0=\\xba\\x05\\xcc\\x1a\\xbe\\x16\\xccz\\xa6'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c_\\\\F\\xcc$~%\\xa1;~|\\xee\\x1e\\x15f\\xa2\\x08=0\\xa9\\x7f\\x14#\\xad-(\\x04\\xa9>(d\\xb1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x9c\\x87}\\xa12\\xfc_\\xc2_\\xe3_\\x9b\\x10\\xc64\\x81\\\\\\xd0\\x1c\\xd7W\\xa75\\xc4S\\xf5\\t\\xe3W\\xe6\\t\\x83O'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b\"\\x81\\x9c\\x81\\x82'=\\xfa\\xa0DP\\xe5\\xa0\\x1d\\x1f\\xc0\\xcb\\x07S\\xd6\\xe3QX\\xa1\\xcaB\\\\\\xf3\\xf6eX\\xe0\\xf6\\x05@\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cmd\":\"AI nWave HeartBeat\"}\n",
      "message {'cmd': 'AI nWave HeartBeat'}\n",
      "Command : AI nWave HeartBeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: b'\\x81\\x8e;\\xa08V\\x7f\\xf3`vw\\xc9K\"^\\xce\\x18\\x13U\\xc4'\n",
      "error from callback <function on_close at 0x1a10311ea0>: socket is already closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection is already closed.\n",
      "DSX Listen End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_app.py\", line 315, in _callback\n",
      "    callback(self, *args)\n",
      "  File \"<ipython-input-206-ac8e05174f95>\", line 112, in on_close\n",
      "    ws.send(\"DSX Listen End\")\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_app.py\", line 147, in send\n",
      "    if not self.sock or self.sock.send(data, opcode) == 0:\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_core.py\", line 240, in send\n",
      "    return self.send_frame(frame)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_core.py\", line 265, in send_frame\n",
      "    l = self._send(data)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_core.py\", line 430, in _send\n",
      "    return send(self.sock, data)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/websocket/_socket.py\", line 114, in send\n",
      "    raise WebSocketConnectionClosedException(\"socket is already closed.\")\n",
      "Unhandled exception in thread started by <function on_open.<locals>.run at 0x1a0d8ee1e0>\n"
     ]
    }
   ],
   "source": [
    "start_websocket_listener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will be used for line by line checking of code for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index1 = 0\n",
    "index2 = 1\n",
    "matches.append({'ID': \"U2\", \n",
    "                'cosine_score': 0, \n",
    "                'SubjectID':\"R01\"})\n",
    "cosine_score = 0.7\n",
    "matches[index2][\"cosine_score\"] = cosine_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ID': 'U1', 'cosine_score': 0.4, 'SubjectID': 'R01'}, {'ID': 'U2', 'cosine_score': 0.7, 'SubjectID': 'R01'}]\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ID': 'U3', 'cosine_score': 0.9, 'SubjectID': 'R03'}, {'ID': 'U4', 'cosine_score': 0.9, 'SubjectID': 'R04'}, {'ID': 'U1', 'cosine_score': 0.8, 'SubjectID': 'R01'}, {'ID': 'U2', 'cosine_score': 0.7, 'SubjectID': 'R02'}, {'ID': 'U5', 'cosine_score': 0.4, 'SubjectID': 'R05'}]\n"
     ]
    }
   ],
   "source": [
    "sorted_obj = sorted(matches, key=lambda x : x['cosine_score'], reverse=True)\n",
    "print(sorted_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in sorted_obj:\n",
    "            if obj['cosine_score'] > 0.4:\n",
    "                top_matches.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-259-382d6133efcf>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-259-382d6133efcf>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])print(top_matches)\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stopWords = get_stop_words('english')\n",
    "# List of words to be ignored for text similarity\n",
    "stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])print(top_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "cosine similarity :\n"
     ]
    }
   ],
   "source": [
    "stopWords = get_stop_words('english')\n",
    "# List of words to be ignored for text similarity\n",
    "stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])\n",
    "\n",
    "# this depicts cosine similarity\n",
    "\n",
    "text1 = \"A customer would like to deposit cheque at the ATM so that he can increase the balance.\"\n",
    "text1tags = ['', ' A customer', 'NP', ' cheque', ' the balance', ' like', 'VERB', ' deposit', ' increase', ' ATM']\n",
    "\n",
    "#text2 = \"This Use case deals with Verification of PIN entered by Customer at ATM. One has to validate the pin using the customer number and the debit card number\"\n",
    "#text2tags = ['', ' case', 'NP', ' the pin', ' the customer', ' number', ' the debit', ' card', ' Use', 'NAME', ' Verification', ' PIN', ' Customer', ' ATM', ' validate', 'VERB']\n",
    "\n",
    "#text1 = \"I am a Customer and I want to withdraw cash from an ATM so that I don’t have to wait in line\"\n",
    "#text1tags = ['', ' cash', 'NP', ' line', ' Customer', 'NAME', ' ATM', ' withdraw', 'VERB', ' wait']\n",
    "\n",
    "#text2 = \"I am a Customer and I want to withdraw cash from an ATM so that I don’t have to wait in line\"\n",
    "#text2tags = ['', ' cash', 'NP', ' line', ' Customer', 'NAME', ' ATM', ' withdraw', 'VERB', ' wait']\n",
    "\n",
    "text2 = \"Customer Name will be used as part of authenting user and to greet customer\"\n",
    "text2tags = ['', ' part', 'NP', ' user', ' customer', ' Customer Name', 'NAME', ' be', 'VERB', ' greet']\n",
    "\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "sentences_text1 = split_sentences(text1)\n",
    "#print(sentences_text1)\n",
    "sentences_text2 = split_sentences(text2)\n",
    "tokens_text1 = []\n",
    "tokens_text2 = []\n",
    "\n",
    "for sentence in sentences_text1:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        #print(tokenstemp)\n",
    "        tokens_text1.extend(tokenstemp)\n",
    "#print(tokens_text1)\n",
    "\n",
    "for sentence in sentences_text2:\n",
    "        tokenstemp = split_into_tokens(sentence.lower())\n",
    "        tokens_text2.extend(tokenstemp)\n",
    "\n",
    "if (len(text1tags) > 0):  \n",
    "        tokens_text1.extend(text1tags)\n",
    "if (len(text2tags) > 0):    \n",
    "        tokens_text2.extend(text2tags)\n",
    "#print(tokens_text1)\n",
    "        \n",
    "tokens1Filtered = [stemmer.stem(x) for x in tokens_text1 if x not in stopWords]\n",
    "#print(tokens1Filtered)    \n",
    "tokens2Filtered = [stemmer.stem(x) for x in tokens_text2 if x not in stopWords]\n",
    "    \n",
    "    #  remove duplicate tokens\n",
    "tokens1Filtered = set(tokens1Filtered)\n",
    "tokens2Filtered = set(tokens2Filtered)\n",
    "#print(tokens1Filtered)\n",
    "\n",
    "tokensList=[]\n",
    "\n",
    "text1vector = []\n",
    "text2vector = []\n",
    "    \n",
    "if len(tokens1Filtered) < len(tokens2Filtered):\n",
    "    tokensList = tokens1Filtered\n",
    "else:\n",
    "    tokensList = tokens2Filtered\n",
    "\n",
    "#print(tokensList)\n",
    "for token in tokensList:\n",
    "    if token in tokens1Filtered:\n",
    "        text1vector.append(1)\n",
    "    else:\n",
    "        text1vector.append(0)\n",
    "    if token in tokens2Filtered:\n",
    "        text2vector.append(1)\n",
    "    else:\n",
    "        text2vector.append(0)         \n",
    "#print(text1vector)  \n",
    "print(text2vector)\n",
    "cosine_similarity = 1-cosine_distance(text1vector,text2vector) \n",
    "\n",
    "print(\"cosine similarity :\")\n",
    "#print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>As a &lt;type of user&gt;</th>\n",
       "      <th>I want to &lt;perform some task&gt;</th>\n",
       "      <th>so that I can &lt;achieve some goal&gt;</th>\n",
       "      <th>ClassifiedText</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DomainMatchScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R01</td>\n",
       "      <td>Customer</td>\n",
       "      <td>deposit check</td>\n",
       "      <td>I want to increase my bank balance</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  deposit check, Action]</td>\n",
       "      <td>[{'ID': 'U1', 'cosine_score': 0.81649658092772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R02</td>\n",
       "      <td>Customer</td>\n",
       "      <td>withdraw cash from an ATM</td>\n",
       "      <td>I don't have to wait in line at the Bank</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  withdraw cash, Action]</td>\n",
       "      <td>[{'ID': 'U1', 'cosine_score': 0.75592894601845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R03</td>\n",
       "      <td>Customer</td>\n",
       "      <td>want to transfer money from one account to ano...</td>\n",
       "      <td>I don't need to pay the amount in person</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  transfer money, Action]</td>\n",
       "      <td>[{'ID': 'U4', 'cosine_score': 0.77459666924148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R04</td>\n",
       "      <td>Customer</td>\n",
       "      <td>pay my utility bills online</td>\n",
       "      <td>I don't need to write checks or use postal ser...</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  pay my utility bills, Action]</td>\n",
       "      <td>[{'ID': 'U1', 'cosine_score': 0.49999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R05</td>\n",
       "      <td>Customer</td>\n",
       "      <td>apply for a loan</td>\n",
       "      <td>purchase a car</td>\n",
       "      <td>{'Keywords': [{'User': ''}, {'User': 'Customer...</td>\n",
       "      <td>[, Customer,  apply for a loan, Action]</td>\n",
       "      <td>[{'ID': 'U7', 'cosine_score': 0.81649658092772...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID As a <type of user>                      I want to <perform some task>  \\\n",
       "0  R01            Customer                                      deposit check   \n",
       "1  R02            Customer                          withdraw cash from an ATM   \n",
       "2  R03            Customer  want to transfer money from one account to ano...   \n",
       "3  R04            Customer                        pay my utility bills online   \n",
       "4  R05            Customer                                   apply for a loan   \n",
       "\n",
       "                   so that I can <achieve some goal>  \\\n",
       "0                 I want to increase my bank balance   \n",
       "1           I don't have to wait in line at the Bank   \n",
       "2           I don't need to pay the amount in person   \n",
       "3  I don't need to write checks or use postal ser...   \n",
       "4                                     purchase a car   \n",
       "\n",
       "                                      ClassifiedText  \\\n",
       "0  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "1  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "2  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "3  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "4  {'Keywords': [{'User': ''}, {'User': 'Customer...   \n",
       "\n",
       "                                      Keywords  \\\n",
       "0         [, Customer,  deposit check, Action]   \n",
       "1         [, Customer,  withdraw cash, Action]   \n",
       "2        [, Customer,  transfer money, Action]   \n",
       "3  [, Customer,  pay my utility bills, Action]   \n",
       "4      [, Customer,  apply for a loan, Action]   \n",
       "\n",
       "                                    DomainMatchScore  \n",
       "0  [{'ID': 'U1', 'cosine_score': 0.81649658092772...  \n",
       "1  [{'ID': 'U1', 'cosine_score': 0.75592894601845...  \n",
       "2  [{'ID': 'U4', 'cosine_score': 0.77459666924148...  \n",
       "3  [{'ID': 'U1', 'cosine_score': 0.49999999999999...  \n",
       "4  [{'ID': 'U7', 'cosine_score': 0.81649658092772...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements_df.head()\n",
    "#domain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage': {'text_characters': 502, 'features': 2, 'text_units': 1}, 'keywords': [{'text': 'A', 'relevance': 0}], 'language': 'en', 'entities': [{'type': 'Person', 'text': 'Stephen Hawking', 'relevance': 0.846941, 'count': 5}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('sample.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument_SpResponse(responsejson,updateType,text,tag):\n",
    "    \"\"\" Update the NLU response JSON with augumented classifications.\n",
    "    \"\"\"\n",
    "    if(updateType == 'keyword'):\n",
    "        if not any(d.get('text', None) == text for d in responsejson['keywords']):\n",
    "            responsejson['keywords'].append({\"text\":text,\"relevance\":0.5})\n",
    "    else:\n",
    "        if not any(d.get('text', None) == text for d in responsejson['entities']):\n",
    "            responsejson['entities'].append({\"type\":tag,\"text\":text,\"relevance\":0.5,\"count\":1})        \n",
    "    return responsejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responsejson = augument_SpResponse(data,'entities','Ryan','Person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage': {'text_characters': 502, 'features': 2, 'text_units': 1}, 'keywords': [{'text': 'A', 'relevance': 0}], 'language': 'en', 'entities': [{'type': 'Person', 'text': 'Stephen Hawking', 'relevance': 0.846941, 'count': 5}, {'type': 'Person', 'text': 'Ryan', 'relevance': 0.5, 'count': 1}]}\n"
     ]
    }
   ],
   "source": [
    "#print(responsejson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select*\n"
     ]
    }
   ],
   "source": [
    "x =\"select*\"\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(nlu_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *****   The Following code for uploading and downloading is working\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** this will upload the file UserStroies-V0.1.xlsx in the S3\n",
    "First delete the file if you want to see it in S3 \n",
    "While downloading the png it will be downloaded as \"MYLOCALIMAGE.PNG\" in the location where you started the jupyter\n",
    "Credentials for S3 are provided above in section 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done uploading\n",
      "Done downloading\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "import pandas as pd\n",
    "data = None\n",
    "\n",
    "ACCESS_KEY_ID = ''\n",
    "ACCESS_SECRET_KEY = ''\n",
    "BUCKET_NAME = 'software-testing-pyscript'\n",
    "KEY = 'Banking-BRD.xlsx' # replace with your object key\n",
    "\n",
    "\n",
    "data = open('Banking-BRD.xlsx', 'rb' )\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=ACCESS_SECRET_KEY,\n",
    "    config=Config(signature_version='s3v4')\n",
    ")\n",
    "\n",
    "#s3.put_object(Bucket=BUCKET_NAME, Key=KEY, Body=data)\n",
    "\n",
    "print(\"Done uploading\")\n",
    "\n",
    "\n",
    "\n",
    "s3.download_file(BUCKET_NAME,KEY,\".//test/MYLOCALEXCELBRD_mod.xlsx\")\n",
    "    \n",
    "print(\"Done downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Story ID</th>\n",
       "      <th>User</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R01</td>\n",
       "      <td>Customer</td>\n",
       "      <td>A customer would like to deposit cheque so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R02</td>\n",
       "      <td>Customer</td>\n",
       "      <td>I am a Customer and I want to withdraw cash fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R03</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Customers would like to transfer money from on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R04</td>\n",
       "      <td>Customer</td>\n",
       "      <td>My name is Ryan and I am a customer at the ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R05</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Customer will need to have a feature to apply ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User Story ID      User                                        Description\n",
       "0           R01  Customer  A customer would like to deposit cheque so tha...\n",
       "1           R02  Customer  I am a Customer and I want to withdraw cash fr...\n",
       "2           R03  Customer  Customers would like to transfer money from on...\n",
       "3           R04  Customer  My name is Ryan and I am a customer at the ban...\n",
       "4           R05  Customer  Customer will need to have a feature to apply ..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"MYLOCALEXCELBRD_mod.xlsx\",\"Banking-Requirements\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Banking-Requirements']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl = pd.ExcelFile(\"MYLOCALEXCELBRD_mod.xlsx\")\n",
    "xl.sheet_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x1a133226d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = xl.parse(\"Banking-Requirements\")\n",
    "df.iterrows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"configuration\": {\\n    \"classification\": {\\n      \"stages\": [\\n        {\\n          \"name\": \"Base Tagging\",\\n          \"steps\": [\\n            {\\n              \"type\": \"keywords\",\\n              \"keywords\": [\\n                {\\n                  \"tag\": \"chart\",\\n                  \"text\": \"bar\"\\n                },\\n                { \\n                  \"tag\": \"chart\",\\n                  \"text\": \"line\"\\n                },\\n                {\\n                  \"tag\": \"chart\",\\n                  \"text\": \"pie\"\\n                },\\n                {\\n                  \"tag\": \"UI\",\\n                  \"text\": \"visualization\"\\n                },\\n                {\\n                  \"tag\": \"edition\",\\n                  \"text\": \"editions\"\\n                },\\n                {\\n                  \"tag\": \"country\",\\n                  \"text\": \"countries\"\\n                },\\n                {\\n                  \"tag\": \"medal\",\\n                  \"text\": \"medals\"\\n                },\\n                {\\n                  \"tag\": \"edition\",\\n                  \"text\": \"years\"\\n                },\\n                {\\n                  \"tag\": \"login\",\\n                  \"text\": \"authentication\"\\n                },\\n                {\\n                  \"tag\": \"login\",\\n                  \"text\": \"password\"\\n                },\\n                {\\n                  \"tag\": \"login\",\\n                  \"text\": \"username\"\\n                },\\n                {\\n                  \"tag\": \"login\",\\n                  \"text\": \"credentials\"\\n                },\\n                {\\n                  \"tag\": \"websocket\",\\n                  \"text\": \"socket\"\\n                }\\n              ]\\n            },\\n            {\\n              \"type\": \"d_regex\",\\n              \"d_regex\": [\\n                {\\n                  \"tag\": \"Number\",\\n                  \"pattern\": \"[0-9]{10}\"\\n                }\\n              ]\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  }\\n}\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = open(\"sample_config.txt\")\n",
    "\n",
    "config.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xlrd import open_workbook\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "class BRD:\n",
    "    def __init__(self, usrStryID, asa, action, goal):\n",
    "        self.usrStryID = usrStryID\n",
    "        self.asa = asa\n",
    "        self.action = action\n",
    "        self.goal = goal\n",
    "        \n",
    "        #Reads the spreadsheet from the file location\n",
    "#wb = open_workbook(\"MYLOCALEXCEL.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in /anaconda3/lib/python3.6/site-packages (2015.2.23.1)\n",
      "\u001b[31mboto3 1.7.11 has requirement botocore<1.11.0,>=1.10.11, but you'll have botocore 1.10.10 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " # Prepares the list of Stop words which can be ignored like the, can , am etc\n",
    "!pip install stop-words\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "stopWords = get_stop_words('english')\n",
    "# List of words to be ignored for text similarity\n",
    "stopWords.extend([\"The\",\"This\",\"That\",\".\",\"!\",\"?\"])\n",
    "#stop_words = set(stopwords.words('english'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/swaroopmishra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/swaroopmishra/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Customer']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NN')]\n",
      "----> (S Customer/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')])]\n",
      "===> (S Customer/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')])]\n",
      "['A customer would like to deposit cheque so that he can increase the balance']\n",
      "*********************************************\n",
      "Tagged: [('A', 'DT'), ('customer', 'NN'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('deposit', 'VB'), ('cheque', 'NN'), ('so', 'RB'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), ('increase', 'VB'), ('the', 'DT'), ('balance', 'NN')]\n",
      "----> (S\n",
      "  A/DT\n",
      "  customer/NN\n",
      "  would/MD\n",
      "  (Chunk like/VB)\n",
      "  to/TO\n",
      "  (Chunk deposit/VB)\n",
      "  cheque/NN\n",
      "  so/RB\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  can/MD\n",
      "  (Chunk increase/VB)\n",
      "  the/DT\n",
      "  balance/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')]), Tree('S', [('A', 'DT'), ('customer', 'NN'), ('would', 'MD'), Tree('Chunk', [('like', 'VB')]), ('to', 'TO'), Tree('Chunk', [('deposit', 'VB')]), ('cheque', 'NN'), ('so', 'RB'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), Tree('Chunk', [('increase', 'VB')]), ('the', 'DT'), ('balance', 'NN')])]\n",
      "===> (S\n",
      "  A/DT\n",
      "  customer/NN\n",
      "  would/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  deposit/VB\n",
      "  cheque/NN\n",
      "  so/RB\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  can/MD\n",
      "  increase/VB\n",
      "  the/DT\n",
      "  balance/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('A', 'DT'), ('customer', 'NN'), ('would', 'MD'), Tree('Chunk', [('like', 'VB')]), ('to', 'TO'), Tree('Chunk', [('deposit', 'VB')]), ('cheque', 'NN'), ('so', 'RB'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), Tree('Chunk', [('increase', 'VB')]), ('the', 'DT'), ('balance', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('A', 'DT'), ('customer', 'NN'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('deposit', 'VB'), ('cheque', 'NN'), ('so', 'RB'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), ('increase', 'VB'), ('the', 'DT'), ('balance', 'NN')])]\n",
      "Filtered Sentence--> ['Customer', 'A', 'customer', 'like', 'deposit', 'cheque', 'can', 'increase', 'balance']\n",
      "['Customer']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NN')]\n",
      "----> (S Customer/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')])]\n",
      "===> (S Customer/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')])]\n",
      "['I am a Customer and I want to withdraw cash from an ATM so that I don’t have to wait in line']\n",
      "*********************************************\n",
      "Tagged: [('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('Customer', 'NNP'), ('and', 'CC'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('withdraw', 'VB'), ('cash', 'NN'), ('from', 'IN'), ('an', 'DT'), ('ATM', 'NNP'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NNS'), ('have', 'VBP'), ('to', 'TO'), ('wait', 'VB'), ('in', 'IN'), ('line', 'NN')]\n",
      "----> (S\n",
      "  I/PRP\n",
      "  (Chunk am/VBP)\n",
      "  a/DT\n",
      "  Customer/NNP\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  (Chunk want/VBP)\n",
      "  to/TO\n",
      "  (Chunk withdraw/VB)\n",
      "  cash/NN\n",
      "  from/IN\n",
      "  an/DT\n",
      "  ATM/NNP\n",
      "  so/IN\n",
      "  that/IN\n",
      "  I/PRP\n",
      "  (Chunk don/VBP)\n",
      "  ’/JJ\n",
      "  t/NNS\n",
      "  (Chunk have/VBP)\n",
      "  to/TO\n",
      "  (Chunk wait/VB)\n",
      "  in/IN\n",
      "  line/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')]), Tree('S', [('I', 'PRP'), Tree('Chunk', [('am', 'VBP')]), ('a', 'DT'), ('Customer', 'NNP'), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('want', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('withdraw', 'VB')]), ('cash', 'NN'), ('from', 'IN'), ('an', 'DT'), ('ATM', 'NNP'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), Tree('Chunk', [('don', 'VBP')]), ('’', 'JJ'), ('t', 'NNS'), Tree('Chunk', [('have', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('wait', 'VB')]), ('in', 'IN'), ('line', 'NN')])]\n",
      "===> (S\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  a/DT\n",
      "  (Chunk Customer/NNP)\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  want/VBP\n",
      "  to/TO\n",
      "  withdraw/VB\n",
      "  cash/NN\n",
      "  from/IN\n",
      "  an/DT\n",
      "  (Chunk ATM/NNP)\n",
      "  so/IN\n",
      "  that/IN\n",
      "  I/PRP\n",
      "  don/VBP\n",
      "  ’/JJ\n",
      "  t/NNS\n",
      "  have/VBP\n",
      "  to/TO\n",
      "  wait/VB\n",
      "  in/IN\n",
      "  line/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('I', 'PRP'), Tree('Chunk', [('am', 'VBP')]), ('a', 'DT'), ('Customer', 'NNP'), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('want', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('withdraw', 'VB')]), ('cash', 'NN'), ('from', 'IN'), ('an', 'DT'), ('ATM', 'NNP'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), Tree('Chunk', [('don', 'VBP')]), ('’', 'JJ'), ('t', 'NNS'), Tree('Chunk', [('have', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('wait', 'VB')]), ('in', 'IN'), ('line', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), Tree('Chunk', [('Customer', 'NNP')]), ('and', 'CC'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('withdraw', 'VB'), ('cash', 'NN'), ('from', 'IN'), ('an', 'DT'), Tree('Chunk', [('ATM', 'NNP')]), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NNS'), ('have', 'VBP'), ('to', 'TO'), ('wait', 'VB'), ('in', 'IN'), ('line', 'NN')])]\n",
      "Filtered Sentence--> ['Customer', 'I', 'Customer', 'I', 'want', 'withdraw', 'cash', 'ATM', 'I', 'don', '’', 't', 'wait', 'line']\n",
      "['Customer']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NN')]\n",
      "----> (S Customer/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')])]\n",
      "===> (S Customer/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')])]\n",
      "['Customers would like to transfer money from one account to another so that there is no physical transfer of money']\n",
      "*********************************************\n",
      "Tagged: [('Customers', 'NNS'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('transfer', 'VB'), ('money', 'NN'), ('from', 'IN'), ('one', 'CD'), ('account', 'NN'), ('to', 'TO'), ('another', 'DT'), ('so', 'RB'), ('that', 'IN'), ('there', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('physical', 'JJ'), ('transfer', 'NN'), ('of', 'IN'), ('money', 'NN')]\n",
      "----> (S\n",
      "  Customers/NNS\n",
      "  would/MD\n",
      "  (Chunk like/VB)\n",
      "  to/TO\n",
      "  (Chunk transfer/VB)\n",
      "  money/NN\n",
      "  from/IN\n",
      "  one/CD\n",
      "  account/NN\n",
      "  to/TO\n",
      "  another/DT\n",
      "  so/RB\n",
      "  that/IN\n",
      "  there/EX\n",
      "  (Chunk is/VBZ)\n",
      "  no/DT\n",
      "  physical/JJ\n",
      "  transfer/NN\n",
      "  of/IN\n",
      "  money/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')]), Tree('S', [('Customers', 'NNS'), ('would', 'MD'), Tree('Chunk', [('like', 'VB')]), ('to', 'TO'), Tree('Chunk', [('transfer', 'VB')]), ('money', 'NN'), ('from', 'IN'), ('one', 'CD'), ('account', 'NN'), ('to', 'TO'), ('another', 'DT'), ('so', 'RB'), ('that', 'IN'), ('there', 'EX'), Tree('Chunk', [('is', 'VBZ')]), ('no', 'DT'), ('physical', 'JJ'), ('transfer', 'NN'), ('of', 'IN'), ('money', 'NN')])]\n",
      "===> (S\n",
      "  Customers/NNS\n",
      "  would/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  transfer/VB\n",
      "  money/NN\n",
      "  from/IN\n",
      "  one/CD\n",
      "  account/NN\n",
      "  to/TO\n",
      "  another/DT\n",
      "  so/RB\n",
      "  that/IN\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  physical/JJ\n",
      "  transfer/NN\n",
      "  of/IN\n",
      "  money/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('Customers', 'NNS'), ('would', 'MD'), Tree('Chunk', [('like', 'VB')]), ('to', 'TO'), Tree('Chunk', [('transfer', 'VB')]), ('money', 'NN'), ('from', 'IN'), ('one', 'CD'), ('account', 'NN'), ('to', 'TO'), ('another', 'DT'), ('so', 'RB'), ('that', 'IN'), ('there', 'EX'), Tree('Chunk', [('is', 'VBZ')]), ('no', 'DT'), ('physical', 'JJ'), ('transfer', 'NN'), ('of', 'IN'), ('money', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('Customers', 'NNS'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('transfer', 'VB'), ('money', 'NN'), ('from', 'IN'), ('one', 'CD'), ('account', 'NN'), ('to', 'TO'), ('another', 'DT'), ('so', 'RB'), ('that', 'IN'), ('there', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('physical', 'JJ'), ('transfer', 'NN'), ('of', 'IN'), ('money', 'NN')])]\n",
      "Filtered Sentence--> ['Customer', 'Customers', 'like', 'transfer', 'money', 'one', 'account', 'another', 'physical', 'transfer', 'money']\n",
      "['Customer']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NN')]\n",
      "----> (S Customer/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')])]\n",
      "===> (S Customer/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')])]\n",
      "['My name is Ryan and I am a customer at the bank, and I want to order checks so that I don’t need to write checks or use postal service']\n",
      "*********************************************\n",
      "Tagged: [('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Ryan', 'NNP'), ('and', 'CC'), ('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('customer', 'NN'), ('at', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('order', 'NN'), ('checks', 'NNS'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NNS'), ('need', 'VBP'), ('to', 'TO'), ('write', 'VB'), ('checks', 'NNS'), ('or', 'CC'), ('use', 'VB'), ('postal', 'JJ'), ('service', 'NN')]\n",
      "----> (S\n",
      "  My/PRP$\n",
      "  name/NN\n",
      "  (Chunk is/VBZ)\n",
      "  Ryan/NNP\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  (Chunk am/VBP)\n",
      "  a/DT\n",
      "  customer/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  (Chunk want/VBP)\n",
      "  to/TO\n",
      "  order/NN\n",
      "  checks/NNS\n",
      "  so/IN\n",
      "  that/IN\n",
      "  I/PRP\n",
      "  (Chunk don/VBP)\n",
      "  ’/JJ\n",
      "  t/NNS\n",
      "  (Chunk need/VBP)\n",
      "  to/TO\n",
      "  (Chunk write/VB)\n",
      "  checks/NNS\n",
      "  or/CC\n",
      "  (Chunk use/VB)\n",
      "  postal/JJ\n",
      "  service/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')]), Tree('S', [('My', 'PRP$'), ('name', 'NN'), Tree('Chunk', [('is', 'VBZ')]), ('Ryan', 'NNP'), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('am', 'VBP')]), ('a', 'DT'), ('customer', 'NN'), ('at', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('want', 'VBP')]), ('to', 'TO'), ('order', 'NN'), ('checks', 'NNS'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), Tree('Chunk', [('don', 'VBP')]), ('’', 'JJ'), ('t', 'NNS'), Tree('Chunk', [('need', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('write', 'VB')]), ('checks', 'NNS'), ('or', 'CC'), Tree('Chunk', [('use', 'VB')]), ('postal', 'JJ'), ('service', 'NN')])]\n",
      "===> (S\n",
      "  My/PRP$\n",
      "  name/NN\n",
      "  is/VBZ\n",
      "  (Chunk Ryan/NNP)\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  a/DT\n",
      "  customer/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  want/VBP\n",
      "  to/TO\n",
      "  order/NN\n",
      "  checks/NNS\n",
      "  so/IN\n",
      "  that/IN\n",
      "  I/PRP\n",
      "  don/VBP\n",
      "  ’/JJ\n",
      "  t/NNS\n",
      "  need/VBP\n",
      "  to/TO\n",
      "  write/VB\n",
      "  checks/NNS\n",
      "  or/CC\n",
      "  use/VB\n",
      "  postal/JJ\n",
      "  service/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('My', 'PRP$'), ('name', 'NN'), Tree('Chunk', [('is', 'VBZ')]), ('Ryan', 'NNP'), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('am', 'VBP')]), ('a', 'DT'), ('customer', 'NN'), ('at', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), Tree('Chunk', [('want', 'VBP')]), ('to', 'TO'), ('order', 'NN'), ('checks', 'NNS'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), Tree('Chunk', [('don', 'VBP')]), ('’', 'JJ'), ('t', 'NNS'), Tree('Chunk', [('need', 'VBP')]), ('to', 'TO'), Tree('Chunk', [('write', 'VB')]), ('checks', 'NNS'), ('or', 'CC'), Tree('Chunk', [('use', 'VB')]), ('postal', 'JJ'), ('service', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), Tree('Chunk', [('Ryan', 'NNP')]), ('and', 'CC'), ('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('customer', 'NN'), ('at', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('order', 'NN'), ('checks', 'NNS'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NNS'), ('need', 'VBP'), ('to', 'TO'), ('write', 'VB'), ('checks', 'NNS'), ('or', 'CC'), ('use', 'VB'), ('postal', 'JJ'), ('service', 'NN')])]\n",
      "Filtered Sentence--> ['Customer', 'My', 'name', 'Ryan', 'I', 'customer', 'bank', ',', 'I', 'want', 'order', 'checks', 'I', 'don', '’', 't', 'need', 'write', 'checks', 'use', 'postal', 'service']\n",
      "['Customer']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NN')]\n",
      "----> (S Customer/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')])]\n",
      "===> (S Customer/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')])]\n",
      "['Customer will need to have a feature to apply for a loan from bank so that he can purchase a car']\n",
      "*********************************************\n",
      "Tagged: [('Customer', 'NNP'), ('will', 'MD'), ('need', 'VB'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('feature', 'NN'), ('to', 'TO'), ('apply', 'VB'), ('for', 'IN'), ('a', 'DT'), ('loan', 'NN'), ('from', 'IN'), ('bank', 'NN'), ('so', 'IN'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), ('purchase', 'VB'), ('a', 'DT'), ('car', 'NN')]\n",
      "----> (S\n",
      "  Customer/NNP\n",
      "  will/MD\n",
      "  (Chunk need/VB)\n",
      "  to/TO\n",
      "  (Chunk have/VB)\n",
      "  a/DT\n",
      "  feature/NN\n",
      "  to/TO\n",
      "  (Chunk apply/VB)\n",
      "  for/IN\n",
      "  a/DT\n",
      "  loan/NN\n",
      "  from/IN\n",
      "  bank/NN\n",
      "  so/IN\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  can/MD\n",
      "  (Chunk purchase/VB)\n",
      "  a/DT\n",
      "  car/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Customer', 'NN')]), Tree('S', [('Customer', 'NNP'), ('will', 'MD'), Tree('Chunk', [('need', 'VB')]), ('to', 'TO'), Tree('Chunk', [('have', 'VB')]), ('a', 'DT'), ('feature', 'NN'), ('to', 'TO'), Tree('Chunk', [('apply', 'VB')]), ('for', 'IN'), ('a', 'DT'), ('loan', 'NN'), ('from', 'IN'), ('bank', 'NN'), ('so', 'IN'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), Tree('Chunk', [('purchase', 'VB')]), ('a', 'DT'), ('car', 'NN')])]\n",
      "===> (S\n",
      "  (Chunk Customer/NNP)\n",
      "  will/MD\n",
      "  need/VB\n",
      "  to/TO\n",
      "  have/VB\n",
      "  a/DT\n",
      "  feature/NN\n",
      "  to/TO\n",
      "  apply/VB\n",
      "  for/IN\n",
      "  a/DT\n",
      "  loan/NN\n",
      "  from/IN\n",
      "  bank/NN\n",
      "  so/IN\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  can/MD\n",
      "  purchase/VB\n",
      "  a/DT\n",
      "  car/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Customer', 'NN')]), Tree('S', [('Customer', 'NNP'), ('will', 'MD'), Tree('Chunk', [('need', 'VB')]), ('to', 'TO'), Tree('Chunk', [('have', 'VB')]), ('a', 'DT'), ('feature', 'NN'), ('to', 'TO'), Tree('Chunk', [('apply', 'VB')]), ('for', 'IN'), ('a', 'DT'), ('loan', 'NN'), ('from', 'IN'), ('bank', 'NN'), ('so', 'IN'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), Tree('Chunk', [('purchase', 'VB')]), ('a', 'DT'), ('car', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Customer', 'NN')]), Tree('S', [Tree('Chunk', [('Customer', 'NNP')]), ('will', 'MD'), ('need', 'VB'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('feature', 'NN'), ('to', 'TO'), ('apply', 'VB'), ('for', 'IN'), ('a', 'DT'), ('loan', 'NN'), ('from', 'IN'), ('bank', 'NN'), ('so', 'IN'), ('that', 'IN'), ('he', 'PRP'), ('can', 'MD'), ('purchase', 'VB'), ('a', 'DT'), ('car', 'NN')])]\n",
      "Filtered Sentence--> ['Customer', 'Customer', 'will', 'need', 'feature', 'apply', 'loan', 'bank', 'can', 'purchase', 'car']\n",
      "['Banker']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NN')]\n",
      "----> (S Banker/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')])]\n",
      "===> (S Banker/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')])]\n",
      "['Banker should be able to restock sufficient cash in ATM.', 'This will help customer to withdraw cash.']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NNP'), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('restock', 'VB'), ('sufficient', 'JJ'), ('cash', 'NN'), ('in', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('customer', 'NN'), ('to', 'TO'), ('withdraw', 'VB'), ('cash', 'NN'), ('.', '.')]\n",
      "----> (S\n",
      "  Banker/NNP\n",
      "  should/MD\n",
      "  (Chunk be/VB)\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  (Chunk restock/VB)\n",
      "  sufficient/JJ\n",
      "  cash/NN\n",
      "  in/IN\n",
      "  ATM/NNP\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  (Chunk help/VB)\n",
      "  customer/NN\n",
      "  to/TO\n",
      "  (Chunk withdraw/VB)\n",
      "  cash/NN\n",
      "  ./.)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('should', 'MD'), Tree('Chunk', [('be', 'VB')]), ('able', 'JJ'), ('to', 'TO'), Tree('Chunk', [('restock', 'VB')]), ('sufficient', 'JJ'), ('cash', 'NN'), ('in', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('customer', 'NN'), ('to', 'TO'), Tree('Chunk', [('withdraw', 'VB')]), ('cash', 'NN'), ('.', '.')])]\n",
      "===> (S\n",
      "  (Chunk Banker/NNP)\n",
      "  should/MD\n",
      "  be/VB\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  restock/VB\n",
      "  sufficient/JJ\n",
      "  cash/NN\n",
      "  in/IN\n",
      "  (Chunk ATM/NNP)\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  help/VB\n",
      "  customer/NN\n",
      "  to/TO\n",
      "  withdraw/VB\n",
      "  cash/NN\n",
      "  ./.)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('should', 'MD'), Tree('Chunk', [('be', 'VB')]), ('able', 'JJ'), ('to', 'TO'), Tree('Chunk', [('restock', 'VB')]), ('sufficient', 'JJ'), ('cash', 'NN'), ('in', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('customer', 'NN'), ('to', 'TO'), Tree('Chunk', [('withdraw', 'VB')]), ('cash', 'NN'), ('.', '.')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')]), Tree('S', [Tree('Chunk', [('Banker', 'NNP')]), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('restock', 'VB'), ('sufficient', 'JJ'), ('cash', 'NN'), ('in', 'IN'), Tree('Chunk', [('ATM', 'NNP')]), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('customer', 'NN'), ('to', 'TO'), ('withdraw', 'VB'), ('cash', 'NN'), ('.', '.')])]\n",
      "Filtered Sentence--> ['Banker', 'Banker', 'able', 'restock', 'sufficient', 'cash', 'ATM', 'will', 'help', 'customer', 'withdraw', 'cash']\n",
      "['Banker']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NN')]\n",
      "----> (S Banker/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')])]\n",
      "===> (S Banker/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')])]\n",
      "['Banker will need to limit the cash withdrwal from ATM.', 'This will help more customers can prevail the ATM cash and also prevent fradulent activities']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NNP'), ('will', 'MD'), ('need', 'VB'), ('to', 'TO'), ('limit', 'VB'), ('the', 'DT'), ('cash', 'NN'), ('withdrwal', 'NN'), ('from', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('more', 'JJR'), ('customers', 'NNS'), ('can', 'MD'), ('prevail', 'VB'), ('the', 'DT'), ('ATM', 'NNP'), ('cash', 'NN'), ('and', 'CC'), ('also', 'RB'), ('prevent', 'JJ'), ('fradulent', 'NN'), ('activities', 'NNS')]\n",
      "----> (S\n",
      "  Banker/NNP\n",
      "  will/MD\n",
      "  (Chunk need/VB)\n",
      "  to/TO\n",
      "  (Chunk limit/VB)\n",
      "  the/DT\n",
      "  cash/NN\n",
      "  withdrwal/NN\n",
      "  from/IN\n",
      "  ATM/NNP\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  (Chunk help/VB)\n",
      "  more/JJR\n",
      "  customers/NNS\n",
      "  can/MD\n",
      "  (Chunk prevail/VB)\n",
      "  the/DT\n",
      "  ATM/NNP\n",
      "  cash/NN\n",
      "  and/CC\n",
      "  also/RB\n",
      "  prevent/JJ\n",
      "  fradulent/NN\n",
      "  activities/NNS)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('will', 'MD'), Tree('Chunk', [('need', 'VB')]), ('to', 'TO'), Tree('Chunk', [('limit', 'VB')]), ('the', 'DT'), ('cash', 'NN'), ('withdrwal', 'NN'), ('from', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('more', 'JJR'), ('customers', 'NNS'), ('can', 'MD'), Tree('Chunk', [('prevail', 'VB')]), ('the', 'DT'), ('ATM', 'NNP'), ('cash', 'NN'), ('and', 'CC'), ('also', 'RB'), ('prevent', 'JJ'), ('fradulent', 'NN'), ('activities', 'NNS')])]\n",
      "===> (S\n",
      "  (Chunk Banker/NNP)\n",
      "  will/MD\n",
      "  need/VB\n",
      "  to/TO\n",
      "  limit/VB\n",
      "  the/DT\n",
      "  cash/NN\n",
      "  withdrwal/NN\n",
      "  from/IN\n",
      "  (Chunk ATM/NNP)\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  help/VB\n",
      "  more/JJR\n",
      "  customers/NNS\n",
      "  can/MD\n",
      "  prevail/VB\n",
      "  the/DT\n",
      "  (Chunk ATM/NNP)\n",
      "  cash/NN\n",
      "  and/CC\n",
      "  also/RB\n",
      "  prevent/JJ\n",
      "  fradulent/NN\n",
      "  activities/NNS)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('will', 'MD'), Tree('Chunk', [('need', 'VB')]), ('to', 'TO'), Tree('Chunk', [('limit', 'VB')]), ('the', 'DT'), ('cash', 'NN'), ('withdrwal', 'NN'), ('from', 'IN'), ('ATM', 'NNP'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('more', 'JJR'), ('customers', 'NNS'), ('can', 'MD'), Tree('Chunk', [('prevail', 'VB')]), ('the', 'DT'), ('ATM', 'NNP'), ('cash', 'NN'), ('and', 'CC'), ('also', 'RB'), ('prevent', 'JJ'), ('fradulent', 'NN'), ('activities', 'NNS')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')]), Tree('S', [Tree('Chunk', [('Banker', 'NNP')]), ('will', 'MD'), ('need', 'VB'), ('to', 'TO'), ('limit', 'VB'), ('the', 'DT'), ('cash', 'NN'), ('withdrwal', 'NN'), ('from', 'IN'), Tree('Chunk', [('ATM', 'NNP')]), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('more', 'JJR'), ('customers', 'NNS'), ('can', 'MD'), ('prevail', 'VB'), ('the', 'DT'), Tree('Chunk', [('ATM', 'NNP')]), ('cash', 'NN'), ('and', 'CC'), ('also', 'RB'), ('prevent', 'JJ'), ('fradulent', 'NN'), ('activities', 'NNS')])]\n",
      "Filtered Sentence--> ['Banker', 'Banker', 'will', 'need', 'limit', 'cash', 'withdrwal', 'ATM', 'will', 'help', 'customers', 'can', 'prevail', 'ATM', 'cash', 'also', 'prevent', 'fradulent', 'activities']\n",
      "['Banker']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NN')]\n",
      "----> (S Banker/NN)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')])]\n",
      "===> (S Banker/NN)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')])]\n",
      "['Banker should be able to review the credit history and the bank balance of customers that apply for loans .', 'This will help banker to decide wether to approve or reject the loan applications']\n",
      "*********************************************\n",
      "Tagged: [('Banker', 'NNP'), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('review', 'VB'), ('the', 'DT'), ('credit', 'NN'), ('history', 'NN'), ('and', 'CC'), ('the', 'DT'), ('bank', 'NN'), ('balance', 'NN'), ('of', 'IN'), ('customers', 'NNS'), ('that', 'WDT'), ('apply', 'VBP'), ('for', 'IN'), ('loans', 'NNS'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('banker', 'NN'), ('to', 'TO'), ('decide', 'VB'), ('wether', 'JJR'), ('to', 'TO'), ('approve', 'VB'), ('or', 'CC'), ('reject', 'VB'), ('the', 'DT'), ('loan', 'NN'), ('applications', 'NNS')]\n",
      "----> (S\n",
      "  Banker/NNP\n",
      "  should/MD\n",
      "  (Chunk be/VB)\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  (Chunk review/VB)\n",
      "  the/DT\n",
      "  credit/NN\n",
      "  history/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  balance/NN\n",
      "  of/IN\n",
      "  customers/NNS\n",
      "  that/WDT\n",
      "  (Chunk apply/VBP)\n",
      "  for/IN\n",
      "  loans/NNS\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  (Chunk help/VB)\n",
      "  banker/NN\n",
      "  to/TO\n",
      "  (Chunk decide/VB)\n",
      "  wether/JJR\n",
      "  to/TO\n",
      "  (Chunk approve/VB)\n",
      "  or/CC\n",
      "  (Chunk reject/VB)\n",
      "  the/DT\n",
      "  loan/NN\n",
      "  applications/NNS)\n",
      "Grouped VERBS :: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('should', 'MD'), Tree('Chunk', [('be', 'VB')]), ('able', 'JJ'), ('to', 'TO'), Tree('Chunk', [('review', 'VB')]), ('the', 'DT'), ('credit', 'NN'), ('history', 'NN'), ('and', 'CC'), ('the', 'DT'), ('bank', 'NN'), ('balance', 'NN'), ('of', 'IN'), ('customers', 'NNS'), ('that', 'WDT'), Tree('Chunk', [('apply', 'VBP')]), ('for', 'IN'), ('loans', 'NNS'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('banker', 'NN'), ('to', 'TO'), Tree('Chunk', [('decide', 'VB')]), ('wether', 'JJR'), ('to', 'TO'), Tree('Chunk', [('approve', 'VB')]), ('or', 'CC'), Tree('Chunk', [('reject', 'VB')]), ('the', 'DT'), ('loan', 'NN'), ('applications', 'NNS')])]\n",
      "===> (S\n",
      "  (Chunk Banker/NNP)\n",
      "  should/MD\n",
      "  be/VB\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  review/VB\n",
      "  the/DT\n",
      "  credit/NN\n",
      "  history/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  balance/NN\n",
      "  of/IN\n",
      "  customers/NNS\n",
      "  that/WDT\n",
      "  apply/VBP\n",
      "  for/IN\n",
      "  loans/NNS\n",
      "  ./.\n",
      "  This/DT\n",
      "  will/MD\n",
      "  help/VB\n",
      "  banker/NN\n",
      "  to/TO\n",
      "  decide/VB\n",
      "  wether/JJR\n",
      "  to/TO\n",
      "  approve/VB\n",
      "  or/CC\n",
      "  reject/VB\n",
      "  the/DT\n",
      "  loan/NN\n",
      "  applications/NNS)\n",
      "Chunked Verbs:: [Tree('S', [('Banker', 'NN')]), Tree('S', [('Banker', 'NNP'), ('should', 'MD'), Tree('Chunk', [('be', 'VB')]), ('able', 'JJ'), ('to', 'TO'), Tree('Chunk', [('review', 'VB')]), ('the', 'DT'), ('credit', 'NN'), ('history', 'NN'), ('and', 'CC'), ('the', 'DT'), ('bank', 'NN'), ('balance', 'NN'), ('of', 'IN'), ('customers', 'NNS'), ('that', 'WDT'), Tree('Chunk', [('apply', 'VBP')]), ('for', 'IN'), ('loans', 'NNS'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), Tree('Chunk', [('help', 'VB')]), ('banker', 'NN'), ('to', 'TO'), Tree('Chunk', [('decide', 'VB')]), ('wether', 'JJR'), ('to', 'TO'), Tree('Chunk', [('approve', 'VB')]), ('or', 'CC'), Tree('Chunk', [('reject', 'VB')]), ('the', 'DT'), ('loan', 'NN'), ('applications', 'NNS')])]\n",
      "Chunked ProNOuns:: [Tree('S', [('Banker', 'NN')]), Tree('S', [Tree('Chunk', [('Banker', 'NNP')]), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('review', 'VB'), ('the', 'DT'), ('credit', 'NN'), ('history', 'NN'), ('and', 'CC'), ('the', 'DT'), ('bank', 'NN'), ('balance', 'NN'), ('of', 'IN'), ('customers', 'NNS'), ('that', 'WDT'), ('apply', 'VBP'), ('for', 'IN'), ('loans', 'NNS'), ('.', '.'), ('This', 'DT'), ('will', 'MD'), ('help', 'VB'), ('banker', 'NN'), ('to', 'TO'), ('decide', 'VB'), ('wether', 'JJR'), ('to', 'TO'), ('approve', 'VB'), ('or', 'CC'), ('reject', 'VB'), ('the', 'DT'), ('loan', 'NN'), ('applications', 'NNS')])]\n",
      "Filtered Sentence--> ['Banker', 'Banker', 'able', 'review', 'credit', 'history', 'bank', 'balance', 'customers', 'apply', 'loans', 'will', 'help', 'banker', 'decide', 'wether', 'approve', 'reject', 'loan', 'applications']\n"
     ]
    }
   ],
   "source": [
    "wb = open_workbook(\"MYLOCALEXCELBRD_mod.xlsx\")\n",
    "# FOr each sheet in Spreadsheet\n",
    "for sheet in wb.sheets():\n",
    "        numberRows = sheet.nrows\n",
    "        numberCols = sheet.ncols\n",
    "        \n",
    "        items = []\n",
    "        rows = []\n",
    "        # For each row in a workbook\n",
    "        for row in range(1, numberRows):\n",
    "            values =  []\n",
    "            filtered_Sentence = []\n",
    "            verbs = []\n",
    "            proNouns = []\n",
    "            # For each columns in the workbook\n",
    "            for col in range(1, numberCols):\n",
    "                value = (sheet.cell(row, col).value)\n",
    "                values.append(value)\n",
    "                # tokenize the words in the sentence\n",
    "                print(sent_tokenize(value))\n",
    "                print(\"*********************************************\")\n",
    "                words = word_tokenize(value)\n",
    "                # Words are tagged so, that they can be identified which one is verb/Noun/ Pronoun\n",
    "                tagged = nltk.pos_tag(words)\n",
    "                print (\"Tagged:\",tagged)\n",
    "                #Retrieves Verb from the Sentence or tokens\n",
    "                chunkVerb = r\"\"\"Chunk: {<VB.?>*} \"\"\"\n",
    "                chunkProNoun = r\"\"\"Chunk: {<NNP.?>*} \"\"\"\n",
    "                \n",
    "                chunkParser = nltk.RegexpParser(chunkVerb)\n",
    "                chunked = chunkParser.parse(tagged)\n",
    "                print (\"---->\",chunked)\n",
    "                verbs.append(chunked)\n",
    "                print (\"Grouped VERBS ::\", verbs)\n",
    "                chunkParser = nltk.RegexpParser(chunkProNoun)\n",
    "                chunked = chunkParser.parse(tagged)\n",
    "                print(\"===>\",chunked)\n",
    "                proNouns.append(chunked)\n",
    "                print (\"Chunked Verbs::\",verbs)\n",
    "                print (\"Chunked ProNOuns::\",proNouns)\n",
    "                \n",
    "                #chunked.draw()\n",
    "                \n",
    "               \n",
    "                for w in words:\n",
    "                    if w not in stopWords:\n",
    "                        filtered_Sentence.append(w)\n",
    "            print(\"Filtered Sentence-->\",filtered_Sentence)\n",
    "                \n",
    "\n",
    "        break;\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Utility functions for Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prepare data **\n",
    "* Load artifacts from object storage and create pandas dataframes\n",
    "* Prepare the pandas dataframes. Add additional columns required for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements.xlsx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/test/Requirements.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ed233fa7233d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#prepare_artifact_dataframes()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bcd74ccafd6a>\u001b[0m in \u001b[0;36mload_artifacts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m# we had to use so many variables as we were not able to run python 3 with boto3 get_object()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mrequirements_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequirements_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequirements_sheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdomain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_sheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdataelements_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataelements_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataelements_sheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, skiprows, skip_footer, index_col, names, usecols, parse_dates, date_parser, na_values, thousands, convert_float, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     return io._parse_excel(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/test/Requirements.xlsx'"
     ]
    }
   ],
   "source": [
    "load_artifacts()\n",
    "#prepare_artifact_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run Spacy Text Classifier on data **\n",
    "* Add the text classification output to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_column_name = \"ClassifiedText\"\n",
    "#defects_df = add_text_classifier_output(defects_df,config, output_column_name)\n",
    "#testcases_df = add_text_classifier_output(testcases_df,config, output_column_name)\n",
    "#requirements_df = add_text_classifier_output(requirements_df,config, output_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Populate keywords and entities **\n",
    "* Add the keywords and entities extracted from the unstructured text to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Correlate keywords between artifacts **\n",
    "* Add the text similarity score of associated artifacts to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utility functions to store entities and relations in Orient DB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform results for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Expose integration point with a websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Start websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_websocket_listener()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
